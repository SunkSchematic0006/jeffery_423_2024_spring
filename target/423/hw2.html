<h3>CSE 423 Homework 2: A Lexical Analyzer</h3>

Due: Tuesday February 6, 11:59pm<p>

In this assignment you will write a lexical analyzer in
<code>flex(1)</code>, for a subset of Rust known as the <code>Irony</code>
language that is documented in its
<A href="http://www.cs.nmt.edu/~jeffery/courses/423/ironyref.html">
reference document</A>.

<p>
<A name="engineering"><h3> Engineering Requirements </h3></A>

In this and all subsequent assignments in 423, please meet the following
engineering requirements. Points will be assigned in grading for them.

<dl>
<dt> Mandatory .zip file unpacks to the <b>current directory</b>.
<dd> Turnin Must be a .zip containing a valid compressed archive that can
     be uncompressed on Linux via the command <code>unzip</code>.
     It may not be a <code>.tar</code> or a <code>.rar</code>
     or a <code>.bzip</code> or whatever, whether disguised or renamed or not.
     The <code>.zip</code> must unpack into the current directory, not a
     subdirectory.  Subdirectories are fine, but there must be a
     top-level makefile that builds an executable named
     <code>fec</code>
     in the top-level directory from where you were unzipped.
     That is what my test script will attempt to run.
     Fec stands for "Irony compiler", since Fe is the symbol for Iron.
<dt> "make" just works on login.cs.nmt.edu; <b>it builds an executable
     named <code>fec</code></b>.
<dd> You have to supply a makefile that contains build rules described below.
     Also: historically, a good number of students
     will lose points at some point in the semester for not bothering
     to test their work on the machine that I will grade on.  Testing in
     your own working directory will not protect you against accidentally
     omitting required files or other surprises. Test in a separate directory.

<dt> Fully Separate Compilation.
<dd> The compiler must be invoked separately on each source file.
     E.g. all .c files must be linked together via .o object files, no using
     <code>#include</code> of .c files.  No including any code (function
     bodies) in .h files.
<dt> No Warnings.
<dd> The gcc compiler must be invoked with <code>-Wall</code>
     on all compilation lines. If you are using another language,
     which must be approved by Dr. J, you must also seek to use all
     its warning options, or get any omissions approved.
     Points will be lost if you don't fix warnings.  There are some common
     lex/flex warnings, such as about not using <code>input()</code> that
     are no big deal, but use
<pre>
%option noinput
%option nounput
</pre>
     to shut them up.  See the instructor if you are unable to fix a warning.
<dt> Valgrind validation
<dd> You should test your work on login.cs.nmt.edu both with and without
     valgrind.
     Valgrind output should be free of <b>memory errors</b>.
     You will also become
     more experienced with gdb in this class, but valgrind is your first line
     of defense.  For the purposes of this class, a "memory error" is a
     message from valgrind indicating a
     read or write of one or more bytes of illegal, out-of-bounds,
     or uninitialized memory.
     Other (non-memory) valgrind messages may be useful to you, or you
     can ignore them; they will not cost you points.
</dl>

<h3> Feature Requirements </h3>

In this document, the term "must" indicates a feature that is
required for passing grade, while the term "should" indicates a feature
that is expected for a grade of "A" or "B".  If you do not know what
something means, or don't know how to do it, you are encouraged to ask
and find out rather than turning in a homework that does not meet the
specifications.

<p>

Your program executable must be named <code>fec</code>.  Your program
should read in source file(s) named on the command line and
write output with one line for each token, described below.
Source files
must accept the extension <code>.rs</code>. The compiler should
automatically add
<code>.rs</code> to the end of filenames if no other extension is given.
(Eventually in a later homework, the compiler will automatically name the
executable the same name as the first argument.
For this assignment there is no output executable.)

<p>

Compilers and related tools are used by programs such as <code>make(1)</code>
that read the process exit status to tell whether all is well. Your
program's exit status should return 0 if there are no errors, and a nonzero
number to indicate errors. For lexical errors, return 1.

<h3> Language Details </h3>

The <code>Irony</code> language is (not) described (yet) at
<A href="http://www.cs.nmt.edu/~jeffery/courses/423/ironyref.html">
http://www.cs.nmt.edu/~jeffery/courses/423/ironyref.html</A>. As this
is a new language this semester, these details will be filled in
and corrected and amended as needed in response to student questions.

<h3> Starting Points </h3>

<ul>
<li> You must write a <A href="rustlex.l">rustlex.l</A> that matches the
     tokens of the Rust language.
<li> you will need to make up a set of integer codes for yylex() to return;

<li> you will need to read Rust references and get precise definitions
     of the literal constants, including escape characters in strings, etc.

<li>
     In C this is done as a set of #define's or an enum, in a .h file.
<li>
     Classic yacc used the name y.tab.h for this file; can be named otherwise.

<li> Indent/dedent tokens will require special treatment, as will tabs.

<li> A full Rust lexer might have to account for dual-byte Unicode or
     UTF-8 multi-byte characters.
     For our subset of Rust we can live without.

<li> For further notes,
     see discussion in section <code>yylex()</code> and <code>main()</code>,
     below.
</ul>

<A name="lextokens">
<h3> Rust Lex Tokens </h3>
</A>

These are from a Rust grammar I found, but are not in Flex
format. For some of them we will have to ascertain precise definitions.
For some of them we might end up omitting them if we can't identify
a valid rust token that they denote.

<h4> Single-byte tokens </h4>

Tokens like the left parenthesis or the dot operator can generally be
returned as their ASCII code, between 1-127.  So for left parenthesis,
for example, return '(' a.k.a. 40.

<h4> Multi-byte tokens </h4>

Tokens that are multiple-bytes long get returned as integers larger than
256, and you will need symbolic names to refer to them

<pre>
 SHL               "<<"
 SHR               ">>"
 LE                "<="
 EQEQ              "=="
 NE                "!="
 GE                ">="
 ANDAND            "&amp;&amp;"
 OROR              "||"
 SHLEQ             "<<="
 SHREQ             ">>="
 MINUSEQ           "-="
 ANDEQ             "&="
 OREQ              "|="
 PLUSEQ            "+="
 STAREQ            "*="
 SLASHEQ           "/="
 CARETEQ           "^="
 PERCENTEQ         "%="
 DOTDOT            ".."
 DOTDOTDOT         "..."
 MOD_SEP           "::"
 RARROW            "->"
 LARROW            unknown, "<-" ?
 FAT_ARROW         "=>"
 LIT_BYTE          byte literals
 LIT_CHAR          char literals
 LIT_INTEGER       integer literals
 LIT_FLOAT         float literals
 LIT_STR           string literals
 LIT_STR_RAW       raw string literals
 LIT_BYTE_STR      byte string literals
 LIT_BYTE_STR_RAW  raw byte string literals
 IDENT             identifiers
 UNDERSCORE        "_"
 LIFETIME

// keywords
 SELF
 STATIC
<s> ABSTRACT</s>
<s> ALIGNOF</s>
<font color=red> AS</font>
<font color=red> BECOME</font>
<font color=green> BREAK</font>
 CATCH
 CRATE
 DO
 ELSE
 ENUM
 EXTERN
 FALSE
 FINAL
 FN
 FOR
 IF
 IMPL
 IN
 LET
 LOOP
 MACRO
 MATCH
 MOD
 MOVE
 MUT
 OFFSETOF
 OVERRIDE
 PRIV
 PUB
 PURE
 REF
 RETURN
 SIZEOF
 STRUCT
 SUPER
 UNION
 UNSIZED
 TRUE
 TRAIT
 TYPE
 UNSAFE
 VIRTUAL
 YIELD
 DEFAULT
 USE
 WHILE
 CONTINUE
 PROC
 BOX
 CONST
 WHERE
 TYPEOF
 INNER_DOC_COMMENT
 OUTER_DOC_COMMENT

 SHEBANG        "#!"
 SHEBANG_LINE   "#!"... followed by other stuff up to a newline
 STATIC_LIFETIME
</pre>

<h3> "Fixing" the Literal Constants </h3>

We will give various examples of regular expressions for literal constants
in lecture, but your mission is to get the literal constants for Rust as
correct as you can manage.

<ul>
<li> If some legal Rust token is supposed to be in Irony,
     add or correct regexes for it to rustlex.l
<li> If some legal Rust token is <b>not</b> supposed to be in Irony, have
     your lexical analyzer report a lexical error and stop execution.
<li> Place a special focus on literal constants (strings, integers, reals...)
<li> Catch lexical errors related to literal constants and report them
     (with filename and line number)
     and stop, instead of just returning bogus output.
<li> Examples: what does your lexical analyzer do with
<pre>
     "hello
     /* world
     12e
</pre>
</ul>

<h3> Lexical Attributes </h3>

In your <code>yylex()</code>, you should compute attributes for each token,
and store them in a global variable named <code>yytoken</code>. Note that
this is not part of the lex/yacc public interface, although it is named so
as to be a recognizable extension of said interface.  You should use the
following token type, or a compatible extension of it.

<p>

<pre>
struct token {
   int category;   /* the integer code returned by yylex */
   char *text;     /* the actual string (lexeme) matched */
   int lineno;     /* the line number on which the token occurs */
   char *filename; /* the source file in which the token occurs */
   int ival;       /* for integer constants, store binary value here */
   double dval;	   /* for real constants, store binary value here */
   char *sval;     /* for string constants, malloc space, de-escape, store */
                   /*    the string (less quotes and after escapes) here */
   }
</pre>

<p>

In this homework your <code>main()</code> procedure should 
build a LINKED LIST of all the token structs, each of which is created by
<code>yylex()</code>.  In the next assignment, we will discard the linked
list and instead insert all these tokens into a tree.<p>

Example linked list structure:

<pre>
   struct tokenlist {
      struct token *t;
      struct tokenlist *next;
      }
</pre>

Use the <code>malloc()</code> function to allocate chunks of memory for
<code>struct token</code> and <code> struct tokenlist</code>.

<h3> <code>yylex()</code> and <code>main()</code> </h3>

Your <code>yylex()</code> should return a different unique integer &gt; 257
for each reserved word, and for each other token category (identifier,
integer literal constant, string literal constant, addition operator, etc).
Numbers &gt; 257 are required for the sake of compatibility with the
parser generator tool.  For each such number, you must <code>#define</code>
a symbol, as in

<pre>
#define IDENTIFIER 260
</pre>

This is required for the sake of readability.  Your <code>yylex()</code>
should return -1 when it hits end of file.  In this homework, your
<code>yylex()</code> should recognize lines beginning with # and treat them
as comments, i.e. delete the line contents silently.  In later homework,
treatment of preprocessor directives will become more interesting.

<p>

In this assignment, there should be (at least) two separately-compiled .c
files, a .h file and a makefile. The <code>yylex()</code> function must be
called by a <code>main()</code> function in a loop.  For each token, the
<code>main()</code> function should
write out a line containing the token category (an integer
&gt; 257) and lexical attributes.

<h3> Turn in... </h3>

An electronic copy via Canvas.  The electronic copy should be a
compressed archive .zip file, containing makefile, flex rustlex.l file, main.c
file, and ytab.h file.  </pre>

If you add any other source files to your program, be sure you add it/them
to the makefile rules and .zip containing the set of files that you turn in.

<h3> Example </h3>

<p>

For an example input file named hello.rs that contains:
<p>
<table border>
<tr><td>
<pre>
   fn main() {
      println!("hello,\tIrony!\n");
   }
</pre>
</table>

<p>

your output should look something like the following. Integer categories
are for illustration purposes; <em>your integer codes may be different</em>.

<p>

<table border>
<tr><td>
<pre>
Category	Text		Lineno		Filename	Ival/Sval
-------------------------------------------------------------------------
270		fn		1		hello.rs
271		main		1		hello.rs
290		(		1		hello.rs
291		)		1		hello.rs
292		{		1		hello.rs
271		println		2		hello.rs
294		!		2		hello.rs
290		(		2		hello.rs
272		"hello,\tIrony!\n" 2		hello.rs	hello,	Irony!

291		)		2		hello.rs
293		}		3		hello.rs
</pre>
</table>
