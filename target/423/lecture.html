<html><head></head><body><h1> Dr. J's Compiler and Translator Design Lecture Notes </h1>

(C) Copyright 2011-2024 by Clinton Jeffery and/or original authors where
appropriate.  For use in Dr. J's Compiler classes only.  Lots of material
in these notes originated with Saumya Debray's Compiler course notes from
the University of Arizona, for which I owe him a debt of thanks.  Various
portions of his notes were in turn inspired by the ASU red dragon book.

<table>
<tbody><tr align="top">
<td>
<ul>
<li> <a href="#intro">Introduction</a>
<ul>
<li> <a href="#1">Lecture 1</a> <!--(<a href="https://www.cs.nmt.edu/~jeffery/courses/423/445-1.pptx">pptx</a>)-->
</li></ul>
</li><li> <a href="#lexical">Lexical Analysis</a>
<ul>
<li> <a href="#2">Lecture 2</a> <!--(<a href="https://www.cs.nmt.edu/~jeffery/courses/423/445-2.pptx">pptx</a>)-->
</li><li> <a href="#3">Lecture 3</a> <!--(<a href="https://www.cs.nmt.edu/~jeffery/courses/423/445-3.pptx">pptx</a>)-->
</li><li> <a href="#4">Lecture 4</a>
</li><li> <a href="#5">Lecture 5</a> <!--(<a href="https://www.cs.nmt.edu/~jeffery/courses/423/445-5.pptx">pptx</a>)-->
</li><li> <a href="#6">Lecture 6</a>
</li><li> <a href="#7">Lecture 7</a><!-- (<a href="https://www.cs.nmt.edu/~jeffery/courses/423/445-7.pptx">pptx</a>)-->
</li><li> <a href="#8">Lecture 8</a>
</li><li> <a href="#9">Lecture 9</a>
</ul>
</li></ul>
<ul>
<li> <a href="#syntax">Syntax Analysis</a>
<ul>
<li> <a href="#10">Lecture 10</a>
<li> <a href="#11">Lecture 11</a>
<li> <a href="#12">Lecture 12</a>
<li> <a href="#13">Lecture 13</a>
<li> <a href="#14">Lecture 14</a>
<li> <a href="#15">Lecture 15</a>
<li> <a href="#16">Lecture 16</a>
<li> <a href="#17">Lecture 17</a>
<li> <a href="#18">Lecture 18</a>
</ul>
</li></ul>
</td>
<td align="top">
<ul>
<li> <a href="#semantic">Semantic Analysis</a>
<ul>
</li><li> <a href="#19">Lecture 19</a>
<li> <a href="#20">Lecture 20</a>
</li><li> <a href="#21">Lecture 21</a>
</li><li> <a href="#22">Lecture 22</a>
</ul>

<li> Midterm Review

<li> More Semantic Analysis
<ul>
</li><li> <a href="#23">Lecture 23</a>
</li><li> <a href="#24">Lecture 24</a>
</li><li> <a href="#25">Lecture 25</a>
</li><li> <a href="#26">Lecture 26</a>
</li><li> <a href="#27">Lecture 27</a>
</li><li> <a href="#28">Lecture 28</a>
<li> <a href="#29">Lecture 29</a>
</li></ul>
</li></ul>


</td><td>


<li> <a href="#codegen">Intermediate Code Generation</a>
<ul>
</li><li> <a href="#30">Lecture 30</a>
</li><li> <a href="#31">Lecture 31</a>
</li><li> <a href="#32">Lecture 32</a>
</li><li> <a href="#33">Lecture 33</a>
<li> <a href="#34">Lecture 34</a>
</li><li> <a href="#35">Lecture 35</a>
</li><li> <a href="#36">Lecture 36</a>
</li></ul>

<li> <a href="#finalcode">Final Code Generation</a>
<ul>
</li><li> <a href="#37">Lecture 37</a>
</li><li> <a href="#38">Lecture 38</a>
</li><li> <a href="#39">Lecture 39</a>
</li><li> <a href="#40">Lecture 40</a>
</li></ul>

</li><li> <a href="#optimization">Optimization</a>
<ul>
</li><li> <a href="#41">Lecture 41</a>
</li><li> <a href="#42">Lecture 42</a>
</li></ul>
</li>
<li> <A href="#finalreview">Final Exam Review</A>
</td>
</tr>
</tbody></table>

<p>
<font size="1"> <a name="1">lecture #1</a> began here</font>
</p><p>

</p><h3> Syllabus</h3>

Yes, go over the <a href="https://www.cs.nmt.edu/~jeffery/courses/423/syllabus.html">syllabus</a>.

<h3> Announcements </h3>

<ul>
  <li> Homework #1 is posted.
</ul>

<h3> Comments on Implementation Languages </h3>

<ul>
</li><li> C is the recommended language for you to use in this course,
     however there is a bit of wiggle room.
</li><li> The ideal language is: the one that you know best, that happens
     to have a near-100%-compatible lex and yacc tool, and happens
     to be on newlogin.cs.nmt.edu
</li><li> Examples of languages I've allowed students to attempt to use in past:
<dl>
<dt> C++
</dt><dd> OK, but not recommended. If calling flex/bison from C++ give you
     trouble, that's on you.
</dd><dt> Python
</dt><dd> Vetoed. The main "lex and yacc for Python", PLY, is not lex and yacc
  compatible enough. Past students whom I allowed to use this performed poorly.
</dd><dt> Java
</dt><dd> OK, but you have to agree to use jflex and byacc/j, and we might need
     to do some setup for it to run as needed.
</dd><dt> <a href="http://www.unicon.org/">Unicon</a>
</dt><dd> My research language will be used
     occasionally in examples this semester.
     Unicon has a language level akin to Python but
     syntax a bit more C/Pascal/Java-ish. Lex and yacc specifications
     that are written carefully can be shared by Unicon and Java tools.
</dd></dl>
</li><li> If you wish to use something other than C, you must confer with Dr. J
     and it must be approved, which may include demonstrating to me that it
  runs on the computer named newlogin.cs.nmt.edu, and must have compiler
  generation tools. NMT sysadmins might or
  might not be able to install new things that you might need.
</li>
<li> If you wish to use compiler tools that are not near-100% compatible with
  Lex/Yacc, you must confer with Dr. J and it must be approved.  PLY and ANTLR
  are examples of not-compatible-enough parser generator tools that have
  pros and cons. For example some of the pros of ANTLR are highlighted at
  <A href="https://tomassetti.me/why-you-should-not-use-flex-yacc-and-bison/">
  Why you should not use (f)lex, yacc and bison</A>, by G. Tomassetti.  Just
  because someone writes something does not make it un-biased or true.  But
  it does make some valid points and tell one side of the story.
</ul>

<H3>What We Tried Last Year?</h3>

Last year in order to try to reduce the number of D's and F's in CSE 423
we tried various changes.

<ul>
  <li> Team focus
    <ul>
  <li> (Even) a (toy) compiler is almost too big a job for one person
  <li> We are going to run this class more like a software engineering course
  <li> Larger emphasis on group teamwork
  <li> Size and composition of teams is a Big Question
  <li> In past software engineering courses, I have run team sizes
    ranging from 2 (pairs) to ~40 (entire class) on
    a team. Larger team size allows more specialization but makes bigger
    communication and load-balancing challenges.
  <li> Slackers, if there are any, tend to fail exams, but we also need
    to mitigate risk to the teams. Not OK if the team fails due to some
    team members' not being fully invested.
  <li> Everyone still needs to learn the theory
  <li> Everyone needs to be heavily involved in the code
  <li> So: <em>earn</em> the right to team up and split labor,
       via one or more mergers
       after successful completion of assignments, starting after HW#2.
  </ul>
  <li> Target Language we are implementing
    <ul>
      <li> Last year: Java subset.
      <li> This year: Python subset.
      <li> Everyone will have to know, or learn, Python basics. If you
	don't know Python you might start with
	<A href="https://www.cs.nmt.edu/~jeffery/Shipman/www/docs/tcc/help/pubs/python27/python27.pdf">this</A>
      <li> We will define our Python subset as we go, starting from
	<A href="punyref.html">this reference</A> (still being
	constructed/translated)
      <li> Every team will have to sort out Python syntax and parsing,
	including whitespace-based indentation (woot)
    </ul>
  </ul>

Some of this worked, some of it didn't. For 2024

  <ul>
  <li> Target Language we are implementing: Rust (subset)
    <ul>
      <li> Everyone will have to know, or learn, Rust basics.  See HW#1
      <li> We will define our Rust subset early and refine it as we go.
      <li> Every team will have to sort out Rust syntax and parsing,
	including whitespace-based indentation (woot)
	<li> Semantics and runtime system for Rust likely to be a small subset
    </ul>
  </ul>



</p><h4> Reading! </h4>

<ol>

<li>
Read the Thain text chapters 1-3. Within the Scanning chapter, there are
portions on the finite automata that should be CSE 342 review; you may
SKIM that material, unless you don't know it or don't remember it, in
which case you should READ in detail.

<li> If you have BYOPL, you may want to read the BYOPL text, chapters 1-3.
  You can sort of skim chapter 1-2.
  Chapter 3 is important for the next homework(s) #2+.

<li>
Read Sections 3-5 of the Flex manual,
<a href="http://westes.github.io/flex/manual/">Lexical Analysis With Flex</a>.

</li><li> Read the class lecture notes
as fast as we manage to cover topics. Please ask questions about
whatever is not totally clear.  You can <em>Ask Questions</em> in class or
via e-mail.
</li></ol>

<p>

Although the whole course's lecture notes are ALL available to you
up front, I generally revise each lecture's notes, making additions,
corrections and adaptations to this year's homeworks, the night before each
lecture.  The best time to print hard copies of the lecture notes, if you
choose to do that, is one
day at a time, right before the lecture is given.  Or just read online.
</p><p>


<a name="intro">
<h3>Why study compilers?</h3>
</a>

Computer scientists study compiler construction for the
following reasons:

<ul>
<li> Experience with large-scale
applications development. Your compiler may be the largest
program you write as a student.  Experience working with really big
data structures and complex interactions between algorithms will
help you out on your next big programming project.

</li><li> A shining triumph of CS theory.
It demonstrates the value of theory over the impulse to just "hack up"
a solution.

</li><li> A basic element of programming language research.
Many language researchers write compilers for the languages they design.

</li><li> Many applications have similar properties to one or more phases of
a compiler, and compiler expertise and tools can help an application
programmer working on other projects besides compilers.

</li></ul>

CSE 423 is labor intensive. This is a good thing: there is no way to
learn the skills necessary for writing big programs without this kind
of labor-intensive experience.

<h3> Some Tools we will use </h3>

Labs and lectures will discuss all of these, but if you do not know them
already, the sooner you go learn them, the better.

<dl>
<dt> C and "make".
</dt><dd> If you are not expert with these yet, you will be a lot closer
     by the time you pass this class.
</dd><dt> lex and yacc
</dt><dd> These are compiler-writers tools, but they are useful for other
     kinds of applications, almost anything with a complex file format
     to read in can benefit from them.
</dd><dt> gdb and valgrind
</dt><dd> If you do not know a source-level like gdb debugger well, start learning.
      You will need one to survive this class. If you have never used valgrind:
      it can find some bugs that gdb misses!
</dd><dt> e-mail
</dt><dd> Regularly e-mailing your instructor is a crucial part of class
     participation.  If you aren't asking questions, you aren't doing
     your job as a student.
</dd><dt> web
</dt><dd> This is where you get your lecture notes, homeworks, and labs,
     and turnin all your work.
</dd></dl>

<p>
<a name="lexical">
<font size="1"> </font></a><font size="1"><a name="2">lecture #2</a> began here</font>

<h3> Three Threads for Awhile </h3>
  
<dl>
  <dt> Requirements Analysis
    <dd> Learn Rust, decide what our Rust subset consists of.  BTW, what is
      the name of our Rust subset?
      <ul>
	<li> Oxide - oxc (the oxide compiler)
	<li>Rus (or maybe even Ru)
	<li> Your nomination here
	</ul>
      <dt> Book Lernin
	<dd> Learn about lexical analysis
	  <dt> Flex
	    <dd> Learn about the lexical analyzer generator
</dl>

<h3> Rust of the Day </h3>

Tell me everything you've learned about Rust so far in like two minutes
or less:

<pre>
fn f() { } is the function syntax
let <em>v</em> : <em>type</em> = <em>val</em>; is the variable declaration syntax; types often inferred
it uses semicolons ;-(
println! is a macro
...

</pre>


<h3> How big is our Rust subset? </h3>

<ul>
<li> certainly not: everything you see in Rust By Example
<li> ideally: big enough for a CS1 class (e.g. CSE 113) taught in Rust
<li> stuff that would be similar to C 113 content, but with Rust syntax
<li> practically: just a subset of even that
<li> no tuples if I can help it
<li> yes arrays, but no slices
</ul>

<h3> Compilers - What Are They and What Kinds of Compilers are Out There? </h3>

The purpose of a compiler is: to translate a program in some language (the
<i>source language</i>) into a lower-level language (the <i>target
language</i>).  The compiler itself is written in some language, called
the <i>implementation language</i>.  To write a compiler you have to be
very good at programming in the implementation language, and have to
think about and understand the source language and target language.<p>

There are several major kinds of compilers:

</p><dl>
<dt> Native Code Compiler
</dt><dd> Translates source code into hardware (assembly or machine code)
     instructions.  Example: gcc.

</dd><dt> Virtual Machine Compiler
</dt><dd> Translates source code into an abstract machine code, for execution
     by a virtual machine interpreter.  Example: javac.

</dd><dt> JIT Compiler
</dt><dd> Translates virtual machine code to native code.  Operates within
     a virtual machine. Example: Sun's HotSpot java machine.

</dd><dt> Preprocessor
</dt><dd> Translates source code into simpler or slightly lower level source code,
     for compilation by another compiler.  Examples: cpp, m4.

</dd><dt> Pure interpreter
</dt><dd> Executes source code on the fly, without generating machine code.
     Example: Lisp.
</dd></dl>

OK, so a pure interpreter is not really a compiler.  Here are some more tools,
by way of review, that compiler people might be directly concerned with, even
if they are not themselves compilers.
You should learn any of these terms that you don't already know.

<dl>
<dt> assembler
</dt><dd> a translator from human readable (ASCII text) files of machine
instructions into the actual binary code (object files) of a machine.
</dd><dt> linker
</dt><dd> a program that combines (multiple) object files to make an executable.
     Converts names of variables and functions to numbers (machine addresses).
</dd><dt> loader
</dt><dd> Program to load code.  On some systems, different executables start at
     different base addresses, so the loader must patch the executable with
     the actual base address of the executable.
</dd><dt> preprocessor
</dt><dd> Program that processes the source code before the compiler sees it.
     Usually, it implements macro expansion, but it can do much more.
</dd><dt> editor
</dt><dd> Editors may operate on plain text, or they may be wired into the rest
     of the compiler, highlighting syntax errors as you go, or allowing
     you to insert or delete entire syntax constructs at a time.
</dd><dt> debugger
</dt><dd> Program to help you see what's going on when your program runs.
     Can print the values of variables, show what procedure called what
     procedure to get where you are, run up to a particular line, run
     until a particular variable gets a special value, etc.
</dd><dt> profiler
</dt><dd> Program to help you see where your program is spending its time, so
     you can tell where you need to speed it up.
</dd></dl>



<h3> Phases of a Compiler </h3>

<table>
  <tr><td>
<img src="fig1-1.png" width=100>
<td>

<dl>
<dt>Lexical Analysis:</dt>
<dd>Converts a sequence of characters into words, or <i>tokens</i></dd>
<dt>Syntax Analysis:</dt>
<dd>Converts a sequence of tokens into a <i>parse tree</i></dd>
<dt>Semantic Analysis:</dt>
<dd>Manipulates parse tree to verify symbol and type information</dd>
<dt>Intermediate Code Generation:</dt>
<dd>Converts parse tree into a sequence of intermediate code instructions</dd>
<dt>Optimization:</dt>
<dd>Manipulates intermediate code to produce a more efficient program</dd>
<dt>Final Code Generation:</dt>
<dd>Translates intermediate code into final (machine/assembly) code</dd>
</dl>
</table>
</p><p>
</p>



<h3> Example of the Compilation Process </h3>

Consider the example statement; its translation to machine code
illustrates some of the issues involved in compiling.
<table border=""><tbody><tr><td><pre>position = initial + rate * 60
</pre></td></tr></tbody></table>
30 or so characters, from a single line of source code, are first
transformed by lexical analysis into a sequence of 7 tokens.  Those
tokens are then used to build a tree of height 4 during syntax analysis.
Semantic analysis may transform the tree into one of height 5, that
includes a type conversion necessary for real addition on an integer
operand.  Intermediate code generation uses a simple traversal
algorithm to linearize the tree back into
a sequence of machine-independent three-address-code instructions.
<p>
<table border=""><tbody><tr><td><pre>
  t1 = inttoreal(60)&nbsp;&nbsp;
  t2 = id<sub>3</sub> * t1
  t3 = id<sub>2</sub> + t2
  id<sub>1</sub> = t3</pre></td></tr></tbody></table>

</p><p>
Optimization of the intermediate code allows the four instructions to
be reduced to two machine-independent instructions.  Final code generation
might implement these two instructions using 5 machine instructions
in which the actual registers and addressing modes of the CPU are utilized
(left column). For comparison the right column shows the same computation
using a bytecode instruction set. Many bytecodes are stack-based and have
no registers.
</p><p>

  <table border=""><tbody>
<tr><th> native <th> VM
      <tr><td><pre>
  MOVF	id<sub>3</sub>, R2&nbsp;&nbsp;
  MULF	#60.0, R2
  MOVF	id<sub>2</sub>, R1
  ADDF	R2, R1
  MOVF	R1, id<sub>1</sub>
</pre>
	</td>
	<td><pre>
pnull   # push space for a result
var 0   # load a reference to var slot 0 (position)
pnull   # push space for a result
var 1   # load a reference to var slot 1 (initial)
pnull   # push space for a result
var 2   # load a reference to var slot 2 (rate)
int 0   # load a reference to constant slot 0 (60)
mult    # multiply top two references
plus    # add top two references
asgn    # assign value from top ref into next ref</pre>
      </tr>
</tbody></table>

<h3> Revision Controls Yes, Public Repositories No </h3>

It is sensible to use software engineering tools including revision control
systems such as git on a large project like writing a compiler.  On the
other hand it is not OK to share your work with your classmates,
intentionally or through stupidity, except where
teams are explicitly approved or assigned.
If you use a revision control system,
figure out how to make it private and share access only with approved
team members. Various options:
</p><ul>
<li> on github you setup private repositories, either for free or cheap
</li><li> you can use revision control with a local repository. setup is easy,
     but if you do this, figure out how to back up your work.
</li><li> you can figure out how to do git through ssh onto a department unix
     account
</li></ul>
<p>

<p>
<font size="1"> <a name="3">lecture #3</a> began here</font>
</p><p>

  <h3> Rust Reference </h3>

Have you found the <A href="https://doc.rust-lang.org/stable/reference/">
Rust Reference</A> yet?


<h3> Overview of Lexical Analysis </h3>

A lexical analyzer, also called a <em>scanner</em>, typically has the
following functionality and characteristics.

<ul>

<li> Its primary function is to convert from a (often very long) sequence of
characters into a (much shorter, perhaps 10X shorter) sequence of tokens.
This means less work for subsequent phases of the compiler.

</li><li> The scanner must Identify and Categorize specific character sequences
into tokens.  It must know whether every two adjacent characters in the file
belong together in the same token, or whether the second character must be
in a different token.

</li><li> Most lexical analyzers discard comments &amp; whitespace. In most
languages these characters serve to separate tokens from each other, but
once lexical analysis is completed they serve no purpose.  On the other
hand, the exact line # and/or column # may be useful in reporting errors,
so some record of what whitespace has occurred may be retained.  <em>Note:</em>
in some languages, even popular ones, whitespace is significant.

</li><li> Handle lexical errors (illegal characters, malformed tokens) by
reporting them intelligibly to the user.

</li><li> Efficiency is crucial; a scanner may perform elaborate input buffering

</li><li> Token categories can be (precisely, formally) specified using regular
expressions, e.g.
<pre>	 IDENTIFIER=[a-zA-Z][a-zA-Z0-9]*
</pre>

</li><li> Lexical Analyzers can be written by hand, or implemented automatically
using finite automata.
</li></ul>


</p><h3>A couple comments on the Lab for this course</h3>

<dl>
<dt> Labs start in earnest on Monday
  <dd>Generally they will run every Monday from 4-5pm after lecture
<dt> Main purpose of the lab: auxiliary public Q &amp; A and debugging help
     for your project. </dt><dd> Bring us your coredumps, your stack
     overflows, your
     huddled parse problems, yearning to breath free.
</dd><dt> Auxiliary purpose of the lab: extended practice with the
     professional tools of the course.
</dt><dd> For some of you, this part will be review.
</dd><dt> Format of the Labs
    <dd> Usually a public Q &amp; A followed by
     a lab exercise. <!-- The TA will run a lot of the labs.
     Sometimes the instructor may do the lab or they may team teach it.-->
</dt><dt> Grading of the Labs
</dt><dd> The Labs are to help you complete your real homework (project)
     assignments and will be a miniscule portion of your grade, treated
     comparable to quizzes. Let's say, the aggregate of all labs (and quizzes,
     if any) will amount to 5%. A given lab might be 0.3-0.5% and is
     likely to be graded on a boolean (you did it or not) scsale.
</dd></dl>


<h3> What is a "token" ?</h3>

In compilers, a "token" is:

<ol>
<li> a single word of source code input (a.k.a. "lexeme")
</li><li> an integer code that refers to (the category of) a single word of input
</li><li> a set of lexical attributes computed from a single word of input
</li><li> a struct (or object) that holds all those attributes
</li></ol>

Programmers think about all this in terms of #1. Syntax checking uses
#2. Error reporting, semantic analysis, and code generation require #3.  In
a compiler written in C, for each token you allocate a C struct to store (3)
for each token.

<h4> Auxiliary data structures </h4>

You were presented with the phases of the compiler, from lexical and syntax
analysis, through semantic analysis, and intermediate and final code 
generation.  Each phase has an input and an output to the next phase.
But there are a few data structures
we will build that  survive across multiple phases: the literal table,
the symbol table, and the error handler.

<dl>
<dt> lexeme table
</dt><dd> a table that stores lexeme values, such as strings and variable
     names, that may occur in many places.  Only one copy of each
     unique string and name needs to be allocated in memory.
     (This is an optional memory-saving device.)
</dd><dt> symbol tables
</dt><dd> symbol tables store the names defined (and visible within) each
     particular scope. The most common scopes are: global, and procedure
     (local).
     Real languages have more scopes such as class (or record)
     and package.
</dd><dt> error handlers
</dt><dd> errors in lexical, syntax, or semantic analysis need a common
     reporting mechanism, that shows where the error occurred (filename,
     line number, and maybe column number are useful). This may entail
     helper functions, global variables, or entire data structures.
</dd></dl>



<h3> Regular Expressions </h3>

The notation we use to precisely capture all the variations that a given
category of token may take are called "regular expressions" (or, less
formally, "patterns".  The word "pattern" is really vague and there are
lots of other notations for patterns besides regular expressions).
Regular expressions are a shorthand notation
for sets of strings.  In order to even talk about "strings" you have
to first define an <em>alphabet</em>, the set of characters which can
appear.

<ol>
<li> Epsilon (&#949;) is a regular expression denoting the set
     containing the empty string
</li><li> Any letter in the alphabet is also a regular expression denoting
     the set containing a one-letter string consisting of that letter.
</li><li> For regular expressions r and s, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r | s<br>
     is a regular expression denoting the union of r and s
</li><li> For regular expressions r and s, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r s<br>
     is a regular expression denoting the set of strings consisting of
     a member of r followed by a member of s
</li><li> For regular expression r, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r*<br>
     is a regular expression denoting the set of strings consisting of
     zero or more occurrences of r.
</li><li> You can parenthesize a regular expression to specify operator
     precedence (otherwise, alternation is like plus, concatenation
     is like times, and closure is like exponentiation)
</li></ol>



<h3> Lex/Flex Extended Regular Expressions </h3>

Although the basic regular expression operators given earlier
are sufficient to describe all regular languages,
in practice everybody uses extensions:

<ul>
<li> For regular expression r, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r+<br>
     is a regular expression denoting the set of strings consisting of
     one or more occurrences of r.  Equivalent to rr*
</li><li> For regular expression r, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r?<br>
     is a regular expression denoting the set of strings consisting of
     zero or one occurrence of r.  Equivalent to r|&#949;
</li><li> The notation [abc] is short for a|b|c.  [a-z] is short for a|b|...|z.
     [^abc] is short for: any character other than a, b, or c.
</li><li> The dot (.) operator matches any one char except newline. [^\n]
</li></ul>

Lex has a Lot of extended regular expressions.  I have listed the minimum
set that you are absolutely responsible for knowing. How many others do you
remember from reading the Flex manual?

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


<p>



</p><h3> Lex extended regular expressions </h3>

Here is an almost-complete list of Lex's regular expressions:

<dl>
<dt> c
</dt><dd> normal characters mean themselves
</dd><dt> \c
</dt><dd> backslash escapes remove the meaning from most operator characters.
     Inside character sets and quotes, backslash performs C-style escapes.
</dd><dt> "s"
</dt><dd> Double quotes mean to match the C string given as itself.
     This is particularly useful for multi-byte operators and may be
     more readable than using backslash multiple times.
</dd><dt> [s]
</dt><dd> This character set operator matches any one character among those in s.
</dd><dt> [^s]
</dt><dd> A negated-set matches any one character not among those in s.
</dd><dt> .
</dt><dd> The dot operator matches any one character except newline: [^\n]
</dd><dt> r*
</dt><dd> match r 0 or more times.
</dd><dt> r+
</dt><dd> match r 1 or more times.
</dd><dt> r?
</dt><dd> match r 0 or 1 time.
</dd><dt> r{m,n}
</dt><dd> match r between m and n times.
</dd><dt> r<sub>1</sub>r<sub>2</sub>
</dt><dd> concatenation. match r<sub>1</sub> followed by r<sub>2</sub>
</dd><dt> r<sub>1</sub>|r<sub>2</sub>
</dt><dd> alternation. match r<sub>1</sub> or r<sub>2</sub>
</dd><dt> (r)
</dt><dd> parentheses specify precedence but do not match anything
</dd><dt> r<sub>1</sub>/r<sub>2</sub>
</dt><dd> lookahead.  match r<sub>1</sub> when r<sub>2</sub> follows, without
     consuming r<sub>2</sub>
</dd><dt> ^r
</dt><dd> match r only when it occurs at the beginning of a line
</dd><dt> r$
</dt><dd> match r only when it occurs at the end of a line
</dd></dl>


<p>
<font size="1"> <a name="4">lecture #4</a> began here</font>
</p>

<h3> Rust of the Day</h3>

Since last class,

<ul>
<li> learned a bit about str vs. String types
<li> Rust is not object-oriented but...arguably it can be "object-based".
<li> Student response to Rust has ranged the full gamut from:
<ul>
  <li>      students who are beside themselves with joy, to
<li> students who are disconsolate and despairing
</ul>
That is OK. Maybe some of it is optimism vs. pessimism: is the glass
half-full, or half-empty?
There is some expectations management that we will need to do.

<li> No, you won't have to learn all of Rust, and you won't have to
  implement most of Rust this semester. Learn what you can.
  Implement what (the class determines) you must.

<li> Example: Rust macros are real exciting.  I haven't learned all there
  is to know about them.  Does an Irony compiler need to implement anything
  to do with macros?  Maybe yes, it seems to me we need a strategy for
  what we are going to do about
  println! and format! and maybe 1-2 more.  Does an Irony compiler need to
  implement a proper Rust macro processor?  No.

<LI> should I have gone with a different name, besides Irony?  e.g.
  <ul>
    <li> Runt, because it will be small
    <li> Ruse, because it only pretends to be like Rust
      <li> ...
      </ul>
  
  </ul>




<h3> Avoid Common Regex Bugs </h3>

Usually when doing your homework, you figure out if you messed up and fix it,
but it can bite you on exams

<dl>
<dt> square bracket abuse
</dt><dd> trying to use regex operators inside square brackets; trying to use
     square brackets as if they were parentheses
</dd><dt> good old fashioned operator precedence problems
</dt><dd> when in doubt, use parentheses
</dd><dt> writing a regular expression that is too loose
</dt><dd> be careful especially when using a regex that matches everything;
     you can read the entire file with one match.
</dd></dl>

<h3> Some Regular Expression Examples </h3>

Regular expressions are the preferred notation for
specifying patterns of characters that define token categories.  The best
way to get a feel for regular expressions is to see examples.  Note that
regular expressions form the basis for pattern matching in many UNIX tools
such as grep, awk, perl, etc. <p>

What is the regular expression for each of the different lexical items that
appear in C programs?  How does this compare with another, possibly simpler
programming language such as BASIC?  What are the corresponding rules for our
language this semester, are they the same as C?

<!--This is the first of many things where BASIC is somewhat easier 
to deal with than C.-->

<table border="">
<tbody><tr> <th> lexical category </th><th>Rust</th><th> BASIC </th><th> C <!--<th> Go--> </th></tr>
  <tr> <td> operators </td><td><td> the characters themselves <br>
      such as + or -
    </td><td> For operators that are regular expression operators we need mark them
     with double quotes or backslashes to indicate you mean the character,
     not the regular expression operator.  Note several operators have a
     common prefix. The lexical analyzer needs to look ahead to tell
     whether an = is an assignment, or is followed by another = for example.
<!-- <td> ??-->
 </td></tr>
<tr> <td> reserved words </td><td><td> the concatenation of characters; case insensitive </td><td>
     Reserved words are also matched by the regular expression for identifiers,
     so a disambiguating rule is needed.
<!-- <td> ??-->
</td></tr>

<tr>
<td> identifiers </td><td><td> no _; $ at ends of some; 2 significant letters!?; case insensitive </td><td> [a-zA-Z_][a-zA-Z0-9_]*
<!-- <td> Same a C; only difference is that starting with a Capital specifies
public members of a package. -->
</td></tr>

<tr>
<td> numbers </td><td><td> ints and reals, starting with [0-9]+ </td><td> 0x[0-9a-fA-F]+ etc.
<!-- <td> Go has C literals, plus imaginary/complex numbers.-->
</td></tr>

<tr> <td> comments </td><td><td> REM.* </td><td> C's comments are tricky regexp's
<!-- <td> ??-->

</td></tr>

<tr> <td> strings </td><td><td> almost ".*"; no escapes </td><td> escaped quotes
<!-- <td> ??-->

</td></tr><tr> <td> what else?
<!-- <td> ??-->

</td></tr></tbody></table>

</p>
<p>

<h3> What are the Best Regular Expressions you can Write for Language X ?</h3>

What corrections/improvements/additions are needed in the following?
Note that the full ANSI C language would entail a lot of additions.
What additions are needed for the your compiler's subset language
this semester?
<p>

<table border="">
<tbody><tr> <th> Category </th><th> Regular Expression
</th></tr><tr> <td> Variable names </td><td> [a-zA-Z_][a-zA-Z0-9_]*
</td></tr><tr> <td> Integer constants </td><td> "-"?[0-9]+ | "0x"[0-9A-Fa-f]+
</td></tr><tr> <td> Real # Constants </td><td> [0-9]*"."[0-9]+
</td></tr><tr> <td> String Constants </td><td> \"([^"\n]|("\\\""))*\"
</td></tr></tbody></table>

</p><p>


</p><h3> Lexing Reals </h3>

C float and double constants have to have at least one digit, either
before or after the required decimal.  This is a pain:
<pre>([0-9]+.[0-9]* | [0-9]*.[0-9]+) ...
</pre>

You might almost be happier if you wrote

<pre>([0-9]*.[0-9]*)    { return (strcmp(yytext,".")) ? REAL : PERIOD; }
</pre>

Starring: C's ternary operator <code>e1 ? e2 : e3</code> is an if-then-else
expression, very slick.  Note that if you have to support
scientific/exponential real numbers (JSON does), you'll need a bigger regex.



<!--
<h3> Introductory Comments on BASIC </h3>

We are doing (a large subset of) TRS-80 Color Computer Extended BASIC.
Compared with last semester, you will get more help from me on getting
started with each assignment, and be asked to do a little more.

<li>  The main language reference manuals are on our class web page...

<li> I am writing my own commentary on it 
<A href="basic.html">
basic.html</A>
where most of your formal specifications will appear.

<li> I have made a start at some pseudocode
<A href="basic.icn">basic.icn</A>
for the "interpreter loop" that will wrap around your compiler.
-->


<h3> Lexical Attributes and Token Objects </h3>

Besides the token's category, the rest of the compiler may need several
pieces of information about a token in order to perform semantic analysis,
code generation, and error handling. 

A <em>lexical attribute</em> is a piece of information about a token.  These
typically include:

<table>
<tbody><tr><td> category </td><td> an integer code used to check syntax
</td></tr><tr><td> lexeme </td><td> actual string contents of the token
</td></tr><tr><td> line, column, file </td><td> where the lexeme occurs in source code
</td></tr><tr><td> value </td><td> for literals, the binary data they represent
</td></tr></tbody></table>


These are stored in an object instance of class Token, or in C, a struct.
The fields are generally something like:

<pre>struct token {
   int category;
   char *text;
   int linenumber;
   int column;
   char *filename;
   union literal value;
}
</pre>

The union literal will hold computed values of integers, real numbers, and
strings.  <em>In your homework assignment, I am requiring you to compute
column #'s; not all compilers require them, but they are easy.  Also: in
our compiler project we are not worrying about optimizing our use of memory,
so am not requiring you to use a union</em>.

<p>


<!--
<h3> Seating Chart (in-person section) </h3>

Please space yourself out, and adhere to this seating in future sessions of
this class, to minimize close-contact tracking and quarantining
requirements.  Thanks!
-->


<h3> Comments </h3>

<ul>
<li> C-style multi-line comments?  Any flaws in this one?
  <pre>

"/*"([^*]|"*"+[^/*])*"*"+"/"

  </pre>

<li> It turns out the finite automaton for them is easy!
<li> Getting the regex all-the-way correct is hard enough that some books
     recommend cheating* on this part of your flex specification.
     (*Cheating in this context means, resorting to a non-regular-expression
      method.)
</ul>
  <p>

    <ul>
      <li> Now, how about Python comments? Do we need anything more than:
	<pre>
"#".*
	  </pre>
      </ul>



<h3> Observation </h3>

Of the 50-100 or so categories of things that appear in the source code of
most programming languages, maybe 90% of them are trivial and can be
achieved by just putting the exact lexeme in double quotes, such as "while"
or "&lt;&lt;".  The remaining 10% are usually the identiers (variable names)
and various literal constants.  But what are the <em>exact</em> rules for
those?

<p>
<font size="1"> <a name="5">lecture #5</a> began here</font>
</p><p>

We spent 1/26/24 going over <A href="hw2.html">HW#2</A>

<p>
<font size="1"> <a name="6">lecture #6</a> began here</font>
</p><p>

<h4>Mailbag</h4>
<dl>
<dt>

I've gotten most of the rules for the lexer down, and everything that I've
tested so far seems to be working as expected, with one notable exception:
tokens that are not whitespace separated...  I've noticed that (my) Flex
(scanner) seems to identify matches if and only if they are separated by
whitespace from other tokens; i.e., while `a + b` registers as
IDENT/PLUS/IDENT, its counterpart `a+b` is read as a single entity...

I must be missing something about the way flex's regex works which is
causing this behavior. Would you happen to have any ideas on what I could do
to address this?

<dd>

No regular expression in Rust should allow the pattern a+b as a match.
Show me your regular expression that matches a+b and I will be happy
to debug it for you.  But maybe, knowing that it should not match those
characters, you can debug it yourself.

<dt> I spent some time attempting to add elements of HW#2 to my lab1 and I
ran into a problem when I tried to return the struct I created since yylex()
returns an int and not a struct(). Maybe I misinterpreted the homework
instructions but can we go over how we get yylex to return a struct in
class?

<dd> yylex() returns an int.  The token structure should be left in a
global variable for main to pick up. In HW2 it says to use a variable named
<code>yytoken</code>. Later we will leave it in a global variable dictated
to us by the bison parser generator.

</dl>

<h4> Avoid These Common Bugs in Your Homeworks and Labs! </h4>

<ol>
<li> yytext or yyinput were not declared global
</li><li> main() does not have its required argc, argv parameters!
</li><li> main() does not call yylex() in a loop or check its return value
</li><li> getc() EOF handling is missing or wrong!  check EVERY all to getc() for EOF!
</li><li> opened files not (all) closed! file handle leak!
</li><li> end-of-comment code doesn't check for */
</li><li> yylex() is not doing the file reading
</li><li> yylex() does not skip multiple spaces, mishandles spaces at the front
     of input, or <em>requires</em> certain spaces in order to function OK
</li><li> extra or bogus output not in assignment spec
</li><li> = instead of ==
</li></ol>

<!--
<h3> Language Candidates </h3>

Hypothesize that "it would be wise" for us to choose a language subset project
that is defined by somebody and NOT to make up one from scratch.  FYI: Python
does not have a widely-available YACC parser; Ruby apparently does.

<dl>
<dt> C-based: C-minus-minus
<dd> Pro: familiar.  Con: boring.  And name overloaded by multiple groups.
     Difference from Heckendorn: I will make you target x86_64 assembler.
<dt> Java-based: <A href="http://BantamJava.com"> BantamJava </A> or <A href="http://www2.cs.uidaho.edu/~jeffery/godiva/">Godiva-0</A>
<dd> Pro: Java knowledge is useful.
<dt> TRS-80 Extended Color BASIC
<dd> Pro: can run cool 80's games on it.  Con: BASIC is so last-century
<dt> Ruby-based
<dd> Pro: cool.  Con: ill-defined.  Would we just copy and study the existing
     implementation?  Blah
<dt> Plzero (Pascal language 0, I think)
<dd> Pro: I am sure I have a copy lying around that is newer than the one at
      <A href="http://www.moorecad.com/standardpascal/plzero.pas">moorecad</A>.
<dt> Unicon-based
<dd> Pro: Jeffery knows it inside and out. Con: who cares about Unicon?
</dl>
-->


<h3> What, again with the <tt>lex(1)</tt> and <tt>flex(1)</tt>? </h3>

These programs generally take a lexical specification given in a .l file
and create a corresponding C language lexical analyzer in a file named
<code>lex.yy.c</code>.  The lexical analyzer is then linked with the rest
of your compiler.
<p>

The C code generated by lex has the following public interface.  Note the
use of global variables instead of parameters, and the use of the prefix
yy to distinguish scanner names from your program names.  This prefix is
also used in the YACC parser generator.
</p><pre>FILE *yyin;	/* set this variable prior to calling yylex() */
int yylex();	/* call this function once for each token */
char yytext[];	/* yylex() writes the token's lexeme to an array */
                /* note: with flex, I believe extern declarations must read
                   extern char *yytext;
                 */
int yywrap();   /* called by lex when it hits end-of-file; see below */
</pre>
<p>

The .l file format consists of a mixture of lex syntax and C code fragments.
The percent sign (%) is used to signify lex elements.  The whole file is
divided into three sections separated by %%:
</p><pre>   header
%%
   body
%%
   helper functions
</pre>
<p>

The header consists of C code fragments enclosed in %{ and %} as well as
macro definitions consisting of a name and a regular expression denoted
by that name.  lex macros are invoked explicitly by enclosing the
macro name in curly braces.  Following are some example lex macros.
</p><pre>letter		[a-zA-Z]
digit		[0-9]
ident		{letter}({letter}|{digit})*
</pre>
<p>

</p><blockquote>
<em>A friendly warning: the UNIX/Linux/MacOS Flex tool is NOT
good at handling input files saved in MS-DOS/Windows format, with
carriage returns before each newline character.  Some browsers,
copy/paste tools, and text editors might add these carriage returns
without you even seeing them, and then you might end up in Flex Hell
with cryptic error messages for no visible reason. Download with
care, edit with precision. If you need to get rid of carriage returns
there are lots of tools for that. You can even build them into your
makefile. The most classic UNIX tool for that task is tr(1), the
character translation utility</em>
</blockquote>


<h3> Flex Header Section syntax </h3>

<ul>
<li> <code>%{</code>   and  <code>%}</code>  mark off any C code
that is to be passed through into the top of the generated lex.yy.c
file.
</li><li>  Flex might otherwise think you are defining a macro.
</li><li>  Lex's
syntax is bluntly fast and loose and it will give you cryptic error
messages, or no error messages, if you take any liberties.
</li></ul>

<h3> Flex Body Section </h3>

The body consists of a sequence of regular expressions for different
token categories and other lexical entities.

<ul>
<li> Each regular expression can
have a (C) code fragment enclosed in curly braces that executes when that
regular expression is matched.
</li><li> For most of the regular expressions the 
code fragment (called a <em>semantic action</em>) consists of returning
an integer that identifies the token category to the rest of the compiler.
It is used by the parser to check syntax.
</li><li>  Some typical regular
expressions and semantic actions might include:

<pre>" "		{ /* no-op, discard whitespace */ }
{ident}		{ return IDENTIFIER; }
"*"		{ return ASTERISK; }
"."		{ return PERIOD; }
</pre>

</li><li> You also need regular expressions for lexical errors such as unterminated
character constants, or illegal characters.

</li><li>  If your semantic action executes a return, yylex() is done and has to
be called again by the surrounding code. If there is no semantic action or it
does not return, yylex() resumes scanning looking for a new regular expression
after the action code completes.

</li><li> If NO regular expression will match at a given point, yylex() literally
just advances and prints one character to standard out, and restarts the scan
at the next character.

</li><li> If two or more regular expressions match, yylex() uses the longest match
</li><li> If two or more regular expressions match at the same longest length
    possible, yylex() just uses whichever one appears first in the .l file

</li></ul>
<p>

Actually, your semantic actions in a compiler will do more than just
return the category code.
</p><ul>
<li> Helper functions can be called from the actions in a lex file
body section
</li><li> Helper functions typically compute lexical attributes,
such as the actual integer or string values denoted by literals.
</li><li> One helper function that is required is yywrap(), which is called when lex
hits end of file.  If you just want lex to quit, have yywrap() return 1.
If your yywrap() switches yyin to a different file and you want lex to continue
processing, have yywrap() return 0.
</li><li> On some systems, a "lex library" or "flex library" (-ll or -lfl)
provides a default <code>yywrap()</code> function that return a 1
</li><li> Flex has the directive
<code>%option noyywrap</code> which allows you to skip writing this function.
</li><li>
You can avoid a similar warning for an unused unput() function by saying
<code>%option nounput</code>.
</li></ul>
<p>

Note: other platforms with working Flex installs (including
some versions of CENTOS)
do not have a flex library, neither <code>-ll</code> nor
<code>-lfl</code>. Use <code>%option</code> directives
or provide your own functions instead of expecting <code>-lfl</code>
to be present.  Example:
</p><pre>%{
#include &lt;stdio.h&gt;
%}
%option noyywrap
%%
"abc"	{ printf("!!!"); }
%%
int main()
{
   yyin = stdin;
   return yylex();
}
</pre>

<h3> Lexical Error Handling </h3>

<ul>
<li> Really, two kinds of lexical errors: nonsense, and stuff in the base
     language that's not in our subset of that language.
</li><li> Include file name and line number in your error messages.
</li><li> Avoid cascading error messages -- only print the first one you see
     on a given line/function/source file.
</li><li> You can write regular expressions for common errors, in order
     to give a better message than "lexical error" or "unrecognized character".
     (This is how you should approach stuff in the base language but not our
     subset.)
</li></ul>







Welcome to the lecture that tests the hypothesis that Jeffery could teach
entire classes just by answering (current and past) students' questions.

<h3> Mailbag</h3>

<dl>
<dt> So do I (have to) count words, or not?
<dd> Lab #1 asked you to adapt a word count program to turn it into a
  mini-scanner. It asked you to count words.  HW #2 asks you to finish the job
  of writing a scanner. I don't think it asks you to count words any
  more, but it asks you to count lines and store line numbers in each token.
<!--
<dt> How do I distinguish newlines that continue a previous line from
    newlines that start a new line?
<dd> Well, in terms of regular expressions in your Flex spec, maybe:
<pre>
"\\\n"		{ /* code to continue a line, no logical LINE token */ }
"\n"		{ return NEWLINE; }
</pre>
-->
<!--
<dt> When do I count indentation levels?
<dd> Separate regular expressions for whitespace when at the start of a line
   and whitespace when not at the start of a line. 
<pre>
^[ \t]+         { /* whitespace at the start of a line, calc indents */ }
[ \t]+          { /* whitespace not at the start of a line, discard */ }
</pre>

<dt> So how do I count indentation levels
  <dd> 
Maybe something like
<pre>
int indentlevel(char *s)
{      
   column = 1;
   while(*s != '\0') {
      if (*s == '\t') {
         while ((column % 8) != 0) column++;
      }
      else column++;
      s++;
   }
   return column;
}
</pre>
but no guarantees on that. It is not like I tested it.
-->

<!--
<dt> I've heard of <code>malloc()</code>, but I haven't had any real experience
     working with it.
<dd> <code>malloc()</code>, <code>calloc()</code> and <code>realloc()</code>
     are a flexible memory management
     API for C that corresponds roughly to <code>new</code> keyword in C++
     or Java.  The <code>malloc()</code> family allows you to
     allocate memory generically by # of bytes, independent of the type
     system. This capability is powerful but dangerous.
-->

<!--
<dt> How do I return a "fake" token, e.g. INDENT and DEDENT
<dd>

For a token that is not directly based on regular expression content,
you may allocate a struct/object instance for it, fill in its
fields, put something (even an empty string?) as its lexeme/string,
and return the integer code for it from the yylex() function.  
If you were on a regex that didn't (otherwise) have to return its own
token, then you are good.  If it did have a token but you need to return
a "fake" token to be seen first, then you have to <em>save</em> the actual
token in some global variable and return it later from a separate call to
yylex(). See below.
    
<dt> How do I return <em>several</em> DEDENT's after matching some
     leading whitespace?
<dd> It is one thing to implement the stack of integers...it is another thing
  to enable yylex() to remember a bunch of saved DEDENT tokens and return
  them before moving on to the next thing after the whitespace.  For that,
  you may want to use a wrapper function around the yylex() that reads from
  the saved tokens before calling the "real" flex yylex() to move forward.
  I have literally written makefile rules that after flex runs, its output
  function is renamed to yylex2(), and then a yylex() wrapper looks like:
<pre>
  int yylex()
  {
     /* if saved tokens are on a saved token (DEDENT) stack, return top one */
     /* else return yylex2() */
  }
</pre>
-->


<dt> What should the lexical analyzer look like?  where do I start?
</dt><dd> In Homework #2 you learn to use a declarative language called
     Flex which does almost all the work for you. The only design
     issue is how does it interact with the rest of the compiler, i.e.
     its public interface. This is mostly hardwired/designed for you
     by Flex. Your only customization option is in what form to make token
     information available to the later phases of the compiler.

</dd><dt> How should our output be visible?
</dt><dd> One human readable output line, per token, as shown in hw2.html
     Build the linked list first, then walk it (visit all nodes) to
     print the output. Figure out how to do this so output is in the
     correct order and not reversed!

</dd><dt> You mention storing the int and double as binary. That just means
     storing them in int and double variables, correct?
</dt><dd> It means for constants you have to convert from the lexeme string
     that actually appears in the source code to the value (int, double)
     and then store the result in the corresponding lexical attribute
     variable.

</dd><dt> When do you use <code>extern</code> and when do you use
     <code>#include</code> in C programming?
</dt><dd> <code>extern</code> can be done without an <code>#include</code>,
    to tell one module
    about global variables defined in another module. But if you are
    going to share that <code>extern</code> with multiple modules, it
    is best to put it in an <code>#include</code>.
    More generally, use <code>#include</code> in order to share types,
    externs, function prototypes,
    and symbolic <code>#define</code>'s across multiple files. That is all.
    No code, which is to say, no function bodies.
</dd><dt> Can I add parameters to <code>yylex()</code>?
</dt><dd> No, you can't add your own parameters, <code>yylex()</code> is a
     public interface.
     You might be tempted to
    add some parameters to tell it what filename it is reading from, or
    other such stuff.
     But you can't.  Leave <code>yylex()</code>'s interface alone,
     the parser will call it with its current interface.
    <dt> Can I change yylex()'s return type to return a <code>struct token *</code>?
      <dd> No, you can't change yylex()'s return type, <code>yylex()</code> is
	a public interface.
	You might be tempted to return a token structure pointer. Heck, the
	Jflex that we use wants yylex() to return a class
	instance by default.  But this isn't about what you or JFlex wants.
	It is about what the parser wants. The parser wants an integer
	category, which it interprets as a <em>Terminal Symbol</em> in
	its grammar. Give the parser what it wants.

<dt> There are bugs in your <A href="ironyref.html">ironyref.html</A> file
<dd> Please report issues. Also, think of the specification document as
     a negotiable contract.  If it is missing something that you did well in
     HW#1, has something that shouldn't be there, or needs corrections or
     clarifications, ask for them. English is notoriously ambiguous, and I
     am on a tight time budget.  Especially when it comes to Level Two and
     Level Three, I may be missing or inconsistent or we may need to
     negotiate, because I haven't traditionally run my compiler classes as
     team projects like I do with my software engineering courses.
<dt> Do you want us to have a .h file for enumerating all the different
     kind of tokens for HW 2? I was looking into flex and bison and it
     looks like bison creates a tab.h file that does this automatically.
</dt><dd> Yes. In HW2 it would be best if you create a .h file for these
     #defines; plan to throw it
     away in favor of the one Bison creates for you in HW#3.
</dd>
</dl>


<dl>

<dt> Will you always call "make" on our submissions?
</dt><dd> Yes. I expect you to use make and provide a makefile in each
     homework. Turn in the whole source, not just "changed" or
     "new" files for some assignments. My script will
     unpack your .zip file by saying "unzip" in some new test directory
     and then run "make" and then run your executable. If
     anything goes wrong (say, you unzipping into a subdirectory the script
     does not know the name of) you will lose a few points.
<br><br>
     On the other hand, I do not want the tool-generated files
     (lex.yy.c, cgram.tab.c) or .o or executables.  The makefile should
     contain correct dependencies to rerun flex (and later, bison) and
     generate these files whenever source (.l, .y , etc.) files are changed.

</dd><dt>

When creating the linked list I see that you have a struct token and a
struct tokenlist. Should I create my linked list this way or can I eliminate
the struct tokenlist and add a next pointer inside struct token(struct token
*next) and use that to connect my linked list?

</dt><dd>

The organization I specified - with two separate structs - was very
intentional. Next homework, we need the struct tokens that we allocate from
inside yylex(), but not the struct tokenlist that you allocate from outside
yylex(). You can do anything you want with the linked list structure, but
the struct token must be kept more-or-less as-is, and allocated inside
yylex() before it returns each time.

</dd><dt> I was wondering if we should have a different code for each keyword or just have a 'validkeyword' code and an 'invalidkeyword' code.
</dt><dd>  Generally, you need a different code for two keywords if and when they are used in different positions in the syntax.  For example, int and float are type names and are used in the same situations,  but the keywords func and if, denoting the beginning of a function and the beginning of a conditional expression, have different syntax rules and need different integer codes.

</dd><dt> In the specification for assignment 1 it says that
     if there is no extension given, we should add the required extension
     to the filename.
     Should we still accept and run our compiler on other file extensions
     that could be provided or should we return an error of some sort?
</dt><dd> Accept no other extensions. If any file has an illegal extension,
     you can stop with a message like: "Usage: fec [options] filename[.rs] ..."
</dd><dt> how am i supposed to import the lexer into my main.c file?
</dt><dd> Do not <code>import</code> or <code>#include</code> your lexer.
     Instead,
     link your lexer into the executable, and tell <code>main()</code>
     how to call it, by providing a prototype for <code>yylex()</code>.
     If <code>yylex()</code>
     sets any global variables (it does), you'd declare those as
     <code>extern</code>. You can do prototypes and externs in main.c,
     but these things are exactly what header (.h) files were invented for.
</dd><dt> Is the <code>struct token</code> supposed to be in our
     <code>main()</code>? Do we use <code>yylex()</code>
     along with other variables within lex.yy.c to fill the "struct token" with
     the required information?

</dt><dd> Rather than overwriting a global struct each time, a <em>pointer</em>
    to a struct token should be in <code>main()</code>.
    Function <code>yylex()</code> should allocate a struct token, fill it,
    and make it visible to <code>main()</code>, probably by assigning its
    address to some global pointer variable. Function <code>main()</code>
    should build the linked list in a loop, calling <code>yylex()</code> each
    time through the loop. It should then print the output by looping through
    the linked list.

<!--<dt> Proposed regex solution
<dd> How about this (amalgamated) student proposed solution:
<pre>
"/*"(("*"+[^/*])|[^*]+)*"*"+"/"
</pre>
Correct or not?  If incorrect, give example where it fails.
Can it match <code>/* this **/ regex here*/</code>
-->

<!--
<dt> Discussion of include stacks. Thank you to the student contributor of
this example:
<dd>
<pre>
Here's the code I'm using to push/pop the lexer state.
It uses a couple of user-defined functions and a struct
to store auxiliary information such as the filename,
but the rest are standard C/flex functions.

/*
 * Return 1 if done, 0 if yyin points at more input
 */
int yywrap() {
    // Is the state stack empty?
    if(include_stack == NULL) {
        return 1;
    } else {
        fclose(yyin);

        // Grab the previous input file from the state stack.
        yypop_buffer_state();
        SourceFileState state = pop_file_state(&include_stack);
        filename = state.filename;
        line_num = state.line_num;
        return 0;
    }
}

/*
 * Handles a "user" include directive (using double quotes)
 */
static void handle_user_include() {
    char *fname = strchr(yytext, '\"')+1;
    fname[strlen(fname)-1] = '\0';
    fname = strdup(fname);

    FILE* input_file = fopen(fname, "r");
    if(!input_file) {
        fprintf(stderr, "Unable to open include file %s: ", fname);
        perror("");
        exit(1);
    }

    // Push flex's internal buffer state.
    yypush_buffer_state(yy_create_buffer(input_file, YY_BUF_SIZE));
    // Push "auxiliary" file data.
    push_file_state(&include_stack, filename, line_num);
    filename = fname;
    line_num = 1;
}
</pre>

<A href="http://westes.github.io/flex/manual/Multiple-Input-Buffers.html#Multiple-Input-Buffers">Section 11 of the Flex manual</A> discusses functions such as
yypush_buffer_state().
-->

<dt> When I compile my homework, my executable is named a.out, not what
     our compiler is supposed to be named!  What do I do?
</dt><dd> Some of you who are less familiar with Linux should read the
     "manual pages" for gcc, make, etc.  gcc has a -o option, that would work.
     Or in your makefile you could rename the file after building it.

</dd><dt> Can I use flex start conditions?
</dt><dd> Yes, if you need to, feel free.

</dd><dt> Can I have an extension?
</dt><dd> Yeah, but the further you fall behind, the more zeroes you end up with
     for assignments that you don't do.
     Late homeworks are accepted with a penalty per day (includes
     weekend days) except in the case of a valid excused absence.
     The penalty starts at 10% per day (HW#2), and reduces by 2% per
     assignment (8%/day for HW#3, 6%/day for HW#4, 4%/day for HW#5,
     and 2%/day for HW#6).  I reserve the right to underpenalize.

</dd><dt> Do you accept and regrade resubmissions?
</dt><dd> Submissions are normally graded by a script in a batch.
     Generally, if an initial submission was a fail, I might accept a
     resubmission for partial credit up to a passing (D) grade.  If a
     submission fails for a trivial reason such as a missing file, I might
     ask you to resubmit with a lighter penalty.

</dd><dt> I have not been able to figure out how sscanf() will help me. Could you
     point me to an example or documentation.
</dt><dd> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/sscanf.c.html">Yes</a>. Note that sscanf'ing into a double calls
     for a %lg.

</dd><dt> What is wrong with my commandline argument code.
</dt><dd> If it is not that you are overwriting the existing arrays with strcat()
     instead of allocating new larger arrays in order to hold new longer
     strings, then it is probably that you are using sizeof() instead of
     strlen().

</dd><dt> Can you go over using the %array vs. the standard %pointer option
     and if there are any potential benefits of using %array?
     I was curious to see if you could use YYLMAX in junction
     with %array to limit the size of identifiers, but there is
     a probably a better way.
</dt><dd> After yylex() returns,
     the actual input characters matched are available as a string named
     yytext, and the number of input symbols matched are in yyleng.  But is
     yytext a char * or an array of char?  Usually it doesn't matter in C,
     but <em>I personally have worked on a compiler where declaring an extern
     for yytext in my other modules, and using the wrong one, caused a crash.</em>
     Flex has both pointer and array implementations available via %array
     and %pointer declarations, so your compiler can use either.  YYLMAX
     is not a Flex thing, sorry. How do <em>you</em> think you should limit
     the length of identifiers?  Incidentally: I am astonished, to read
     claims that the Flex scanner buffer doesn't automatically increase
     in size as needed, and might be limited by default to 8K or so regexes.
     If you write open-ended regular expressions, but might be advisable
     in this day of big memory to say something like
<pre>	i=stat(filename,&amp;st);
	yyin=fopen(filename,"r");
	yy_current_buffer = yy_create_buffer(yyin, st.st_size);
</pre>
     to set flex so that it cannot experience buffer overrun. By the way,
     Be sure to
     check ALL your C library calls for error returns in this class!

<!--
<dt> The O'Reilly book recommended using Flex states instead of that big
     regular expression for C comments.  Is that reasonable?
<dd> You may implement the most elegant correct answer you can
     devise, not just what you see in class. If you use something from
     anywhere other than our course texts, you must cite it!
-->
<dt> Are we free to explore non-optimal solutions?
<dd> I do not want to read lots of extra pages of junk code, but you are free
     to explore alternatives and submit the most elegant solution you come
     up with, regardless of its optimality. Note that there are some parts
     of the implementation that I might mandate. For example, the symbol table
     is best done as a hash table. You could use some other fancy data
     structure that you love, but if you give me a linked list I will be
     disappointed. Then again, a working linked list implementation would get
     more points than a failed complicated implementation.
<dt> Is it OK to allocate a token structure inside main() after yylex()
     returns the token?

<dd> No. In the next phase of your compiler, you will not call
<code>yylex()</code>, the Bison-generated parser will call
<code>yylex()</code>.  There is a way for
the parser to grab your token if you've stored it in a global variable,
but there is not a way for the parser to build the token structure itself.
However you <em>are</em> expected to allocate the linked list nodes in main(), and
in the next homework that linked list will be discarded. Don't get attached.

<dt> My tokens' "text" field in my linked list are all messed up when I go
     back through the list at the end. What do I do?
<dd> Remember to make a physical copy of <code>yytext</code> each token,
     because it overwrites itself each time it matches a regular expression
     in <code>yylex()</code>.  Typically a physical copy of a C string is
     made using <code>strdup()</code>, which is a <code>malloc()</code>
     followed by <code>strcpy()</code>.

<!--
<dt> C++ concatenates adjacent string literals, e.g. "Hello" " world"
Does our lexer need to do that?
<dd>
No, you do not have to do it.
But if you did, can you think of a way to get the job done without too
much pain?
It could be done in the lexer, in the parser, or sneakily in-between.
Be careful to consider 3+ adjacent string literals
("Hello" " world, " "how are you" and so on)
-->

<dt> How do I handle escapes in svals? Do I need to worry about more than
\n \t \\ and \r?
<dd>
You replace the two-or-more characters with a single, encoded character.
'\\' followed by 'n' become a control-J character.  We need
\n \t \\ and \" -- these are ubiquitous.
You can do additional ones like \r but they are not required and
will not be tested.
</dl>


<p>
<font size="1"> <a name="7">lecture #7</a> began here</font>
<p>

<h3> Questions about Flex HW </h3>

<ul>
  <li> Your HW is due When, again?  FEBRUARY 6 11:59pm
  <li> Do you have any questions?
</ul>

<h3> Irony naming </h3>

Boy am I glad we didn't try to name ourselves "Oxide",
because <A href="https://arxiv.org/pdf/1903.00982.pdf">
	  these blokes</A> already took that name.


<h3> Brief Comments about Lab #1 Grading</h3>

<ul>
  <li> Labs are almost credit/no-credit
  <li>Smallest Lab #1 zip was 2,610 bytes; the largest was a 2,740,188 byte
    .zip file.
  <li> I do not want your .git/ or .vs/ junk in your lab submission.
    So from lab #2 forward, if you include extraneous files, I'll dock a point.
    <li>
    If you are in doubt about whether to include a file, ask.
  </ul>

<h3> Mailbag </h3>
<dl>
<dt> Can you explain ival/dval/sval again?  What should the output look like?
  <dd> Source code is strings of characters from some source file.
    ival/dval/sval are lexical attributes that contain the values
    denoted by corresponding literal constants.  For literal constants
    ONLY, you compute an ival, dval, or sval (or cval).  Mostly it
    means converting from the string to what the string means. For
    an ival it might be a call to atoi(). For dval perhaps something
    similar. For sval, I think you have to go character by character
    through the string and "de-escape" it.
    The output for ival should look like the yytext did.  The output
    for dval should look like a real number that is really close to
    the input, but is often off by .000001 or whatever. The output
    for sval has the double quotes removed and any escape characters
    have become their true selves, which are usually some non-printing
    control character that affects output appearance.

<dt> Reserved words were not in your list of tokens on hw2.html, do we
  have to implement integer categories for them.
<dd> Yes. Except for ones that are not in PunY, maybe.

<!--
<dt> Does HW#1 expect semi-colon insertion? It is not mentioned in the hw1
description but is in the spec.
<dd> We will need <A href="https://golang.org/ref/spec#Semicolons">semi-colon insertion</A> for HW#2 but it is not required for HW#1. Let's discuss.
-->

<!--
<dt> I was trying to come up with a regular expression for runes that are accep
<dd> The full Go literals spec is <A href="https://golang.org/ref/spec#Rune_literals">here</A>.
VGo rune literals are basically C/C++ char literals. A VGo lexical
analyzer might want to start with a regex for a char literal, and then
add regex'es for things that are legal Go and not legal VGo.  Here are
examples. There are also octal and hex escapes legal in Go but not in VGo.<br>

<table border>
<tr><th>Regex <th> Interpretation
<tr><td>
<code>"'"[^\\\n]"'"</code> <td> initial attempt at normal non-escaped runes
<tr><td>
<code>"'\\"[nt\\']"'"</code> <td> a few legal VGo escaped runes
<tr><td>
<code>"'\\"[abfrv]"'"</code> <td> legal in Go not in VGo escaped runes
<tr><td>
<code>"'\\u"[0-9a-fA-F]{4}"'"</code> <td> legal in Go not in VGo
<tr><td>
<code>"'\\U"[0-9a-fA-F]{8}"'"</code> <td> legal in Go not in VGo
</table>
-->

</dd><dt> You mentioned that the next homework assignment, we won't be calling
<code>yylex()</code> from <code>main()</code> (which is why you previously
mentioned you cannot allocate the token structure in <code>main()</code>).
I have followed that rule,
but I question how will linked lists be set up in the next homework then?

</dt><dd> In the next HW, the linked list will be subsumed/replaced by you
building a tree data
structure. If you built a linked list inside <code>yylex()</code>, that
would be a harmless waste of time and space and could be left in place.
If you malloc'ed the token structs inside <code>yylex()</code> but
built the linked list in your <code>main()</code>, your linked list
will just go away in the next HW when we modify <code>main()</code> to call
the Bison parser function <code>yyparse()</code> instead of the loop
that repeatedly calls <code>yylex()</code>.

</dd><dt> Can you test my scanner and see if I get an "A"?
</dt><dd> No.
</dd><dt> Can you post tests so I can see if my scanner gets an "A"?
</dt><dd> If you share tests that you devise, for example
     when you have questions, I will add them to a public collection
  for use by the class. BTW, test cases are a great example of
  something that one might find on the internet, and use with proper
  citation. Compilers often have validation test suites, a public one
  might exist for Rust.  I started googling things like
  <pre>
    "Rust compiler" lexical test suite  </pre>
  and maybe there is something in there. Tests of some kind.
  CITE anything you find and use.
  Did you see the <A href="https://rustc-dev-guide.rust-lang.org/the-parser.html">Rust Compiler Development Guide's section on Lexing and Parsing</A>?
  
</dd><dt> So if I run OK on a few sample files, do I get an "A"?
</dt><dd> Maybe.
     You should devise coverage tests to hit all described features.

<!--
<dt>
Each time a regular <em>user-written</em> include file is "handled",
we must stop the current yyin file (and save it), and open this new
file and assigning it yyin, and read from the user-defined include
file. Once we finish with the include file, do we have to go back
(somehow) to where yylex was reading from the original yyin?

<dd> Yes. Excellent question because it points out that
switching between files is more than just switching saving and restoring
the global FILE * yyin variable, which (if left open) would retain its
cursor position: flex seems to do its own layer of buffering in addition to
the buffering built-in to C stdio files.
Note that the sample clex.l file omits the saving and restoring of flex's
buffer state, and naively tries to just assign a new yyin and go on.
<p>

Section 11 of the flex manual provides the tools to correct and complete
(or replace entirely) the include mechanism started in clex.l.  Function
<code>yypush_buffer_state()</code>, or function
<code>yy_switch_to_buffer()</code>, allows for switching back (either by
popping, or switching again) after an include file is completed.

<dt>
From reading the Homework #1 page, I can't seem to understand how
you want <em>system includes</em> to be handled. I'm still not really sure
what you want the 120++ lexical anyalzyer to do for system includes,
could you provide some more info?
<dd>
I dismiss the notion of including g++'s real system includes, because they
are too large and liable to have non-standard extensions.
You have two options: 1) set a global boolean flag for each
system include, from the small set that are allowed in 120++. Use those
flags later in your compiler to hardwire "built-in" globals/functions
into your global symbol table.
OR 2) implement the system includes by having the system includes pull in
a set of tiny "120++ include files" that you write for your compiler. For
portability, these should be located either relative to your compiler's
binary location, or built-in such that your compiler can place them in
the current directory as temporary files during the compile.

<dt>
When displaying the token per line, does that mean once we encounter a
user-defined include, it should begin displaying token info for its tokens?

<dd> Yes, and then switch back to the main source file after the #include has
been processed.
-->

</dd><dt>
Are we required to be using a lexical analysis error function lexerr()?
</dt><dd>
<ul>
<li>
Whether you have a helper function with that particular name is up to you.
</li><li> You should report lexical errors in a manner that is helpful to the user.
Include line #, filename, and nature of the error if possible.
</li><li>Many lexical errors could consist of "token Y is not legal in language X".
</li><li>You are allowed to stop with an error exit status when you find an error.
</li></ul>

</dd><dt>
The HW Specification says we are to use at least 2 separately compiled
.c files. Does Flex's generated lex.yy.c count as one of them,
or are you looking for yet another .c file, aside from lex.yy.c? 

</dt><dd>
lex.yy.c counts. You may have more, but you should at least have a lex.yy.c
or other lex-compatible module, and a main function in a separate .c file

</dd><dt> For numbers, should we care about their size? What if an integer in
the source file is greater than 2^64 ?
</dt><dd> We could ask: what do production compilers do?  Or we could just say:
good catch, your compiler would ideally range check and emit an error
if a value that doesn't fit into 64-bits occurs, for either the integer
or (less likely) float64 literals.  Any ideas on how to detect an out
of range literal?

    <p>
      FYI here is what the Rust compiler does:
      <pre>
% rustc hello.rs
error: literal out of range for `i64`
 --> hello.rs:2:45
  |
2 | ...", &amp;(f("golly", 121212121212121212121212121212121212))[..]);
  |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |
  = note: the literal `121212121212121212121212121212121212` does not fit into the type `i64` whose range is `-9223372036854775808..=9223372036854775807`
  = help: consider using the type `i128` instead
  = note: `#[deny(overflowing_literals)]` on by default

error: aborting due to previous error
</pre>


</dd><dt> I was using valgrind to test memory leaks and saw that there is a
<code>leak-check=full</code> option.  Should I be testing that as well, or
just standard valgrind output with no options?

</dt><dd> You are welcome to use valgrind's memory-leak-finding capabilities, but
you are only being graded on whether your compiler performs illegal reads or
writes, including reads from uninitialized memory.

</dd></dl>


<dl>
<dt> My C compiles say "implicit declaration of function"
</dt><dd> The C compiler requires a prototype (or actual function definition)
     before it sees any <em>calls</em> to each function, in order to generate
    correct code. On 64-bit platforms, treat this warning as an error, i.e.
    you really should fix it.
</dd>

<!--
<dt> The 120++ manual's lexical section does not include short/long int
and double types as it does in section 1, from Dr. Soule's book. Are we not
including these?
<dd> We are including short/long reserved words, they are in the 120++ book.
Subject to semantics requirements of ANSI C++, we might simplify our code
generation and implement all sizes as the same
thing (say, a 64-bit integer).
<dt> In reference to including system includes, should we just use a flag to
     note if these have been added?
</dt><dd> You do not have to work out the details in this HW.
     By the semantic analysis phase, you will need a strategy for #include's.
     I recommend one flag for each supported system include.
-->
</dd>

<dt> For built-in library symbols (functions/methods etc.)
  that we need to reference, what
  should our compiler be doing and what will we need for this homework?
<dd>
Good question.  These items are processed normally in the lexical and syntax analysis phases*. For semantic analysis, we will need a strategy for
pre-initializing the symbol table based on what's been included/imported.
*predefined type names such as system-introduced typedef's affect
syntax analysis on some common language grammars.

<!-- 120++
<dt>
With the string library being included, do we not need to worry about char* types being present?
<dd> char * does appear in 120++. We will need to support basic pointer types.
More details will be needed in semantic analysis.  char  and * are two separate
tokens in your scanner of course.

<dt>
Do we need to include the referencing operator &amp;
<dd>
Yes.

<dt>
Is the distinction between and bitwise AND and referencing operation done by our grammar? 
<dd> Yes, the lexical analyzer just returns a token saying it saw an &amp;
and the syntax analyzer has to decide if that is used as a binary operator,
a unary modifer to a parameter, a unary address-of operator, etc.
-->

</dd></dl>



<h3> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/toy.l">Toy compiler example</a> adapted from the Flex Manpage </h3>

<ul>
<li> What does this example have that you might use in your HW?
</li><li> What does the HW require that needs to be different?
</li></ul>

<p>

</p><pre>           /* scanner for a toy Pascal-like language */

           %{
           #include &lt;stdio.h&gt;
           /* need this for the call to atof() below */
           #include &lt;math.h&gt;
           %}

           DIGIT    [0-9]
           ID       [a-z][a-z0-9]*

           %%

           {DIGIT}+    {
                       printf( "An integer: %s (%d)\n", yytext,
                               atoi( yytext ) );
                       }

           {DIGIT}+"."{DIGIT}*        {
                       printf( "A float: %s (%g)\n", yytext,
                               atof( yytext ) );
                       }

           if|then|begin|end|procedure|function        {
                       printf( "A keyword: %s\n", yytext );
                       }

           {ID}        { printf( "An identifier: %s\n", yytext ); }

           "+"|"-"|"*"|"/"   { printf( "An operator: %s\n", yytext ); }

           "{"[^}\n]*"}"     {  /* eat up one-line comments */ }

           [ \t\n]+          { /* eat up whitespace */ }

           .         {  printf( "Unrecognized character: %s\n", yytext ); }

           %%

           int main(int argc, char **argv )
               {
               ++argv, --argc;  /* skip over program name */
               if ( argc &gt; 0 )
                       yyin = fopen( argv[0], "r" );
               else
                       yyin = stdin;

               yylex();
               }
</pre>



<h3> Using character sets (square brackets) in Flex </h3>

A student once sent me an example regular expression for comments that read:
<pre>   COMMENT [/*][[^*/]*[*]*]]*[*/]
</pre>
One problem here is that square brackets are not parentheses, they do not nest,
they do not support concatenation or other regular expression operators. They
mean exactly: "match any one of these characters" or for ^: "match any one
character that is not one of these characters".  Note also that you
<em>can't</em> use ^ as a "not" operator outside of square brackets: you
can't write the expression for "stuff that isn't */" by saying (^ "*/")


<A name=finiteautomata>
<h3> Finite Automata </h3>
</A>

Efficiency in lexical analyzers based on regular expressions is all about
how to best implement those wonders of CS Theory: the finite automata. Today
we briefly review some highlights from theory of computation with an eye
towards implementation.

<p>

A finite automaton (FA) is an abstract, mathematical machine, also known as a
finite state machine, with the following components:

<ol>
<li> A set of states S
<li> A set of input symbols E (the alphabet)
<li> A transition function move(state, symbol) : new state(s)
<li> A start state S0
<li> A set of final states F
</ol>


<h3> Implementing Finite Automata </h3>

<ul>
<li> We aren't going to study Flex's implementation in detail; I am sure
     you could have a lot of fun with that.
</li><li> The word <em>finite</em> refers to the set of states: there is a fixed
     size to this machine.  No "stacks", no "virtual memory", just a known
     number of states.
</li><li> The word <em>automaton</em> refers to the execution mode: there is
     no brain, not so much as a instruction set and sequence of instructions.
</li></ul>

<h4> dfa v1 </h4>

The basic logic is almost a hardwired short loop like this:

<pre>   while ((c=getchar()) != EOF) S := move(S, c);
</pre>

The move() function, which handles transitions from state to state,
might be some kind of table (2D array) lookup.
What this "finite automaton algorithm" lacks in flexibility,
it makes up in speed. 

<h4> dfa v2 </h4>

In real-life, there are some side effects
or semantic action code associated with certain states,
or it is not very useful.

<pre>   while ((c=getchar()) != EOF) { S := move(S, c); switch(S) { ... } }
</pre>

<p>

To go faster than this, you can stop representing the current
state in some variable S, and instead make the state an implicit property of
the instruction/program counter register.

<p>
<font size="1"> <a name="8">lecture #8</a> began here</font>
</p><p>

<h3> Questions </h3>

<dl>
  <dt> Do we have to do augmented operations?
  <dd> Our guiding principle is: does an intro course use it?
      An intro course usually uses += and -=.
       Let's go ahead and include those two. Not so much *=, /=, etc.
</dl>


<h3> DFAs </h3>

The type of finite automata that is easiest to understand and simplest to
implement <!--(maybe even in hardware)--> is called a deterministic finite
automaton (DFA).  The word <em>deterministic</em> here refers to the return
value of
function move(state, symbol), which goes to at most one state.

Example:
<p>
</p><pre>S = {s0, s1, s2}
E = {a, b, c}
move = { (s0,a):s1; (s1,b):s2; (s2,c):s2 }
S0 = s0
F = {s2}
</pre>
<p>

Finite automata correspond in a 1:1 relationship to transition diagrams;
from any transition diagram one can write down the formal automaton in
terms of items #1-#5 above, and vice versa.  To draw the transition diagram
for a finite automaton:
</p><ul>
<li> draw a circle for each state s in S; put a label inside the circles
     to identify each state by number or name
</li><li> draw an arrow between S<sub>i</sub> and S<sub>j</sub>, labeled with x
     whenever the transition says to move(S<sub>i</sub>, x) : S<sub>j</sub>
</li><li> draw a "wedgie" into the start state S0 to identify it
</li><li> draw a second circle inside each of the final states in F
</li></ul>

<h3> The Automaton Game </h3>

If I give you a transition diagram of a finite automaton, you can hand-simulate
the operation of that automaton on any input I give you.


<h4> DFA Implementation </h4>

The nice part about DFA's is that they are efficiently implemented
on computers.  What DFA does the following code correspond to?  What
is the corresponding regular expression?  You can speed this code
fragment up even further if you are willing to use goto's or write
it in assembler.

<pre>state := S0
for(;;)
   switch (state) {
   case 0: 
      switch (input) {
         'a': state = 1; input = getchar(); break;
         'b': input = getchar(); break;
	 default: printf("dfa error\n"); exit(1);
         }
   case 1: 
      switch (input) {
         EOF: printf("accept\n"); exit(0);
	 default: printf("dfa error\n"); exit(1);
         }
      }
</pre>

Flex has extra complications. It accepts multiple regular expressions, runs
them all in parallel in one big DFA, and adds semantics to break ties. These
extra complications might be viewed as "breaking" the strict rules of DFA's,
but they don't really mess up the fast DFA implementation.


</p><h4> Deterministic Finite Automata Examples </h4>

A lexical analyzer might associate different final states with different
token categories. In this fragment, the final states are marked by
"return" statements that say what category to return. What is incomplete
or wrong here?
<p>


<img src="dfacat.png">
</p><p>


C Comments:</p><p>
<img src="dfa-ccom.png">
</p><p>


<h4> Nondeterministic Finite Automata (NFA's)</h4>

Notational convenience motivates more flexible machines in which function
move() can go to more than one state on a given input symbol, and some
states can move to other states even without consuming an input symbol
(&#949;-transitions).
<p>

Fortunately, one can prove that for any NFA, there is an equivalent DFA.
They are just a notational convenience. So, finite automata help us get
from a set of regular expressions to a computer program that recognizes
them efficiently.

</p><h4> NFA Examples </h4>

&#949;-transitions make it simpler to merge automata:<p>
<img src="fa-eps.gif">
</p><p>

multiple transitions on the same symbol handle common prefixes:</p><p>
<img src="fa-less.gif">
</p><p>

factoring may optimize the number of states.  Is this picture OK/correct?</p><p>
<img src="fa-less2.gif">
</p><p>


<h4> NFA examples - from regular expressions </h4>

Can you draw an NFA corresponding to the following?

<pre>(a|c)*b(a|c)*

(a|c)*|(a|c)*b(a|c)*

(a|c)*(b|&#949;)(a|c)*
</pre>




<h3> Regular expressions can be converted automatically to NFA's </h3>

Each rule in the definition of regular expressions has a corresponding
NFA; NFA's are <i>composed</i> using &#949; transitions.  This is called
"Thompson's construction" <!--(Louden pg. 64, ASU Algorithm 3.3-->).
We will work
examples such as (a|b)*abb in class and during lab.

<ol>
<li> For &#949;, draw two states with a single &#949; transition.
     <br><img src="fa-th2.gif">
</li><li> For any letter in the alphabet, 
     draw two states with a single transition labeled with that letter.
     <br><img src="fa-th1.gif">
</li><li> For regular expressions r and s, draw r | s
     by adding a new start state with &#949; transitions to the start
     states of r and s, and a new final state with &#949; transitions
     from each final state in r and s.
     <br><img src="fa-th4.gif">
</li><li> For regular expressions r and s, draw rs
     by adding &#949; transitions from the final states of r to the
     start state of s.
     <br><img src="fa-th3.gif">
</li><li> For regular expression r, draw r*
     by adding new start and final states, and &#949; transitions
<ul>
	<li> from the start state to the final state,
	</li><li> from the final  state back to the start state,
	</li><li> from the new start to the old start and from the old final
            states to the new final state.
</li></ul>
     <br><img src="kleene.png">
</li><li> For parenthesized regular expression (r) you can use the NFA for r.
</li></ol>


<h3> NFA's can be converted automatically to DFA's </h3>

In: NFA N<br>
Out: DFA D<br>
Method: Construct transition table Dtran (a.k.a. the "move function").
Each DFA state is a set of
NFA states. Dtran simulates in parallel all possible moves N can make
on a given string.
<p>

Operations to keep track of sets of NFA states:
</p><p>
</p><dl>
<dt>&#949;_closure(s)</dt>
<dd> set of states reachable from state s via &#949;</dd>
<dt>&#949;_closure(T)</dt>
<dd> set of states reachable from any state in set T via &#949;</dd>
<dt>move(T,a)</dt>
<dd> set of states to which there is an NFA transition from states in T on symbol a</dd>
</dl>
<p>

NFA to DFA Algorithm:
</p><p>
</p><pre>Dstates := {&#949;_closure(start_state)}
while T := unmarked_member(Dstates) do {
	mark(T)
	for each input symbol a do {
		U := &#949;_closure(move(T,a))
		if not member(Dstates, U) then
			insert(Dstates, U)
		Dtran[T,a] := U
	}
}
</pre>



<h3> Practice converting NFA to DFA </h3>

OK, you've seen the algorithm, now can you use it?<p>
<img src="nfadfa.gif">
</p><p>
...
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
...did you get:</p><p>
<img src="nfadfa2.gif">
</p><p>
<br>
<br>
<br>
<br>
OK, how about this one: </p><p>
<img src="nfadfa3.gif">
</p><p>


<p>
<font size="1"> <a name="9">lecture #9</a> began here</font>
</p>


<h3> HW#3 </h3>

</p><h3> Look at <a href="https://www.cs.nmt.edu/~jeffery/courses/423/hw3.html">HW#3</a> </h3>


<h3> Mailbag </h3>

Let's start with any new questions and then look at some old ones.

<dl>
<!--
<dt> Somehow in c113c.html suddenly there appeared a rule about only
    the first 6 letters of identifiers being significant.
    When we parse in flex, and create the linked list, should we keep
    the whole scanned lexeme or only the first six chars?
<dd> For HW#2 I am going to be pretty casual about grading this, but the
    official answer is that if an identifier is longer than 6 characters
    long, you should go ahead and truncate it. I have seen commercial
    compilers that kept longer names but only used the first six letters
    in distinguishing them, but you are not expected to do that. BTW,
    other commercial compilers limit the length at 32, or 256 letters.-->

<dt> Integer literal values include 0. Since integer literal contains
  integer value, should we consider negative sign/value in our
  integer-literal RE or just the positive values including 0?
  <dd> In some languages the minus sign in -123 is not part of the
    integer literal, it is
  an application of the unary negation operator.  So that's two tokens,
  two calls to yylex() and two codes returned.  And all integer literals
    are non-negative. However I agree that my intuition begs -123 to be a
    single token.

<dt> When there is a lexical error, should the scanner terminate with an
  error message in stdout and stop scanning or just output an error message
  and keep scanning the rest of the input(s) and at the end return with 1.
  I think it should output errors with error count and keep reading to find
  out all the errors and at the end return 1 if error count is more than 0.
  I just want to make sure about the HW requirement.
<dd> Thank you for your opinion. A production compiler would probably try to
  recover from a lexical error and continue.  You are not required or expected
  to do so.  If a lexical error occurs, you are allowed to print an error
  message and then terminate with the error exit code.

<dt> In section 2.3 Operators the comma operator ,  -- An error is reported
but in Section 2.5 Punctuation, comma , is a valid lexeme.
<dd> Good observation.  A comma is a legal token.  The comment about it
not being a legal operator in c113c will be addressed in the syntax/grammar.

<dt> since Operators and Punctuations all are one character symbols,
     why are we dividing in two groups? When we parse using Flex, we
     are going to assign different token values for each of those
     allowed symbols? Just to understand it better, whether in HW,
     should we consider a special case besides just RE match?
  <dd> In lexical analysis the distinction of operators and punctuation
    as two groups
     is unnecessary. It is more of a syntax and semantics differentiation,
     and even there, since they all return different integer codes, the
     distinct groups just inform the organization of the document.

<dt> The language requires zero or more characters enclosed in apostrophes. i. e. ''  ' '  'a' 'abc' are valid string literal, right?
<dd> Apostrophes are for character literals, which must always be of length 1.

<dt> Do we want apostrophes (') or double quotes (&#8220;)
     to represent string literal?
<dd>String literals are always and only enclosed in double quotes.

</dl>


<!--<h3> C Comments Redux </h3>

<ul>
<li>
It takes less than 5 minutes to find a solution on the internet, but many
internet "solutions" are in fact buggy or suboptimal.
</li><li> A FA might or might not give solution hints for the corresponding regex.
</li><li> Here is an internet solution, cleaned up:

<pre>"/*"([^*]|"*"+[^/*])*"*"+"/"
</pre>
</li><li> Think hard about it. Does it have any bugs?
</li></ul>
-->




<dl>
<!--
<dt> Go has four different kinds of literal constants, but for HW#2,
     the grammar one thing, LLITERAL, what up?
</dt><dd> You are correct. If you return four different codes for four different
     types of literals, you have to modify the grammar to replace LLLITERAL
     with a grammar rule that allows your four integer codes. Alternatively,
     you can have your four (or more) different flex regular expressions for
     different kinds of literal constants, all return the LLITERAL integer.
</dd><dt> How do I deal with semi-colons?
</dt><dd> For HW#1, hopefully you just added an integer token category for them,
     and returned that integer if you
     saw one, even though explicit semi-colons are infrequent
     in source code.  For HW#2 your options are to write a grammar
     that doesn't need semi-colons and works anyhow, or write a grammar that
     needs semi-colons, and perform semi-colon insertion.
-->
<!--
<dt> I'm trying to understand the <code>d</code> operator.
     What about the following:
<pre>
  d20
  d 20
  d x
  d(x)
  5d16
  5d 16
  5 d16
  5 d 16
  x d16
  x d 16
  (x)d16
  (x)d 16
  5d x
  5 d x
  5d(x)
  5 d(x)
  x d y
  (x) d y
  x d (y)
  (x)d(y)
</pre>
<dd>
Thank you for really pushing the question: what is the d operator.
The intention is indeed that everything that makes sense shall work.
Almost ALL of the patterns listed here come about naturally from adding
a "d" operator in the context free grammar in HW#2. The only things you
have to worry about for HW#1 is what letters belong to how many tokens
in what token categories.  For example, is d20 one token, or two?  It
matches the regex for variable names, but we need it to be two tokens.
Can we do that with flex regular expressions' lookahead operator, or are
we going to have to special-case it as one complex token and have
special treatment for it in the grammar?
-->


<!--
<dt>I'm still not super clear what should happen with system includes.
  They will eventually introduce symbols to be stored in a symbol table
  The symbol table should be a hash table. But what is being stored there?
  Should I look up every variable and function name in the libraries 
  mentioned by c113c, and manually add them all to the symbol table?

<dd> By Homework #3, we need to know what identifiers are the names
  of types (in an OO language this would include classes) in order to
  return the correct category for them.
By homework #4 we will want to store type information for system
functions and parameters and such, and be able to check calls for validity.
-->

<!--
<dt>
120++ mentions "built-in" classes or functions -- <<, >>, cout, 
cin, string, ifstream, etc. What does that mean in terms of the lexer?
<dd> The lexer should include operators (separate integer categories/codes)
     for all C++ operators.  The lexer should treat built-ins that are not
     reserved words as identifiers.  We will need to revisit this topic
     next assignment.
-->

<!--
<dt> I was curious if character literals (i.e. 'a' or 'b') need to be stored as an ival or maybe sval?

<dd> Yes. You could treat them similar to a string and store an
  sval that is only one character long, but I think in a previous
  lecture I suggested adding a cval to the struct token.
-->

<!--
<dt> Are we supposed to distinguish between pointers and multiplication for our scanner? They use the same symbol, but are we supposed to know when it's considered a pointer and when it's considered multiplication?

<dd> No. The lexical analyzer doesn't know the surrounding syntax context
that would say what the token is used for, it just knows it sees a *
-->

</dd><dt>What do you mean, for ival/dval/sval, by telling us to
    "store binary value here"
</dt><dd>A binary value is the actual native representation that corresponds to
the string of ASCII codes that is the lexeme, for example what you get when
you call atoi("1234") for the token "1234".

</dd><dt> I am getting a lot of "unrecognized rule" errors in my .l file
</dt><dd> Look for problems with regular expressions or semantic actions prior to
     the first reported error.  If you need better diagnosis, find a way to
     show me your code. One student saw these errors because they omitted
     the required space between their regular expressions and their C semantic
     actions.

</dd><dt> Do you have any cool tips to share regarding the un-escaping of special
characters?
</dt><dd> Copy character-by-character from the yytext into
a newly allocated array. Every escape sequence of multiple characters in yytext
represents a single character in
sval. Inside your loop copying characters from yytext into sval,
if you see a backslash in yytext, skip it and use a switch statement
on the next character.  See below for additional discussion.

<!--
<dt>
Do we have to support binary literals by using the prefix "0b"
<dd>
Ideally you should write a regular expression for it, allow it on input,
and print an error message if you encounter it.

</dd>
-->
<!--
<dt>
How can we represent and print out the binary value in ival and dval?
Wouldn't both ival and dval need to be char arrays types to actually display
a "binary representation"?

</dt><dd>
You do NOT have to convert to a binary string representation or output anything
in 0b010101010000 format.  Output of ival/dval/sval does involve converting it
back to a string representation.
-->
<!--
<dt>
The 120++ manual mentions "_123 is not a legal variable name ("does not contain a letter"), while the C/C++ languages allow it (underscore is considered to be a letter). The ideal treatment in 120++ would be to issue a warning (at most once).". So, should I follow that rule?
<dd>
Things in C++ that are not in 120++ are allowed to print an error
and exit.
-->

</dd><dt>
Is a function name also an identifier?
</dt><dd>
Yes.
</dd></dl>

<h4> C Pointers, malloc, and your future </h4>

For many of you success as a computer scientist may boil down to what it
will take for you to master the concept of dynamically allocated memory,
and whether you are willing to do that.  In C this means pointers and the
<code>malloc()</code> family of functions.  Here are some tips:

<ul>
<li> Draw "memory box" pictures of your variables.  Pencil and paper
     understanding of memory leads to correct running programs.
</li><li> Always initialize local pointer variables.  Consider this code:
<pre>void f() {
   int i = 0;
   struct tokenlist *current, *head;
   ...
   foo(current)
}
</pre>

Here, <code>current</code> is passed in as a parameter to foo, but it is a
pointer that hasn't been pointed at anything. I cannot tell you how many
times I personally have written bugs myself or fixed bugs in student code,
caused by reading or writing to pointers that weren't pointing at anything
in particular.  Local variables that weren't initialized point at random
garbage. If you are lucky this is a coredump, but you might not be lucky,
you might not find out where the mistake was, you might just get a wrong answer.
This can all be fixed by

<pre>   struct tokenlist *current = NULL, *head = NULL;
</pre>

</li><li> Avoid this common C bug:
<pre>struct token *t = (struct token *)malloc(sizeof(struct token *)));
</pre>
This compiles, but causes coredumps during program execution.  Why?

</li><li> Check your <code>malloc()</code> return value to be sure it is not
NULL.  Sure, modern programs have big memories so you think they will "never
run out of memory".  Wrong. <code>malloc()</code> can return NULL even on
big machines.  Operating systems often place limits on memory far beneath
the hardware capabilities.  wormulon (or cs-course42) is likely a conspicuous
example. Machine shared across 40 users?  You may have a lower memory
limit than you think.

</li></ul>



<!--
<h3> <a href="https://golang.org/ref/spec#Semicolons">Semi-Colon Insertion</a>
     in Go </h3>

The Go designers probably had good reason to include semi-colons in the Go
grammar, to facilitate parsing, but they didn't want code to require them
99% of the time, so they introduced semi-colon insertion, an idea that they
borrowed from other languages.
<p>

</p><ol>
<li> At a newline, semi-colon is inserted if the last token was
<ul>
<li> identifier
</li><li> literal (number, rune, or string)
</li><li> break, continue, fallthrough, or return
</li><li> ++ -- ) ] or }
</li></ul>

</li><li> "a semi-colon may be omitted before a closing ) or }"
</li></ol>

What does (2) even mean?  Automatic ; insertion before every ) or }?
Or just that the grammar handles an optional semi-colon in those spots?

<h3> Ways to Implement Semi-colon Insertion </h3>

<dl>
<dt> preprocessor
</dt><dd> you could write a pre-pass that does nothing but semi-colon insertion
</dd><dt> layered in between yylex() and yyparse()
</dt><dd> you could rename the yylex() generated by flex to be yylex2(), and
     write a new yylex() that returns a semi-colon if conditions are right,
     and otherwise just calls yylex2(). You'd have to have some global or
     static memory for (1) what was the last token and (2) whether we saw
     a newline
</dd><dt> within the regular expression for newline?
</dt><dd> not quite general enough, but you could return a semi-colon integer
     when you see a newline whose previous token met the conditions
</dd><dt> layered inside yylex's C semantic actions
</dt><dd> a student figured out that one can do semi-colon insertion inside
     a helper function called from each flex semantic action. The function,
     if it substitutes a semi-colon for what is normally returned, has to
     save/remember what it was going to return, and return it later. The
     trick here is: if you inserted a semi-colon and saved your found token,
     you return the saved token after you have scanned your <em>next</em>
     token. In that case, you need to save <em>that</em>token somehow;
     one way is to tell flex to back up via yyless(0).
</dd></dl>
-->

<!--
<h3> Semi-Colon Insertion in Unicon </h3>

<ol>
<li> Categorize for each token: is it a legal Beginner?
<li> Categorize for each token: is it a legal Ender?
<li> Remember previous token's Ender status, update each call to yylex()
<li> Set a flag every newline to mark the next token First_on_a_line;
     update each call to yylex()
<li> Algorithm for new yylex():
<pre> 
   IF we saved last token and returned Semi-Colon last time THEN
      return saved token
   ELSE {
      call old yylex()
      IF First_on_a_line AND Beginner AND last.Ender THEN {
          save_token; return Semi-Colon
          }
      ELSE return token
      }
</pre>
</ol>
-->



<h3> HW Tips </h3>

These comments are based on historical solutions. I learned a lot from my
older siblings when I was young. Consider this your opportunity to learn
from your forebears' mistakes.

<dl>
<dt> better solutions' lexer actions looked like
<pre>...regex...      { return token(TERMSYM); }
</pre>
</dt><dd>
     where token() allocates a token structure, sets a global variable to
     point to it, and returns the same integer category that it is passed
     from yylex(), so yylex() in turn returns this value.
</dd><dt> Put in enough line breaks.
</dt><dd>
     Use &lt;= 80 columns in your code, so that it prints readably.
</dd><dt> Comment non-trivial helper functions.  Comment non-trivial code.
</dt><dd> Comment appropriate for a CS professional reader, not a newbie tutorial.
     I know what i++ does, you do not have to tell me.
</dd><dt> Do not leave in commented-out debugging code or whatever.
</dt><dd> I might miss, and misgrade, your good output if I can't see it.
<!--
<li> Does lexer know about C++ library things like cin?  Can it report good
     errors for those if the required system include file was not included?
     (Generally: no, it can't).
-->
</dd><dt> Fancier formatting might calculate field widths from actual data
     and use a variable to specify field widths in the printf.
</dt><dd> You don't
     have to do this, but if you want to it is not that hard.
</dd><dt> Remind yourself of the difference between NULL and '\0' and 0
</dt><dd> NULL is used for pointers. The NUL byte '\0' terminates strings. 0
     is a different size from NULL on many 64-bit compilers. Beware.
</dd><dt> Avoid O(n<sup>2</sup>) or worse, if at all possible
</dt><dd> It is possible to write bad algorithms that work, but it is better
     to write good algorithms that work.
</dd><dt> Avoid big quantities of duplicate code
</dt><dd> You will have to use and possibly extend this code all semester.
</dd><dt> Use a switch when appropriate instead of long chain of if-statements
</dt><dd> Long chains of if statements are actually slow and less readable.
</dd><dt> On strings, allocate one byte extra for NUL.
</dt><dd> This common problem causes valgrind trouble, memory violations etc.
</dd><dt>  On all pointers, don't allocate and then just point the pointer
      someplace else
</dt><dd> This common student error results in, at least, a memory leak.
</dd><dt> Don't allocate the same thing over and over unless copies may need
     to be modified.
</dt><dd> This is often a performance problem.
</dd><dt> Check all allocations and fopen() calls for NULL return (good to have helper functions).
</dt><dd> C library functions can fail.  Expect and check for that.

</dd><dt> Beware losing the base pointer that you allocated.
</dt><dd> You can only free()
     if you still know where the start of what you allocated was.
</dd><dt> Avoid duplicate calls to strlen()
</dt><dd> especially in a loop! (Its O(n<sup>2</sup>))
</dd><dt> Use strcpy() instead of strncpy()
</dt><dd> unless you are really copying only part of a string, or
     copying a string into a limited-length buffer.

</dd><dt> You can't <code>malloc()</code> in a global initializer
</dt><dd> <code>malloc()</code> is a runtime allocation from a memory
     region that does not
     exist at compile or link time. Globals can be initialized, but not to
     point at memory regions that do not exist until runtime.
</dd><dt> Don't use raw constants like 260
</dt><dd> use symbolic names, like LEFTPARENTHESIS or LP
</dd><dt> The vertical bar (|) means nothing inside square brackets!
</dt><dd> Square brackets are an implicit shortcut for a whole lot of ORs
</dd><dt> If you don't allocate your token inside yylex() actions...
</dt><dd> You'll have to go back and do it, you need it for HW#2.
</dd><dt> If your regex's were broken
</dt><dd> If you know it, and were lazy, then fix it.  If you don't know it,
     then good luck on the midterm and/or final, you need to learn these,
     and devise some (hard) tests!
</dd></dl>



<h3> On resizing arrays in C </h3>

The sval attribute in the homework is a perfect example of a problem which a
Business (MIS) major might not be expected to solve well, but a CS major
should be able to do by the time they graduate.  This is not to encourage
any of you to consider MIS, but rather, to encourage you to learn how to
solve problems like these.

<p>

The problem can be summarized as: step through yytext, copying each character
out to sval, <!--removing doublequotes and plusses between the pieces, and
evaluating CHR$() constants. -- this was for BASIC -->
looking for escape sequences.

</p><p>

Space allocated with malloc() can be increased in size by realloc().
realloc() is awesome.  But, it COPIES and MOVES the old chunk of
space you had to the new, resized chunk of space, and frees the old
space, so you had better not have any other pointers pointing at
that space if you realloc(), and you have to update your pointer to
point at the new location realloc() returns.

<!--
<pre>
i = 0; j = 0;
while (yytext[i] != '\0') {
   if (yytext[i] == '\"') {
      /* copy string into sval */
      i++;
      while (yytext[i] != '\"') {
         sval[j++] = yytext[i++];
         }
      }
   else if ((yytext[i] == 'C') || (yytext[i] == 'c')) {
      /* handle CHR$(...) */
      i += 5;
      k = atoi(yytext + i);
      sval[j++] = k;           /* might check for 0-255 */
      while (yytext[i] != ')') i++;
      }
   /* else we can just skip it */
   i++;
}
sval[j] = '\0'; /* NUL-terminate our string */
</pre>
-->
</p><p>

There is one more problem: how do we allocate memory for sval, and how big
should it be?

</p><ul>
<li> Solution #1: sval = malloc(strlen(yytext)+1) is very safe, but wastes
     space.
</li><li> Solution #2: you could malloc a small amount and grow the array as
     needed.
<pre>sval = strdup("");
...
sval = appendstring(sval, yytext[i]); /* instead of sval[j++] = yytext[i] */
</pre>
where the function appendstring could be:
<pre>char *appendstring(char *s, char c)
{
    i = strlen(s);
    s = realloc(s, i+2);
    s[i] = c;
    s[i+1] = '\0';
    return s;
}
</pre>
Note: it is very inefficient to grow your array one character at
a time; in real life people grow arrays in large chunks at a time.

</li><li> Solution #3: use solution one and then shrink your array when you
find out how big it actually needs to be.
<pre>sval = malloc(strlen(yytext)+1);
/* ... do the code copying into sval; be sure to NUL-terminate */
sval = realloc(sval, strlen(sval)+1);
</pre>
</li></ul>


<!--
<h2> Some Remarks (BASIC)</h2>

<ul>
<li> Color BASIC has two-letter identifiers.  We are doing Extended Color
     BASIC, so we will allow longer identifier names.  But in the current
     assignment #2 you will only be tested on short variable names.
<li> Whether we return the same or a different category for integer constants
     and for line numbers depends very much on the grammar we use to parse
     our language,
     and whether it can understand what's going on with the
     line numbers if it doesn't have two categories.  My instinct tells me
     we will probably need either a token for newline characters or will
     need to detect line numbers as distinct from normal integer constants.
     Before we can answer that question, we need to learn about syntax!
</ul>
-->

<!--
<h3> Lexical Analysis and the Literal Table </h3>

In many compilers, the memory management components of the compiler interact
with several phases of compilation, starting with lexical analysis.

<p>

<ul>
<li> Efficient storage is necessary to handle large input files.
<li> There is a colossal amount of duplication in lexical data:
     variable names, strings and other literal values duplicate frequently
<li> What token type to use may depend on previous declarations.
</ul>
<p>
A hash table or other efficient data structure can avoid this duplication.
The software engineering design pattern to use is called the "flyweight".


<h3> Literal Table: Usage Example </h3>

Example abbreviated from [ASU86]: Figure 3.18, p. 109.  Use "install_id()"
instead of "strdup()" to avoid duplication in the lexical data.

<pre>
%{
/* #define's for token categories LT, LE, etc.
%}

digit   [0-9]
id	[a-zA-Z_][a-zA-Z_0-9]*
num     {digit}+(\.{digit}+)?

%%

[ \t\n]+ { /* discard */ }
if	 { return IF; }
then	 { return THEN; }
else	 { return ELSE; }
{id}	 { yylval.id = install_id(); return ID; }
{num}    { yylval.num = install_num(); return NUMBER; }
"&lt;"	 { yylval.op = LT; return RELOP; }
"&gt;"	 { yylval.op = GT; return RELOP; }

%%

install_id()
{
   /* insert yytext into the literal table */
}

install_num()
{
   /* insert (binary number corresponding to?) yytext into the literal table */
}
</pre>

So how would you implement a literal table using a hash table?  We will see
more hash tables when it comes time to construct the symbol tables with which
variable names and scopes are managed, so you had better become fluent.


<h3> Major Data Structures in a Compiler </h3>

<dl>
<dt> token
<dd> contains an integer category, lexeme, line #, column #, filename...
     We could build these into a link list, but instead we'll use them
     as leaves in a tree structure.
<dt> syntax tree
<dd> contains grammar information about a sequence of related tokens.
     leaves contain lexical information (tokens).  internal nodes
     contain grammar rules and pointers to tokens or other tree nodes.
<dt> symbol table
<dd> contains variable names, types, and information needed to generate
     code for a name (such as its address, or constant value).  Look ups
     are by name, so we'll need a hash table.
<dt> intermediate &amp; final code
<dd> We'll need link lists or similar structures to hold sequences of machine
     instructions
</dl>


<h4> Quick Note on things to look for in HW </h4>

<ul>
<li> Adding reserved words is trivial. But clex.l was for C, and we
     need some of the C++ reserved words for 120++.
<li> Also look for: any new data types (besides bool) and their new
     types of literal constants?
     New literals require new nontrivial regular expressions in your
     lex file.
<li> If there are bugs in the clex.l file you were given, the
ones we would be most likely to care about are bugs in the regular expressions
for literal constants.  This calls for close scrutiny and painstaking attention
to detail...
</ul>

-->


<h3> Reading Assignment </h3>

Clarifying the reading assignment from last lecture:

<ul>
  <li> Read <A href="https://www3.nd.edu/~dthain/compilerbook/">
	       Thain</A> Chapters 4-6
</li><li> Read Flex+Bison optional book chapters on
        Bison or alternatively, you may read sections
     1, 3, 4, 5 and 6 of the <a href="https://www.gnu.org/software/bison/manual/html_node/">Bison Manual</a>
</li>
</ul>

<p>

<p>
<font size="1"> <a name="10">lecture #10</a> began here</font>
</p><p>

<a name="syntax"></a></p><h2><a name="syntax"> Syntax Analysis </a></h2>

<em>Parsing</em> is the act of performing syntax analysis to verify an input
program's compliance with the source language.  A by-product of this process
is typically a tree that represents the structure of the program.


<h3> Context Free Grammars </h3>

A context free grammar G has:

<ul>
<li> A set of terminal symbols, T
</li><li> A set of nonterminal symbols, N
</li><li> A start symbol, s, which is a member of N
</li><li> A set of production rules of the form A -&gt; &#969;,
     where A is a nonterminal and &#969; is a string of terminal and 
     nonterminal symbols.
</li></ul>


<h4> Example CFG </h4>

Gonna use Bison syntax, not CSE 342 syntax. Arrows become colons.
OR bars denote additional production rules.  Semi-colons are superfluous.


<pre>
  nt1 : nt2 nt3 nt4 ;
  nt2 : OPEN ;
  nt3 : nt3 X | nt3 ;
  nt4 : CLOSE ;
</pre>


<h4> Derivation </h4>


A context free grammar can be used to <em>generate</em> strings in the
corresponding language as follows:
<pre>let X = the start symbol s
while there is some nonterminal Y in X do
   apply any one production rule using Y, e.g. Y -&gt; &#969;
</pre>
When X consists only of terminal symbols, it is a string of the language
denoted by the grammar.  Each iteration of the loop is a
<em>derivation step</em>.  If an iteration has several nonterminals
to choose from at some point, the rules of derviation would allow any of these
to be applied.  In practice, parsing algorithms tend to always choose the
leftmost nonterminal, or the rightmost nonterminal, resulting in strings
that are <em>leftmost derivations</em> or <em>rightmost derivations</em>.

<h3> C Context Free Grammar Example </h3>

Well, OK, so how much of the <!--BASIC--> C language grammar can we come up
with in class today?  Start with expressions, work on up to statements, and
work there up to entire functions, and programs.

<pre>
<em>insert your CFG ideas here </em>
...
<em>then cross reference them against <A href="cgram.y">cgram.y</A></em>
</pre>



<h3> Context Free Grammar Example (from BASIC) </h3>

How many terminals and non-terminals does the grammar below use?
Compared to the little grammar we started last time, how does this rate?
What parts make sense, and what parts seem bogus?

<pre>Program : Lines
Lines   : Lines Line
Lines   : Line
Line    : INTEGER StatementList
StatementList : Statement COLON StatementList
StatementList : Statement
Statement: AssignmentStatement
Statement: IfStatement
<em> REMark: ... BASIC has many other statement types </em>

AssignmentStatement : Variable ASSIGN Expression
Variable : IDENTIFIER
<em> REMark: ... BASIC has at least one more Variable type: arrays </em>

IfStatement: IF BooleanExpression THEN Statement
IfStatement: IF BooleanExpression THEN Statement ELSE Statement

Expression: Expression PLUS Term
Expression: Term
Term      : Term TIMES Factor
Term      : Factor
Factor    : IDENTIFIER
Factor    : LEFTPAREN Expression RIGHTPAREN
<em> REMark: ... BASIC has more expressions </em>
</pre>



<!--
<h3> A brief aside on casting your mallocs </h3>

<li> If you don't put a prototype for malloc(), C thinks it returns an int.
<pre>
#include &lt;stdlib.h&gt;
</pre>
includes prototypes for malloc(), free(), etc.  malloc() returns a void *.
<br><br>

<li> void * means "pointer that points at nothing", or "pointer that points
     at anything".  You need to cast it to what you are really pointing at,
     as in:
<pre>
union lexval *l = (union lexval *)malloc(sizeof(union lexval));
</pre>
Note the stupid duplication of type information; no language is perfect!
Anyhow, always cast your mallocs.  The program may work without the cast,
but you need to fix every warning, so you don't accidentally let a serious
one through.<br><br>
-->



<h3> Grammar Ambiguity </h3>

The grammar

<pre>E -&gt; E + E
E -&gt; E * E
E -&gt; ( E )
E -&gt; ident
</pre>

allows two different derivations for strings such as "x + y * z".
The grammar is ambiguous, but the semantics of the language dictate
a particular operator precedence that should be used.  One way to
eliminate such ambiguity is to rewrite the grammar. For example,
we can force the precedence we want by adding some nonterminals and
production rules.

<pre>E -&gt; E + T
E -&gt; T
T -&gt; T * F
T -&gt; F
F -&gt; ( E )
F -&gt; ident
</pre>

Given the arithmetic expression grammar from last lecture:
<p>

How can a program figure that x + y * z is legal?<br>
How can a program figure out that x + y (* z) is illegal?
</p><p>





<a name="yacc">
</a></p><h3><a name="yacc"> YACC </a></h3><a name="yacc">
</a>

YACC ("yet another compiler compiler") is a popular tool which originated at
AT&amp;T Bell Labs.  YACC takes a context free grammar as input, and generates a
parser as output.  Several independent, compatible implementations (AT&amp;T
yacc, Berkeley yacc, GNU Bison) for C exist, as well as many implementations
for other popular languages. There also exist other more "modern" parser
generators, but they are often less portable and are
heavily inspired/influenced by YACC so it is what we will study. <p>

YACC files end in .y and take the form
</p><pre>declarations
%%
grammar
%%
subroutines
</pre>
The declarations section defines the terminal symbols (tokens) and
nonterminal symbols. The most useful declarations are:
<dl>
<dt> %token a
</dt><dd> declares terminal symbol a; YACC can generate a set of #define's
that map these symbols onto integers, in a y.tab.h file. <em><b> Note: don't
#include your y.tab.h file from your grammar .y file, YACC generates the
same definitions and declarations directly in the .c file, and including
the .tab.h file will cause duplication errors.</b></em>
</dd><dt> %start A
</dt><dd> specifies the start symbol for the grammar (defaults to nonterminal
     on left side of the first production rule).
</dd></dl>
<p>
The grammar gives the production rules, interspersed with program code
fragments called semantic actions that let the programmer do what's
desired when the grammar productions are reduced.  They follow the
syntax
</p><pre>A : body ;
</pre>
Where body is a sequence of 0 or more terminals, nonterminals, or semantic
actions (code, in curly braces) separated by spaces.  As a notational
convenience, multiple production rules may be grouped together using the
vertical bar (|).



<h3> Bottom Up Parsing (How Does Bison's yyparse() Work?) </h3>

Bottom up parsers start from the sequence of terminal symbols and work
their way back up to the start symbol by repeatedly replacing grammar
rules' right hand sides by the corresponding non-terminal.  This is
the reverse of the derivation process, and is called "reduction".
<p>

Example. For the grammar
</p><pre>(1)	S-&gt;aABe
(2)	A-&gt;Abc
(3)	A-&gt;b
(4)	B-&gt;d
</pre>
the string "abbcde" can be parsed bottom-up by the following reduction
steps:
<pre>abbcde
aAbcde
aAde
aABe
S
</pre>


<h3> Handles </h3>

Definition: a <em>handle</em> is a substring that
<ol>
<li> matches a right hand side of a production rule in the grammar and
</li><li> whose reduction to the nonterminal on the left hand side of that
     grammar rule is a step along the reverse of a rightmost derivation.
</li></ol>


<p>
<font size="1"> <a name="11">lecture #11</a> began here</font>
</p><p>

<h3> Comments on HW#2 </h3>

<dl>
  <dt> I have run some tests on everyone's HW#2 submission. If you didn't "make" you got a fix-and-resubmit e-mail
    <dd> Still in process of grading. Maybe by Monday;
      due to other obligations, probably not.
  <dt> Testing is for basic functionality
  <dd> Testing will get more elaborate in later HW's
  <dt> The executable is to be named puny and not anything else
  <dt> In a Makefile, CFLAGS is for -c compile steps, LDFLAGS is for link steps
  <dd> Typical to define CFLAGS in this class to be -c -g -Wall.
  <dt> Do not mix compile lines with link lines.
  <dd> The link line should link together .o files. The larger the program,
      the more important it is to not recompile all files whenever one changes.
  <dt> Did I learn anything from the preliminary build checks yesterday?
  <dd> I am reminded that <code>-&gt;</code> is used in type hinting. Punyref
</dl>


<h3> Mailbag </h3>

<em>Thank you</em> to all of you who are sending me juicy questions
by e-mail.

<dl>
<dt> I am trying to get a better picture of the communication that
     happens between Flex and Bison. From my understanding:

<ol>
<li><code>main()</code> calls <code>yyparse()</code>
</li><li><code>yyparse()</code> calls <code>yylex()</code>
</li><li><code>yylex()</code> returns tokens from the input
    as integer values which are enumerated to text for readability
    to the .y file
</li><li> <code>yyparse()</code> tries to match these integers against
    rules of our grammar.
<br>
(if it is unsuccessful, it errors (shift/reduce, reduce/reduce, unable to parse))
</li></ol>
Is this correct?
</dt><dd>
    <ul> <li>1-3 are correct.
      <li> 3 also includes: yylex() sets a global variable
    so that yyparse() can pickup the lexical attributes, e.g. a pointer to
    struct token.
      <li> 4 is correct except that shift/reduce and reduce/reduce conflicts are
	warnings that are found/reported
at bison time, not at yyparse() runtime.  But yes yyparse() can find syntax
  errors and we have to report them meaningfully.
  </ul>

</dd><dt> Does <code>yylval</code> have any use to us?  I read that
          it is used to bring the value of the token into the parser.
</dt><dd> Yes, <code>yylval</code> is how yyparse() picks up lexical
     attributes. We will talk about it more in class.

</dd><dt>How would we add artificial tokens, such as to insert a token, perhaps an INDENT token,
    <!-- like the semi-colon-->, without skipping real tokens when we return?
</dt><dd> Save the real, found token in a global or static, or figure out a way to
push it back onto the input stream.  Easiest is a one-token saved (pointer to
a) token struct. One could build a whole stack of saved tokens if one wished.
    In a previous Lab #2 and its aftermath, we worked out how to generate the sequence of integer codes
    that were needed. This question gets more interesting once the token structures in
    (formerly yyoken and now) yylval must be considered.

</dd>
<!--
<dt> Since we are adding semi-colons without knowledge
of the grammar how do we avoid simply putting a semi-colon at the end of
every line? Is there a set group of tokens that can't add semi-colons?
</dt><dd> You make an interesting point that one could maybe do semi-colon
insertion with guidance from the parser, but it is intended that it be
done in the way described previously in class: classify every token as
to whether it is a legal statement-beginner, and whether it is a legal
statement-ender.  Insert semi-colons at newlines between an ender and
a beginner.  Example classification (via an array of booleans or whatever):

<table border="">
<tbody><tr><th>token</th><th>Beginner?</th><th>Ender?
</th></tr><tr><td>  x  </td><td> yes </td><td> yes
</td></tr><tr><td>  1  </td><td> no?  </td><td> yes
</td></tr><tr><td>  if </td><td> yes </td><td> no
</td></tr><tr><td>  (  </td><td> yes </td><td> no
</td></tr><tr><td>  )  </td><td> no </td><td> yes
</td></tr><tr><td>  +  </td><td> no? </td><td> no
</td></tr><tr><td>  -  </td><td> no? </td><td> no
</td></tr></tbody></table>
-->

</dd><dt> How can I make Bison use a different yylex() in order to allow for
     token <!--semi-colon--> insertion?
</dt><dd> Two possibilities come to mind:
<ol>
<li> Modify output of bison to replace the call to yylex() with myyylex(),
</li><li> Modify output of flex to change its declaration of yylex to realyylex()
</li></ol>
     A traditional Linux tool for sneaky stuff like this is
     <code>sed(1)</code>, which could be invoked from your makefile.


<!--
</dd><dt> Does VGo support both statements with semi-colons and statements without
semi-colons?
</dt><dd> Go does.  VGo probably should, but if you figured out a way to hack
     the grammar to not use semi-colons and still recognize all of VGo,
     it would be pretty OK to only support statements without semicolons.

</dd>-->
  <dt>Does our language support empty statements?
</dt><dd> Most mainstream languages allow these. Did they get used in CSE 107 class?
   Unlikely. Occasionally I find them handy IRL. I would say they are optional in PunY.
  </dd>

<dt> In the previous HW, I created one token to handle all cases of
<em>unsupported</em> reserved words. Is there any reason I should keep the
individual tokens for the unsupported reserved words in the .y file? Or can I
just use my catch all token.  Same goes for unsupported operators/punctuations.

<dd> You can use your catch-all token. If your lexical analyzer
    stops with a good error message (filename, linenumber, what's strong),
    you don't have to have grammar rules for the things not our language. This is
  why I am not making you "recover" from lexical errors; so your grammar
  can become smaller and you'll have less tree constructing to do in HW#3.

  <dt>  How would you recommend "de-escaping" strings?
    <dd>
I recommend the following algorithm:
      <pre>
outputstring gets the empty string
for every character inside the double quotes
   if the character is backslash then
      do a big switch statement on the next character
         (backslash followed by t, for example, means outputstring gets a '\t' appended to it
   else the character was not a backslash, so just append it to the outputstring</pre>
      It can look humorous, and very meta, to be switching on case 't' outputting
      a '\t', on case 'n' outputting a '\n' etc.

<dt> Part 2, Step 6 of Lab 3 says:
    "Modify your HW2 main() function to call yyparse() one time in place
    of the while loop that called yylex() over and over again."
    In HW2, we used each call to yylex() to fill each node of our linked list.
    For Lab 3, are we supposed to keep the linked list?
<dd> You don't need to build a linked list in Lab 3.  If you did, you'd
      have to build it entirely inside yylex(), but instead for Lab 3 you are
      probably just ignoring the tokens. In Lab 4 we are going to
      be building tree nodes and putting the struct token * allocated in
      yylex() into the tree instead of into a linked list.
<!--
<dt>  How do we differentiate TYPEDEF_NAME and ENUMERATION_CONSTANT
      from a regular IDENTIFIER? Can we write a regex where typedef
      or enum comes before the identifier itself to return the correct value?
  <dd>  Wow, good question. There is identifying them (part 1) and then using
        knowledge of them to change what your lexical analyzer returns (part 2)
    Don't (try to) use a complex regex to identify type names, that is
       what your grammar does best.
-->

<dt> I read we could use '{' and such as terminal symbols in the grammar,
     instead of names like LCURLY. What are the pros and cons.  I know in C,
     <code>'{'</code> is just a small integer.
</dt><dd> I used to dislike grammars using character constants for their
    one-letter terminal symbols, instead of names. I found the mixture
    of character literals and name to be jarring, and found consistency
    to be comforting in my newbieness.  But Bison starts named terminals
    above 256 for a reason. When a terminal is only one character long,
    using its ASCII code is the shortest, most human readable way to
    identify it.
    So I have taken to preferring that.
</dd>
<!--<dt> What element types can be used in arrays and maps?  Can I have an
     array of arrays?  A map of maps?

</dt><dd> For VGo, legal map index types are: int, string. Element types
     also include float64 and structs.
     Array of arrays and map of maps are awesome but not in VGo.
     Note that structs can have arrays or maps as member variables.
-->
</dd><dt> What about no-op statements like 2+2?
</dt><dd> It is OK to not allow no-op statements like 2+2.  You have to use
     the value somehow, like by writing it out or assigning it to a variable.

</dd><dt> The grammar you gave us has many symbols that have not been mentioned.
     Should we support them, or not?  If we don't
     have to support them does that mean we don't have to include all the
     grammar rules that use them?
</dt><dd> Feel free to ask about specifics.
     The supplied grammar is for the whole language not our subset. You
     would need to delete from it <em>en masse</em> to get down to our subset.
     While that might be helpful from a code-management perspective,
     it would also leave you saying a more vague "parse error" message
     for many legal constructs for which a more helpful message is
     "this feature is not supported by XXX", where XXX is our language.

</dd><dt> How about a tool that would generate #define numbers for grammar rules
automatically from our .y files?
</dt><dd> I wrote a <a href="https://www.cs.nmt.edu/~jeffery/courses/423/nonterms.icn">cheap hack version 0</a>
of such a tool awhile back. I have not tested it on our .y, it might be buggy.

</dd><dt> Will we get marked off for any reduce/reduce conflicts we have?
</dt><dd> Yes you will lose points if you turn in a HW#2 with reduce/reduce
conflicts.

</dd><dt> How are we supposed to integrate the token names we created in the
     lexer with those token names in the Bison .y file?
</dt><dd> Any which way you can.  Probably, you
     either rename yours to use their names, or rename theirs to
     use your names.

</dd><dt> what action should be taken in the case of epsilon statements
</dt><dd> HW#2 spec says to use $$=NULL. I could also imagine using
     <code>$$=alctree(EPSILON, 0)</code> to build an explicit epsilon leaf,
     for people who don't like to have to check for NULL everywhere.

</dd><dt> Will I be setting myself up for failure if I attempt to write
     my own grammar from scratch?
</dt><dd> Go right ahead and ignore the provided grammar if you want; feel free to
     instead derive your grammar from the reference manual.
</dd></dl>



<a name="shiftreduce">
<h3> Shift Reduce Parsing </h3>     
</a>

A shift-reduce parser performs its parsing using the following structure
<pre><u>Stack</u>					<u>Input</u>
$						&#969;$
</pre>
At each step, the parser performs one of the following actions.
<ol>
<li> Shift one symbol from the input onto the parse stack
</li><li> Reduce one handle on the top of the parse stack. The symbols
     from the right hand side of a grammar rule are popped off the
     stack, and the nonterminal symbol is pushed on the stack in their place.
</li><li> Accept is the operation performed when the start symbol is alone
     on the parse stack and the input is empty.
</li><li> Error actions occur when no successful parse is possible.
</li></ol>


</p>

<h3> Type Names </h3>

"Type names" include typedef names (C/C++), enumeration constants (C/C++/Java),
and in OO languages, class names too.
<p>

Type names are an example where in some languages if we are not careful,
all the beautiful CFG parsing theory we've used up to this point breaks down
and flex/bison compilers tend to cheat a little.
<ul>
<li> Once a typedef is introduced (which can first be recognized at the syntax level),
     certain identifiers should be legal type names in addition or instead of being
     identifiers.
<li> The lexical analyzer may have
     to know whether the syntactic context needs a type name or an
     identifier at each point in which it runs into one of these names.
<li> Feedback from syntax or semantic analysis back into lexical
     analysis is not un-doable but it requires extensions added by hand to
     the machine generated lexical and syntax analyzer code.
</ul>
</p><p>
</p><pre>typedef int foo;
foo x;                    /* a normal use of typedef... */
foo foo;                  /* try this on gcc! is it a legal global? */
void main() { foo foo; }  /* what about this ? */
</pre>

On the other hand, some languages' grammars (yay Golang!) avoid this problem entirely.


<h3> What CSE 423 Should do About Type Names This Semester </h3>

We will do nothing special unless our careful reading of the Python Grammar determines that something is necessary.


<!--
Minimum:
<ul>
  <li> remember if any system include has been included, via global flags.
  <li> if stdio.h has been included, recognize FILE as a TYPEDEF_NAME.
       You can do this via a check in the lexer code for identifiers.
</ul>

Basic:
<ul>
  <li> build a "type name table", either a linked list or hash table that
    remembers all type names
  <li> lexer code for identifiers checks the table, returns TYPEDEF_NAME
       if a given identifier appears in the type name table, else IDENTIFIER
  <li> can generalize to a table that associates names with what category
    to return, so it can hold names from either TYPEDEF_NAME or
    ENUMERATION_CONSTANT (...or CLASS_NAME, etc.)
</ul>

Higher-power:
<ul>
  <li> in a real C compiler, you'd have to turn on and off "context flags"
    so that a name would return TYPEDEF_NAME in a context where a type
    is expected, and IDENTIFIER in a context where a type is not expected.
</ul>

Progressive:
<ul>
  <li> The Go language grammar was constructed such that it does not
       depend on these distinctions or entail such cheating!
</ul>
-->


<h3> Midterm Exam Date Discussion </h3>

We will need to have a midterm. It will be an in-class
(or in Student Access Services) midterm.


<h3> The YACC Value Stack </h3>

<ul>
<li> YACC's parse stack contains only "states"
</li><li> YACC maintains a parallel set of values
</li><li> $ is used in semantic actions to name elements on the value stack
</li><li> $$ denotes the value associated with the LHS (nonterminal) symbol
</li><li> $n denotes the value associated with RHS symbol at position n.
</li><li> Value stack typically used to construct the parse tree
</li><li> Typical rule with semantic action: A : b C d { $$ = tree(R,3,$1,$2,$3); }
</li></ul>



<h3> YACC Value Stack's Element Type: YYSTYPE </h3>

<ul>
<li> The default value stack is an array of integers
</li><li> The value stack can hold arbitrary values in an array of unions
</li><li> The union type is declared with %union and is named YYSTYPE
</li></ul>

<p>
<font size="1"> <a name="12">lecture #12</a> began here</font>
</p><p>

<h3> Midterm Exam Date Discussion </h3>

It will be an in-class (or in Student Access Services) midterm.
We voted for:
<ul>
<li> Friday March 10
</ul>

<h3> HW#2 Grading Status </h3>

<ul>
  <li> I am making progress grading the first batch of HW#2 submissions
  <li> I will probably post most of the grades before Wednesday's class
<li> Grading mistakes happen.  Feel free to explain your circumstances,
    especially if your
    program met the specifications exactly
    but didn't receive the grade it should.
<li> If you have a late submit/resubmit/regrade,
       I will try to do all of those after HW#2 grades are posted.
</ul>


<h3> Old Mailbag </h3>

<dl>
<dt> During my "make" the linker complains about redefinition of yyparse()
     and missing main(). What's going on?
</dt><dd> If your main() function is in puny.c, you had better not rename
     cgram.y as puny.y, or be careful if you do -- on at least some
     platforms (probably this refers to Linux and GNU make) the "make"
     program has default rules that assume if a .c file has the same name
     as a .y file, it is supposed to build the .c from the .y by running
     yacc and renaming the foo.tab.c as foo.c!

<!--
</dd><dt> My parser always dies on the first LBODY, what gives?
</dt><dd> Wow, this opened an awesome can of worms!  go.y as delivered
     by the go 1.2.2 compiler used two different codes for '{' in
     the grammar! In their lexical analyzer, which we are not using,
     they wrote:
<pre>	 * to implement rule that disallows
	 *	if T{1}[0] { ... }
	 * but allows
	 * 	if (T{1}[0]) { ... }
	 * the block bodies for if/for/switch/select
	 * begin with an LBODY token, not '{'.
	 *
	 * when we see the keyword, the next
	 * non-parenthesized '{' becomes an LBODY.
	 * loophack is normally 0.
	 * a keyword makes it go up to 1.
	 * parens push loophack onto a stack and go back to 0.
	 * a '{' with loophack == 1 becomes LBODY and disables loophack.
</pre>
     We will have to devise a strategy to deal with this.
<ul>
<li> "Just for fun" I changed all LBODY in go.y into '{' to see the fuss.
</li><li> result was: 2 shift-reduce conflicts. Presumably these are not the kind
     of shift-reduce conflicts I am used to ignoring.
</li><li> I looked at the conflicts details using <code>bison -v</code>, which
     writes a *.output file
</li><li> Deleting a couple of production rules under non-terminal pexpr_no_paren
     would "fix" the problem...
</li><li> One of the conflicting rules was actually already an error
     ("cannot parenthesize type in compusite literal")
</li><li> The other one might be for struct initializers. We can live without those
     in VGo.
</li><li> Summary: go.y was updated, it is recommended that you change all LBODY to
     '{' and delete a couple grammar production rules.
</li></ul>
-->
</dd><dt> What is <code>%prec</code> about?  What about %left and %right?
</dt><dd> Great question.  %prec TERM directs Bison to apply the
     current grammar rule with the precedence of TERM.  In a .y file,
     fake terminal symbols (like THEN) can be introduced to avoid
     shift/reduce conflicts.

     Note that neither %prec nor TERM are symbols on the righthand side of
     whatever production rule is being given -- if there aren't any other
     symbols then that precedence is being applied to an epsilon rule.

     %prec is used to apply some precedence rules specified via %left,
      %right etc. to production rules in the Bison grammar where there is
      not a symbol that can be declared as %left or %right.  %left and
      %right are in turn, Bison's way of tie-breaking ambiguous grammar
      rules that would otherwise generate shift/reduce or reduce/reduce
      conflicts.


</dd>
<dt> I am working on the tree but I am confused as to how to approach
    it. For example package has the following rule:
<pre>package: LPACKAGE sym ';'</pre>

The tree struct shown on the HW assignment sheet has kids which
are of type <code>struct tree</code> and a leaf which is of
<code>struct token</code>. Since package
has two tokens the LPACKAGE and ';' how should I approach saving this
to the tree struct. Should everything be saved under kids? With how I have
my %union right now, LPACKAGE and ';' are tokens and sym is struct tree.

</dt><dd> The example tree type in the HW spec, which you are not required
    to follow, illustrates
one possible way to incorporate terminal symbols as leaves.  If you follow
it, separate from your struct token for each leaf you allocate a struct tree,
with 0 children, whose prodrule is the token's terminal symbol #, and for
a treenode with 0 children and a terminal symbol as a prodrule, the code that
goes back through the tree afterwards would know to not visit the children
array, but instead look at the leaf field for a token.
To do all this with your current %union with pointer to struct token on the
tree for terminal symbols, every time you are about to insert a tree node
with terminal symbols, you would allocate a leaf node to hold the token *.
So your rule for a package would allocate three tree nodes total, one for
the parent and two for the two terminal symbols being placed into leaves.
There are other ways that one can get it done, but this would work.

</dd></dl>

<h4> Getting Lex and Yacc to talk </h4>

<ul>
<li> YACC uses a global variable named <code>yylval</code>, of type YYSTYPE,
to receive lexical information from the scanner.
</li><li> Whatever is in this variable <code>yylval</code> gets copied onto the
top of the value stack each time <code>yylex()</code> returns to the parser
</li></ul>
<p>

Options:
</p><ol>
<li> Declare that struct token may appear in the %union.
     In that case the value stack is a mixture of struct node
     and struct token.  You still have to have a mechanism for
     how do tokens get wired into your tree. Are all children
     of type union YYSTYPE, and you use the prodrule R
     to tell which are which?
</li><li> For each terminal symbol, allocate a "leaf" tree node with 0 children
     and point its "leaf" field at your struct token.  0 children implies
     "don't use the kids field" and "a non-null leaf might be present"
</li><li> declare a tree type that allows tokens to include
     their lexical information directly in the tree nodes, perhaps tree nodes
     contain a union that provides EITHER an array of kids OR a struct token.
</li></ol>

If you have more than one %union type possible, be prepared to see type
conflicts and to declare the types of all your nonterminals.

<p>

Getting all this straight takes some time; you can plan on it.  Your best
bet is to draw pictures of how you want the trees to look, and then make the
code match the pictures. Given pictures, I can help you make the code do
what the pictures say.  No pictures == "Dr. J will ask to see your
pictures and not be able to help if you can't describe your trees."


</p><h3> Declaring value stack types for terminal and nonterminal symbols </h3>

Unless you are going to use the default (integer) value stack, you will
have to declare the types of the elements on the value stack.  Actually,
you do this by declaring which
union member is to be used for each terminal and nonterminal in the
grammar.
<p>
Example: in the cocogram.y that I gave you we could add a %union declaration
with a union member named treenode:
</p><pre>%union {
  nodeptr treenode;
}
</pre>

This will produce a compile error if you haven't declared a nodeptr type
using a typedef, but that is another story.  To declare that a nonterminal
uses this union member, write something like:
<pre>%type &lt; treenode &gt; function_definition
</pre>

Terminal symbols use %token to perform the corresponding declaration.
If you had a second %union member (say struct token *tokenptr) you
might write:
<pre>%token &lt; tokenptr &gt; SEMICOL
</pre>

<h3> Examples </h3>

<A href="ch5_v4a.pdf">Chapter 5 of Building Your Own PL</A>



<h3> Mailbag </h3>

<dl>
<dt> My compiler is complaining about strdup being missing. What up?
</dt><dd> It turns out -std=c99 removes strdup() because it is not part of that
     standard.  Possibly solutions include: not using -std=c99 when compiling
     files that call strdup(), or writing/providing your own strdup().

</dd><dt> When I compile my .y file, bison complains spitting out a bunch of
     warnings about useless nonterminals and rules. how much attention
     should I pay to this?
</dt><dd> "Useless" warnings sound innocuous, but they mean what they say.
     You probably have something wrong that will have to be fixed.
     Everything but shift/reduce conflicts is potentially serious, until
     you determine otherwise. If you can't figure out what some Bison error
     is after giving it the reasonable college try, send it to me by e-mail
     or schedule an appointment.  If I am not available or you are remote,
     we may schedule a Zoom meeting.  You might have to learn some Zoom.
     I might have to setup a camera on my many machines, and remember my
     Zoom credentials.
</dd><dt> I've been trying to implement implicit concatenation in the grammar
     and I'm getting reduce/reduce errors. Do you have any tips for
     implementing implicit concatenation? Should I make specific rules
     for concatenating strings and lists and stop trying to integrate
     it into my expression syntax?
</dt><dd> If you can't get implicit concatenation working, you might resort
     to explicit concatenation via (perhaps) the + operator. Tips to avoid
     reduce/reduce errors include: avoid epsilon rules. MERGE rules that
     look like the same thing (in Ada, functions and arrays both used the
     same syntax!  sad!).  Incidentally, neither Unicon nor Java have
     implicit concatenation, so in g0 it is a "can we do it?" question.
     I would be happy to consult with folks on your grammarly endeavors
     in office hours and additional appointments.

</dd><dt> It seems we soon will have to implement a hash table.
     If this is the case, what would be a reasonable size (# buckets) of
     the table?  n=20?
</dt><dd> Fixed-size tables should use a prime. For the size of inputs
     I will ever manage in this class, probably a prime less than 100 would do.
     How about n=41 ?
<!--
<dt> Are we just supporting class, enum, typedef, and namespace identifiers and <em>not</em> structs?
<dd> 120++ has to my knowledge class, typedef, and struct but not
     enum or namespaces other than std.  Furthermore, typedef and
     struct are only mentioned in passing and not used significantly.
     About the only mention of them is
<pre>
typedef struct pet {
int happy;
int hunger;
char name[100];
} pet;
pet pet1, pet2;
</pre>

For the purposes of our class, the Best thing to do would be to
make the "type names table" record, for each name, whether it was
a struct label, a typedef name, or a class name.  However, it will
sufficient if all you managed was to return CLASS_NAME
instead of IDENTIFIER for names that were declared as the names of
classes.

-->
</dd></dl>


  <h3> Top Issues w/ HW#2 </h3>
  <ul>
    <li> you can't just strcat() onto the end of argv[i]
      <pre>
int main(int argc, char *argv[]) {
   for(i=1;i&lt;argc;i++) {
      char *filename = argv[i];
      int len = strlen(filename);
      if ((len &lt; 5) || strcmp(filename+len-5, ".java"))
          strcat(filename, ".java");
      yyin = fopen(filename, "r");
      /* ... rest of compiler */
   }
}
</pre>

<li> Java compiler writers, you need to include a puny executable such as
      <pre>#!/bin/sh
java puny $*
</pre>
</ul>


<h3>Mailbag</h3>

<dl>
<dt> My syntax checker seems to be having some issues on control words such as for, while etc.. Interestingly enough if I replace the return type of these statements in my .l file with an integer return type then the error goes away.
<dd> return type of yylex() definitely must be int and the integers returned
  definitely must be those yyparse() #define's in a .tab.h file generated
  by running "bison -d" on the .y file.  To check if lexer and parser are
  talking OK, turn on global variable yydebug=1 in main() before calling
  yyparse() (and turn on YYDEBUG in the .y file if its not on already).

<dt> My HW didn't get all the points. Can I resubmit with fixes?
<dd> In many cases you need the fixes for use in your compiler the rest
    of the semester.
<blockquote>
     Generally, if an initial submission was fail, I accept a
     resubmission for partial credit up to a passing grade.  If a
     submission fails for a trivial reason such as a missing file, I might
     ask you to resubmit with a lighter penalty.
</blockquote>
     As a reminder, I do Not grade on a 90/80/70/60 scale.
</dl>

<p>
<font size="1"> <a name="13">lecture #13</a> began here</font>
</p><p>

<H3> How to interpret your HW#2 Grade </h3>

<ul>
<li> This was our "getting more acquainted with Dr. J" homework
<li> Later homeworks will be weighted heavier
<li> What was tested is not a complete representation of your work
<li> I do not grade on a curve
<li> I do grade you relative to your peers
<li> I do correct grades when mistakes happen
<li> ... catch up, persevere, and/or seek more help as needed
</ul>
</p>

<h3>Old Mailbag</h3>

<dl>
<!--
<dt> I haven't been able to find a way to edit the yylex() that's generated
     (in order to semi-colon insertion).
</dt><dd> You aren't supposed to do this manually, you are supposed to do it
     automatically with a computer program whenever you (re)make it. Per
     a previous class discussion, there are several UNIX tools that could
     do this, including the option of writing a C program or a flex program
     to do it.  But one of the simplest options may be something like the
     following in your makefile:
<pre>lex.yy.c: lex.l
	flex lex.l
	sed -i 's/yylex/myyylex/g' lex.yy.c
</pre>

</dd>
-->
<dt> In the example <code>A : b C d {$$ = tree(R,3,$1,$2,$3);} ;</code>
Suppose C is a terminal and b and d are non-terminals. Then $2 will be
OK, but when will I be able to get the data that $1 and $3 need to
be set to?
</dt><dd>Bison parsers are bottom up. You don't reduce this grammar rule
or execute this code until sometime after the handle <code>b C d</code>
has already been parsed, and in that process the production rules for
b and d have already executed, just as surely as the shift of C which
placed whatever yylval held at that time onto the value stack in $2.
If the rules for b and d had actions that said {$$=...} at that point
in the past, then $1 and $3 now will be holding what was assigned to $$
back in those rules' semantic actions.

</dd><dt> In the example <code>A : b C d {$$ = tree(R,3,$1,$2,$3);} ;</code>
     to what doth R refer?
</dt><dd> R was intended to be an integer code that allows you to tell, when
     walking through the tree later on, what production rule built that node.
     I would typically do a code for each nonterminal, gapped large enough
     that R can be (nonterminal+rule#forthatnonterminal).  Suppose this was
     the first of three production rules that build an A.  The integer might
     be (__A__ + 1) to denote the first A rule.

</dd><dt> I'm considering having some sort of stack that keeps track of the parent
     you should currently be attaching children to.
</dt><dd> You can do anything you want, but bison's value stack is that stack and
     and at each level you should allocate a node for $$ and attach all of its
     children. That is it.

</dd><dt> Should we be defining our own integer codes for token types or just use
 the ones in our *.tab.h file from HW#1?
</dt><dd> You can't define your own codes, you have to use the codes that bison
 generates. You'll have to modify your lexer to use bison's integers, or your
 flex and bison will not work together.

</dd><dt>Are yylval's types defined in the %union?
</dt><dd>Yes, yylval is of type YYSTYPE, the type bison generates for the %union.
</dd><dt> What is the actual value of a $n variable?
</dt><dd> Before your bison grammar's semantic action code triggers, $1, $2, ... 
     etc. will be holding either (A) whatever you put in yylval if the
     corresponding symbol is a terminal, or (B) whatever you put in $$
     for its rule if the symbol is a non-terminal.
  
</dd>
<!--
<dt>Do we have to implicitly concatenate <em>sub</em>strings?
</dt><dd>Yes, substrings are strings.
</dd>-->
<dt> What is required of a for-statement?
</dt><dd> You don't have to do a declaration of a variable in a for initializer.
      Saying <code>for(int i=1; ...)</code> was a C++ thing.
<!--
<dt> what's a declarator?
<dd> A portion of a variable declaration, not including the base type,
     which includes the variable's name and pointer/reference/array status.
     It may optionally include an initializer.  Here is a definition from
     <A href="https://msdn.microsoft.com/en-us/library/86zce4y8.aspx">MS</A>.
<p>
Examples:

<pre>
int x;      // declarator is x
int x, y=5; // declarators are x and y=5 in a declarator list
char *s[3]; // declarator is *s[3]
</pre>

-->
</dd>

<dt> I have spent 30 hours and am not close to finishing adding the
     hundreds of grammar rules and tree construction semantic actions
     required for HW#2!
</dt><dd> As a professional programmer, you should invest time to master
     a powerful programmer's editor with a key-memorizing macro facility
     that can let you insert semantic actions (for example)
     very rapidly.  If you've been typing them in by hand, ouch!
     Paste the right thing 500 times and then just tweak.  Or paste all
     the constructors with the same number of children in batches, so
     you have less to tweak because you already pasted in the right number
     of kids.

<!--
<dt> Your reference parser reports a bogus error on this simple
     120++ program of mine that uses strings:
<pre>
int main(){
  string name;	
}
</pre>
<dd> Yes, this is an error. It is not bogus.  Interestingly,
g++ still reports a syntax error if you add #include &lt;string&gt;.
In order to recognize the non-built-in type string, the
C++ program has to have "using namespace std;" and include one of:
&lt;string&gt;, &lt;iostream&gt;, or &lt;fstream&gt;.  It turns out the
{io,f}stream  includes include &lt;string&gt;.  If these conditions are
present, you should insert "string" into a type names table, such that
your lexical analyzer returns CLASS_NAME when it sees <code>string</code>.

<dt> Your new reference parser reports a bogus error on this simple
      120++ program that declares a class:
<pre>
class Foo{
public:
   Foo();   
   int play();
};
Foo::play(){
  return 0;
}
</pre>
<dd> Aside from probably needing the reserved word "int" before
Foo::play, the reference code posted does not populate the
"type names table" with the names of classes that it encounters.
Part of HW#2 would include this feedback from the parser to the
lexical analyzer.
-->

</dd><dt> Do I need to add <code>%type &lt;treeptr&gt; nonterm</code> for every
non-terminal symbol in the grammar in order to have everything work
</dt><dd> yes. If you are lucky, the %type's are in there in a comment, and all
you have to do is uncomment them and add the <code>&lt;treeptr&gt;</code>
(or whatever) part.
<!--
<dt> when we run into using namespace std; we place string into our
      type name table, but what about cin/cout/endl ?
<dd> In HW#2 we only need the names of types, because they are needed in
      order to parse successfully and not get syntax errors. In addition
      to string, the type names ifstream, ofstream, and fstream
      appear in 120++ and should get added if the include(s) and
      "using namespace std" appear in the program.
-->
</dd><dt> Are we supporting (syntactically) nested classes/structs?
</dt><dd> no
<!--
<dt> Do we have to parse anything with ::
<dd> classname::function name (including classname::constructor) appear to
     be the only uses of :: in 120++.
-->
</dd><dt> What do I do with epsilon rules? Empty tree nodes?
</dt><dd> I previously said to use either $$ = NULL or
     <code>$$ = alctree(RULE, 0)</code>.
     Whether the latter is preferable depends on what will make your
     tree traversals easier later on, in HW#3, and maybe whether the
     encoding of an empty leaf with RULE would help you in reading the
     tree and knowing what to do with it.  Saying $$=NULL
     implies you will have to check children to see if they are NULL
     before you try to visit them.  Never setting $$ to NULL means you
     can "blindly" traverse child pointers if a parent has nkids &gt; 0.

</dd><dt>
All of the leaves in the tree structure are/can be made of lex tokens. To
that point then, what are the non-leaves supposed to be? I think I may have
over thought this point so I am not quite sure.

</dt><dd> Non-leaves (i.e. internal nodes) correspond to non-terminal symbols,
built from particular production rules.

</dd><dt> For the structure of the tree, HW#2 provides a possible "setup".
<pre>struct tree {
   int prodrule;
   int nkids;
   struct tree *kids[9];
   struct token *leaf;
}
</pre>

While I understand nkids (number of kids this node has), *kids[9] (a pointer
array to up to 9 kids), and leaf (the lex token), what exactly is the
prodrule?  I am fairly certain that this is the production rule, but I am
not exactly sure what it associates with.

</dt><dd> The prodrule integer encodes what production rule was used
to build this node, which includes (of course) what non-terminal it represents,
and what syntactic role its children played.  By the way, *kids[9] is
an array of 9 pointers to kids, not a pointer to an array of nine kids.


<!--
<dt>  When I add implicit concatenation, Bison doesn't know whether (x - y)
      is a subtraction, or a concatenation of (x) and (-y).  It gives me
      33 reduce/reduce conflicts!  What do I do?

<dd> Possible solutions include:
<ol>
<li> get rid of implicit concatenation (the "Sorry Dr J" approach)
<li> get rid of unary minus, let's use ~ (eeww!) for unary minus
<li> wiggle around the reduce-reduce conflict, perhaps using Bison's
     precedence and associativity, or just the default tie-breaker
<li> get fancier about lexical rules in which unary minus would apply.
     For example, we could say the spaces are not so optional for one or the
     other.
<li> restrict concatenation to only apply to a subset of expressions such
     as adjacent string literals, or those plus variable names
<li> ... several others in class have worked on it, what have you come up with?
</ol>
-->


<!--
<dt> Will we be using any of the following features?
<dd>
By "using" you mean: supporting in your compiler.
Based on my current understanding:

<dl>
<dt>C++-style constructors for native types (i.e. double d(1.0);)
<dd>Not required.
<dt>The sizeof operator
<dd>Not required.
<dt>Array new/delete
<dd>Not required. new/delete only of single class instances. The book
    mentions "new int" in passing, but it is not used in programs.
<dt>The ternary operator (?:)
<dd>Not required.
<dt>Function pointers
<dd>Not required.
<dt>Fixed-size array declarations (i.e. int i[10];)
<dd>Required. These are used in Chapter 6 of 120++.
<dt>Brace initializers (i.e. int i[] = {1, 2, 3};)
<dd>Not required.
</dl>
-->

</dd><dt>
What exactly is in $1 or $2 or ... when I am at a reduction building a
tree node in $$ for some non-terminal?
</dt><dd>
<ul>
<li> If the rule's first righthandside symbol is a terminal, what is in
$1 is whatever you assigned to yylval when that terminal was matched in yylex.
</li><li> If the rule's first righthandside symbol is a non-terminal, what
is in $1 is whatever you assigned to $$ when that non-terminal was reduced.
</li></ul>

<!--
<dt>
Even though open hashing is recommended, do you lose points for
implementing hash tables with closed hashing instead?
<dd>
Hashing is not required until homework #3.
Not unless the tester constructs a test that exceeds your limits...which he
might. If you use closed hashing, use a bigger bucket size since you won't
handle overflow gracefully. 10K for global symbol table, 1K for local symbol
tables is probably sufficient.  Actually, we could calculate a much smaller
lower bound for g0, how would we go about doing that?
-->

</dd><dt>
I was wondering if it is ok to have a linked list of syntax trees, where the
syntax tree for the current source file be inserted into a linked list (of
syntax trees), then at the end of main(), after generating syntax trees for
each file in command line argument, walk through the linked list and print
out each syntax tree.

</dt><dd>
What is expected is that for each file, you build the tree,
return to main(), print it out, and then move on to the next filename. But
building a linked list of trees and looping again over that to print things
out would be fine. The main thing between each file on the command line is to
clear out the type name table; each file is being compiled independently of
whatever came before them during that compilation process.

</dd></dl>



<h3> Conflicts in Shift-Reduce Parsing </h3>

"Conflicts" occur when an ambiguity in the grammar creates a situation
where the parser does not know which step to perform at a given point
during parsing.  There are two kinds of conflicts that occur.

<dl>
<dt> shift-reduce
</dt><dd> a shift reduce conflict occurs when the grammar indicates that
     different successful parses might occur with either a shift or a reduce
     at a given point during parsing.  The vast majority of situations where
     this conflict occurs can be correctly resolved by shifting.
</dd><dt> reduce-reduce
</dt><dd> a reduce reduce conflict occurs when the parser has two or more
     handles at the same time on the top of the stack.  Whatever choice
     the parser makes is just as likely to be wrong as not.  In this case
     it is usually best to rewrite the grammar to eliminate the conflict,
     possibly by factoring.
</dd></dl>

Example shift reduce conflict:
<pre>S-&gt;if E then S
S-&gt;if E then S else S
</pre>
<p>
In many languages two nested "if" statements produce a situation where
an "else" clause could legally belong to either "if".  The usual rule
(to shift) attaches the else to the nearest (i.e. inner) if statement.
</p><p>


<h3>Mailbag</h3>

<dl>
<dt> I don't get how to start tree traversal. <A href="lab4.html">Lab #4</A>
    at the bottom seems
     to be about that but I can't just paste that into my code.
<dd> yyparse() should build a syntax tree, but it returns an integer that
  indicates whether there were parse errors.  You either traverse your
  tree inside yyparse() before it returns (a bit weird) or you traverse
  your tree outside yyparse() after it returns...by assigning the tree to
  a global variable.

<dt> I have mysterious syntax errors, what do I do?
</dt><dd>
<ul>
<li> make sure that your lexer is including the .tab.h that corresponds to
     your bison file
</li><li> #define YYDEBUG and set yydebug=1 and read the glorious output, especially
   the last couple shifts or reduces before the syntax error.
</li><li> implement semi-colon insertion
</li></ul>
</dd><dt> I can't fix some of the shift/reduce conflicts, what do I do?
</dt><dd> Nothing. You do not have to fix shift/reduce conflicts.
</dd><dt> I can't fix some of the reduce/reduce conflicts, what do I do?
</dt><dd> These generally reflect a real bug and will cost you a few points on HW,
     but they mighty or might not cost you more points on test cases.
     It is only
     a deal breaker and has to be fixed if it prevents us from parsing
     correctly and building our tree. Sometimes epsilon
     rules can be removed successfully by adding grammar rules in a
     parent non-terminal that omit an epsilon-deriving child, and then
     modifying the child to not derive epsilon. This might or might not
     help reduce your number of reduce/reduce conflicts.

</dd><dt>With the default error handling, I am getting an error on the last line of
the file: syntax error before '' token. It looks like an EOF error, but I
cannot figure out how to fix it, as when I add an &lt;&lt;EOF&gt;&gt; rule to my lexer,
it just hangs there, and still produces this error.

</dt><dd> Error on EOF might be because the grammar expects one more semi-colon,
     maybe your EOF regex should return one the first time it hits in each
     file.  By the way, I usually don't have to write a &lt;&lt;EOF&gt;&gt;
     regex, yylex() returns the value on EOF that yyparse() expects.
     If you enable YYDEBUG and turn on yydebug you will get a detailed
     explanation of the parse and where it is failing when you run your
     parser, which may help you.  Feel free to schedule a Zoom session.

</dd></dl>



Example reduce reduce conflict:
</p><pre>(1)	S -&gt; id LP plist RP
(2)	S -&gt; E GETS E
(3)	plist -&gt; plist, p
(4)	plist -&gt; p
(5)	p -&gt; id
(6)	E -&gt; id LP elist RP
(7)	E -&gt; id
(8)	elist -&gt; elist, E
(9)	elist -&gt; E
</pre>
By the point the stack holds ...id LP id<br>
the parser will not know which rule to use to reduce the id: (5) or (7).


<h4> Another Example Reduce Reduce Conflict </h4>

The following grammar, based loosely on an expression grammar,
illustrates a reduce reduce conflict, and how you have to
exercise care when using epsilon productions.  Epsilon productions
were helpful for some of the grammar rewriting methods, such as removing
left recursion, but used indiscriminately, they can cause much trouble.

<pre>T : F | F T2 ;
T2 : p F T2 | ;
F : l T r | v ;
</pre>

The reduce-reduce conflict occurs after you have seen an F.  If the next
symbol is a p there is no question of what to do, but if the next symbol
is the end of file, do you reduce by rule #1 or #4 ?
<p>


</p><h4> Another Example Shift Reduce Conflict </h4>

A slightly different grammar is needed to demonstrate a shift-reduce conflict:

<pre>T : F g;
T : F T2 g;
T2 : t F T2 ;
T2 : ;
F : l T r ;
F : v ;
</pre>

This grammar is not much different than before, and has the same problem,
but the surrounding context (the "calling environments") of F cause the
grammar to have a shift-reduce instead of reduce-reduce.  Once again,
the trouble is after you have seen an F and dwells on the question of
whether to reduce the epsilon production, or instead to shift, upon
seeing a token g.
<p>

The .output file generated by "bison -v" explains these conflicts in
considerable detail.  Part of what you need to interpret them are the
concepts of "items" and "sets of items" discussed below.

</p><p>

<p>
<font size="1"> <a name="14">lecture #14</a> began here</font>
</p><p>

<h3> Puny Language Clarification: For-Loops </h3>

I talked with our CSE 107 instructor about what kinds of loops PunY has to
support. He said we have to do while loops, plus the following kinds of for-loops.

<dl>
<dt> for v in range(stop)
<dd> loop some variable from 0 to stop-1
<dt> for v in range(start,stop)
<dd> loop some variable from start to stop-1
<dt> for v in range(start,stop,step)
<dd> loop some variable from stop to stop-1, changing value by step each
      time
<dt> for v in x:
<dd> loop some variable through values in list or tuple x
</dl>

So far, I have been hoping for PunY that we'd just get by with lists and not
bother with tuples.  How realistic is that for basic Python programming?


<h3>How To Make Labs More Useful and Productive</h3>

<ul>
<li> Our Wednesday Lab Hour exists in order to help you do homeworks
<li> I would like to hear any ideas you have about
     how to make that time more useful for you.
</ul>

<a name="precedence">
</a></p><h4><a name="precedence"> YACC precedence and associativity declarations </a></h4><a name="precedence">
</a>

YACC headers can specify precedence and associativity rules for otherwise
heavily ambiguous grammars.  Precedence is determined by increasing order
of these declarations.  Example:

<pre>%right ASSIGN
%left PLUS MINUS
%left TIMES DIVIDE
%right POWER
%%
expr: expr ASSIGN expr
    | expr PLUS expr
    | expr MINUS expr
    | expr TIMES expr
    | expr DIVIDE expr
    | expr POWER expr
    | IDENT
    ;
</pre>

  
<a name="yyerror">
<h4> YACC error handling and recovery </h4>
</a>
<ul>
<li> Use a special predefined token <code>error</code> where errors expected
</li><li> On an error, the parser pops states until it enters one that has an
    action on the error token. Then it discards input symbols until what
    follows the error token would be legal.
</li><li> For example: statement: error ';' ;
</li><li> The parser must see 3 good tokens before it decides it has recovered.
</li><li> yyerrok tells parser to skip the 3 token recovery rule
</li><li> yyclearin throws away the current (error-causing?) token
</li><li> yyerror(s) is called when a syntax error occurs (s is the error message)
</li></ul>


<h3> Improving (YACC, Bison) Syntax Error Reporting </h3>

<code>yyerror(s)</code> overrides the default error message, which usually
just says either "syntax error" or "parse error", or "stack overflow".

<p>

You can easily add information in your own <code>yyerror()</code> function.
For example, for decades GCC emitted messages that look like:
</p><pre>goof.c:1: parse error before '}' token
</pre>
<p>

You can do at least that good using a <code>yyerror()</code>
function that looks like
<pre>void yyerror(char *s)
{
   fprintf(stderr, "%s:%d: %s before '%s' token\n",
	   yyfilename, yylineno, s, yytext);
}
</pre>
Reminders:
<ul>
  <li> <code>yytext</code> is provided by <code>yylex()</code>
    but only good for the current token.
    <li> The <code>s</code> passed into
<code>yyerror()</code> is not very specific and we might like to do better.
<li> Flex can generate a line number for you if you give it the right option,
but once again it is only good for the latest/current token.
<li> <code>yyfilename</code> is something you would have to
  declare and maintain yourself.
  </ul>
<p>

You could instead, use the error recovery mechanism to produce better messages.
For example
</p><pre>lbrace : LBRACE | { error_code=MISSING_LBRACE; } error ;
</pre>
Where <code>LBRACE</code> is an expected token {<br>
This uses a global variable error_code to pass parse information to yyerror().
<p>

Another related option is to call yyerror() explicitly with a better message
string, and tell the parser to recover explicitly:
</p><pre>package_declaration: PACKAGE_TK error
	{ yyerror("Missing name"); yyerrok; } ;
</pre>
<p>

But, using error recovery to perform better error reporting runs against
conventional wisdom that you should use error tokens very sparingly.
What information from the parser determined we had an error in the first
place?  Can we use that information to produce a better error message?


<p>
<font size="1"> <a name="15">lecture #15</a> began here</font>
</p>
<p>

  <h3>Mailbag</h3>

  <dl>
<dt> You dinged me a point. You should give it back.
<dd> If I was incorrect about a grade I will gladly look into it.
  You may want to post a message on Canvas so it doesn't slip through
  our fingers.

<dt> You didn't test everything that I did!  I worked hard!
<dd> My tests will generally be the most obvious CSE 107-type programs I can
  think of, a pretty tiny sampling of the infinite range of possibilities.
  If PunY were a research or development project that we planned to release,
  we'd have to write a lot more tests.  In fact, one or more of you has
  indicated that you've written more tests, and if you care to share them,
  I may add them to a standard suite that gets run on each subsequent homework.

<dt>

What do we do with TYPE_COMMENT, and some other Python-not-Puny keyword
statements (for example ASYNC, IS NOT, NOT IN)?  Are we just remove them
completely from the grammar?

<dd>

If they result in error-exits in the lexical analyzer, it may be possible to
remove them entirely from the grammar.  My only hesitation on this point is
that removing them from the grammar may in some circumstances cause the
parser to report a syntax error before it even gets to the illegal token,
causing confusing or misleading syntax error messages for some
Python-not-Puny constructs. I'd advise removing such rules from the grammar,
but saving them somewhere and restoring them if it turns out that the
misleading premature syntax error messages are a real thing and not just
hypothetical.
 
<dt>

What should be the value for (int) production rule in alctree()?
Should I just give it some make-up integer? Like 1004, 1005, 1006,...

<dd>

Yes, you can just make up integer codes, I recommend codes that are not
overlapping with tokens, so starting at 1000 is not a bad idea.
 
<dt>

I can't still quite understand how I can correctly make the root tree - how
do we supposed to start the root in the start symbols?  From what I see,
there are 3 types of start symbols: single_input, file_input, eval_input. So
am I supposed to put { $$=alctree(...); root=$$; } to all of them?  Also, do I
put the { $$=alctree(...); root=$$; } in all different cases (I would call them
supporting grammar I think?, as in file_input_prime used in file_input) of a
start symbol, or have to find the right one to put that statement?

<dd>
  
In Bison there is really only one start symbol. Python seems to sort of want
three of them, but for PunY we only have one, and it is file_input.  If
there are multiple production rules that build the start symbol, you would
assign the root in each of them.  If you assigned to root everywhere, it
would be silly but OK/harmless in that the last one assigned is probably the
one that is for the "real" start symbol.
 
<dt>
In this rule in the file:
<pre>
import_from: ('from' (('.' | '...')* dotted_name | ('.' | '...')+)
              'import' ('*' | '(' import_as_names ')' | import_as_names))
</pre>

They say: # note below: the ('.' | '...') is necessary because '..' is
tokenized as ELLIPSIS. So should I put '...' as it is or should I add a
token called ELLIPSIS which takes in 3 dots?

<dd>

Yes, Python has a DOT token and it has an ELLIPSIS token. The "from
..... import" grammar rule allows an arbitrary number of periods before a
name, which means it has to allow any number of either DOT or
ELLIPSIS. However, PunY does not have from...import.

<dt>

In some long grammars in the punygram.y, I'm a bit confused how the OR ( the
vbar | ) works.  Does it just use the OR on one word before and after the
vbar?  For example, I have this grammar:

optional_comma_test: ',' test | {  $$=NULL; };

So in which way the parser will understand this?

optional_comma_test:          ( ',' test ) | {  $$=NULL; }     ;
optional_comma_test:   ','    ( test        | {  $$=NULL; } )      ;
And should I just put parenthesis in cases like this?

<dd>

Vertical bar is the lowest possible precedence and actually denotes the
start of another production rule, so your interpretation #1 is used without
need for parentheses. Parentheses are not used in Bison to force precedence.
 
<dt>
  
Do we do decorator grammar(since it has '@' which is not supported by Puny),
or any grammar rule involves symbols that are not supported by Puny?

<dd>
See the answer to question 1.

<dt>
Should we make tree for optional type of grammar?
An example is optional_expr: expr | {  $$=NULL; } ;

<dd>

This example shows two production rules. The first one has only one child
and does not require a new tree node. The second one has zero production
rules and can be represented by either NULL or by a special leaf that
represents the epsilon.
 
<dt>
  
How are we supposed to make tree for a prime_type_grammar: for example,
I did:
<pre>
statements: stmt stmt_prime;
stmt_prime: stmt_prime stmt;
stmt_prime: {  $$=NULL; } ;
</pre>

(which is equivalent to the following)
<pre>
  statements: stmt statements;
  statements: stmt ;
</pre>

How do we make tree for this? (do alctree for the first two statements?)

And am I doing this correctly at all? I saw your file_input_prime in the lab
and I just copied the way.

As of typing it right now, I saw 1 of your mailboxs answer saying to just
make a epsilon leaf node tree for epsilon rule, so if I just do that for all
grammar rules, will that solves this question?

<dd> 

In this example stmt_prime has two production rules. The first one has two
symbols on the righthand side and needs a binary tree node for those two
children. The second production rule is an epsilon and needs either a NULL
or a special leaf that represents the epsilon.

</dl>

<h3> Clarification on Error Recovery Behavior </h3>

Last time, I was kind of left wondering why I claimed that
<pre>
statement: error ';' ;
</pre>
would let you recover from errors when you get to the end of a statement.
As a student noted, it looks like it would only work if the error was the
last thing before a semi-colon, but usually errors happen in the middle,
and a bunch of input symbols have to be discarded before we would get to
a semi-colon.  I have adapted the answer here from the
<A href="https://www.gnu.org/software/bison/manual/html_node/Error-Recovery.html">Bison manual</A>.

<p>

<blockquote>

What happens if a syntax error occurs in the middle of an expression?  The
error recovery rule, interpreted strictly, applies to the precise sequence
of a <code>statement</code>, an error and a semicolon. If an error occurs in
the middle of an expression, there will probably be some additional tokens
and subexpressions on the stack after the last stmts, and there will be
tokens to read before the next newline. So the rule is not applicable in the
ordinary way.

<p>

But Bison can force the situation to fit the rule, by discarding part of the
semantic context <em>and part of the input</em>. First it discards states
and objects
from the stack until it gets back to a state in which the error token is
acceptable. (This means that in performing error recovery,
the current statement's <b>subexpressions already parsed are
discarded</b>, back to the last complete statement.) At this point the error token
can be shifted. Then, if the old lookahead token is not acceptable to be
shifted next, the parser <em>reads tokens and discards them</em> until it finds a
token which is acceptable. In this example, Bison reads and discards input
until the next newline so that the fourth rule can apply. Note that
discarded symbols are possible sources of memory leaks, see Freeing
Discarded Symbols, for a means to reclaim this memory.
</blockquote>



</p><h3> LR Syntax Error Messages: Advanced Methods </h3>

The pieces of information that YACC/Bison use to determine that there
is an error in the first place are the parse state (yystate) and the
current input token (yychar). These are exactly the pieces of information
one might use to produce better diagnostic error messages without
relying on the error recovery mechanism and mucking up the grammar
with a lot of extra production rules that feature the <code>error</code> token.
<p>

<ul>
  <li> Knowing even just the parse state is enough to do pretty good error messages.
  <li><code>yystate</code> is not part of YACC's public interface!
  <li> you may have to play some tricks to get the information
    into <code>yyerror()</code> from <code>yyparse()</code>.
  <li> In Bison, <code>yystate</code> is a local variable.
  <li> You could pass <code>yystate</code> as a parameter for <code>yyerror()</code> to access it. Say, for example:
</p><pre>#define yyerror(s) __yyerror(s,yystate)
</pre>
</ul>

Inside <code>__yyerror(msg, yystate)</code> you can use a switch statement
or a global array to associate messages with specific parse states.  But,
figuring out which parse state means which syntax error message would be by
trial and error.
<p>



</p><h3> Mailbag </h3>

<dl>
<dt> I got my trees printing for toy examples, am I done?
</dt>
<dd> You are responsible for thoroughly testing your code,
     including constructing test cases. For homeworks from
     now on, try and provide tests so that each tree-constructor
     code fragment that you write gets used by at least one test case
     (achieve statement-level test coverage).  We will have one
     or more labs on constructing test cases.
 <!-- I came up with the
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/vgotest/">go 1.2.2 test suite</a>.  Can we use it as is?  Almost every
test will use features in Go but not in VGo (things like :=), so we have to translate
them into VGo to use them.  We can either leave this all up to you, or we can
collaborate on it, your choice.-->

</dd>
<!--<dt> I get syntax errors on <code>else</code>. What up?
</dt><dd> By running code samples on a real compiler for our language,
    ("go build foo.go") one
can tell whether a given test case was legal or not. It turns out, if you
do an else, it has to be on the same line as the closing curly brace that
precedes it.  I have adjusted the <a href="https://www.cs.nmt.edu/~jeffery/courses/423/vgo.html">VGo Specification</a>
accordingly.

</dd>-->

<dt> I've got reduce/reduce errors! What do I do?
<dd>
<ul>
<li>Run "bison -v" to generate the .output file for your grammar.
<li>Look for "reduce/reduce" conflicts in that .output file
<li>Learn to read the .output file's notation, including the concept
  of items.
<li>Modify your grammar. Maybe refactoring to remove epsilon productions
    or merge duplicating sets of production rules for similar syntaxes.
<li> Oh look, thank you for providing an example with a .output file, let's
     look at it together.
</ul>

</dl>



<h3> Merr </h3>

Last time we ended pointing out that your parse state (yystate) and current
token (yychar) were how Bison discovers you have a syntax error. You can
write a different message for each parse state, or in the extreme case you
could write a different message with each (yystate,yychar)
tuple, and provide wayyy better syntax error messages than just saying
"parse error".
<ul>
<li> The Icon programming language is where I learned to use yystate in
    this way.
<li> Knowing what parse state goes with what error message was evolved
  by manual trial and error!
<li> My Icon project ancestors only worked out a custom message for the
  top 30 or 40 most frequent syntax errors.
<li> Even that much was so difficult to do by hand that we were advised not
  to change the language grammar (a poor policy for a research language)
<lI> Worse: every time you change the grammar all the parse
  state numbers might completely change!
</ul>
<p>

To solve this problem, a tool called <code>Merr</code> was created.
Merr can generate your <code>yyerror()</code>
function with good syntax error messages based on examples: you supply the
sample syntax errors and messages, and Merr figures out which parse state
integer goes with which message.  Merr also uses the yychar (current input
token) to refine the diagnostics in the event that two of your example
errors occur on the same parse state.  See
the <a href="http://unicon.org/merr">Merr</a> web page.
<p>

  Example merr input. The format is:<br>
&nbsp; &nbsp; &nbsp; <em>error-fragment</em><code>:::</code><em>message</em>\n
<pre>
procedure p(); 1 := 2 end
::: missing semicolon or operator
procedure main()
every x do { }
}
end
::: too many closing curly braces
procedure main()
  y := X(1)
  z := "a","b"
end
::: missing semicolon or operator
global::: unexpected end of file
global x y::: invalid global declaration
global x, , y::: missing identifier
procedure p(x) end::: missing semicolon
link procedure p(x)
end
::: link list expected
</pre>
  
<p>

<ul>
<li> I am looking for someone to work on adding Java (byacc/j) support to Merr!
<li> If you are interested, please see me or send me a note.
</ul>

<p>
<font size="1"> <a name="16">lecture #16</a> began here</font>
</p><p>

<h3> Mailbag </h3>
<dl>
  <dt>

For our grammar, are we supposed to implement all possible cases of compound
statements? Is there possibly a simple example for that implementation?
    
<dd> Well, the supplied Python grammar says the following:

<pre>
compound_stmt: if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | decorated | async_stmt
</pre>

In Bison I would translate that roughly as:

<pre>
compound_stmt:
     if_stmt
   | while_stmt
   | for_stmt
   | try_stmt { not_puny("try statement"); }
   | with_stmt { not_puny("try statement"); }
   | funcdef
   | classdef
   | decorated { not_puny("decorated statement"); }
   | async_stmt { not_puny("async statement"); }
;
</pre>
	  
This assumes you write a function <code>not_puny(s)</code>
that prints an error message
and exits with an error code. Note that PunY handles only a restricted
subset of some of the substatements' syntax.

<dt> do we need to have lambdas for puny?
<dd> No, that is not used in 107. It is a Python-not-PunY feature.

<dt> You say we have to do octals, but then you say we don't have to do octals!
      Which is it?
<dd> I asked the CSE 107 instructor if we have to do octals, and he says no.

<dt> How would we go about implementing the for statements grammar in a way
that does not use 'in'?

<dd>"in" was originally believed to not be in PunY, until the CSE 107
instructor told me that 107 uses for loops. Now "in" is allowed in PunY, but
only in the simple supported forms of the for-loop syntax.
For HW#3 you should go ahead and add support for "in" to your lexical analyser.

<dt> What do I do with all these grammar rules for things not in PunY, like
    the bitwise operators for example?

<dd>In many language grammars, there is a long sequence of non-terminals
 to introduce operators such as bitwise
operators 1-2 at a time by precedence. They always have a basis case that
just goes down to the next
non-terminal for the next level of precedence. Eventually they get past
all the operators that are not in our language and into a
non-terminal that we do support. For example, after the bitwise operators
they may proceed to the arithmetic operators with a non-terminal name
such as arith_expr.

Your options are to leave the grammar rules intact and report not-in-PunY
errors in the semantic actions for the unsupported operators, or
remove all these unsupported operators from the grammar, perhaps replacing
references to non-terminal xor_expr with non-terminal arith_expr, for
example.

<dt>
What do we do with the warning of "nonterminal useless in grammar"?  I'm
guessing it means those grammars will not be used during parsing? Is that
correct?  Are we ignoring them or are we supposed to fix them somehow?

<dd>Nonterminal useless in grammar means what it says: there is no path from
the start symbol that ever uses those non-terminals so they are dead code
and will be unused.  If it is for a feature that is not in PunY it might be
harmless, but if it is a feature that normal Python programs would use then
it indicates a bug where some production rule is missing or wrong, that
should have referenced that non-terminal from someplace higher in the
grammar.
 
<dt>
There is one useless nonterminal called "func_type_input" in my file (which
cascading another 6-7 or so of my nonterminals to be deemed useless).
According to the note on top of the grammar file, it says: "func_type_input
is a PEP 484 Python 2 function type comment".

So is this grammar a Python 2 thing? Should I just remove or keep it?

<dd>
From what you describe about func_type_input, it seems likely that you can
live without these nonterminals and can remove them.

</dl>

<p>
<font size="1"> <a name="17">lecture #17</a> began here</font>
</p><p>

<h4> What questions have you got for me, regarding HW#3? </h4?
							       

<h4> Look at <A href="hw4.html">HW#4</A> </h4>

</p><h3> Recursive Descent Parsing </h3>

Perhaps the simplest parsing method, for a large subset of context free
grammars, is called recursive descent.  It is simple because the algorithm
closely follows the production rules of nonterminal symbols.

<ul>
<li> Write 1 procedure per nonterminal rule
</li><li> Within each procedure, a) match terminals at appropriate positions,
     and b) call procedures for non-terminals.
</li><li> Pitfalls:
<ol><li> left recursion is FATAL
</li><li> must distinguish between several
     production rules, or potentially, one has to
     try all of them via <em>backtracking</em>.
</li></ol>
</li></ul>

<h4> Recursive Descent Parsing Example #1</h4>

<pre>E -&gt; E + T
E -&gt; T
T -&gt; T * F
T -&gt; F
F -&gt; ( E )
F -&gt; ident
</pre>

Consider the grammar we gave above.  There will be functions for
E, T, and F.  The function for F() is the "easiest" in some sense: based
on a single token it can decide which production rule to use.  The
parsing functions return 0 (failed to parse) if the nonterminal in
question cannot be derived from the tokens at the current point.
A nonzero return value of N would indicate success in parsing using
production rule #N.

<pre>int F()
{
   int t = yylex();
   if (t == IDENT) return 6;
   else if (t == LP) {
      if (E() &amp;&amp; (yylex()==RP) return 5;
      }
   return 0;
}
</pre>

Comment #1: if F() is in the middle of a larger parse of E() or T(), F()
may succeed, but the subsequent parsing may fail. The parse may have
to <em>backtrack</em>, which would mean we would have to be able to put
tokens back for later parsing.  Add a memory (say, a gigantic array or
link list for example) of already-parsed tokens
to the lexical analyzer, plus backtracking logic to E() or T() as needed.
The call to F() may get repeated following a different production rule
for a higher nonterminal.
<p>

Comment #2: in a real compiler we need more than "yes it parsed" or
"no it didn't": we need a parse tree if it succeeds, and we need a
useful error message if it did not.
</p><p>

Question: for E() and T(), how do we know which production rule to try?
Option A: just blindly try each one in turn.
Option B: look at the first (current) token, only try those rules that
start with that token (1 character lookahead).  If you are lucky, that
one character will uniquely select a production rule. If that is always
true through the whole grammar, no backtracking is needed.
</p><p>


Question: how do we know which rules start with whatever token we are
looking at?  Can anyone suggest a solution, or are we stuck?
</p><p>

Below is an industrious start of an implementation of the
corresponding recursive descent parser for non-terminal <code>T</code>.
Now is student-author time, what is our next step?  What is wrong with
this picture?


</p><pre>int T()
{  // save where the current token is
   if (T() &amp;&amp; (yylex()==ASTERISK) &amp;&amp; F()) return 3;
   // restore the current input pointer to the saved location
   if (F()) return 4;
   return 0;
}
</pre>


<h3> Removing Left Recursion </h3>


<pre>E -&gt; E + T | T
T -&gt; T * F | F
F -&gt; ( E ) | ident
</pre>

We can remove the left recursion by introducing new nonterminals
and new production rules.

<pre>E  -&gt; T E'
E' -&gt; + T E' | &#949;
T  -&gt; F T'
T' -&gt; * F T' | &#949;
F  -&gt; ( E ) | ident
</pre>

Getting rid of such <em>immediate left recursion</em> is not enough, one must
get rid of indirect left recursion, where two or more nonterminals are
mutually left-recursive.
One can rewrite <em>any</em> CFG to remove left recursion (Algorithm 4.19). 

<pre>for i := 1 to n do
   for j := 1 to i-1 do begin
      replace each A<sub>i</sub> -&gt; A<sub>j</sub> &#947; with productions
         A<sub>i</sub> -&gt; &#948;<sub>1</sub>&#947; | &#948;<sub>2</sub>&#947; | ... | &#948;<sub>k</sub>&#947;, where
            A<sub>j</sub> -&gt; &#948;<sub>1</sub> | &#948;<sub>2</sub> | ... | &#948;<sub>k</sub> are all current A<sub>j</sub>-productions
      end
   eliminate immediate left recursion
</pre>


<h3> Where We Are </h3>

<ul>
<li> We started in on recursive descent parsing by observing that for some
grammar rules, we could just write the code easy peasy by  matching
the first token and then calling nonterminal functions.
</li><li> Then we hit a wall, because the other nonterminals were left recursive,
we had to solve the infinite recursion problem, which is detailed in your
dragon book.
</li><li> If we ever clear the left recursion hurdle, THEN we can worry about the
backtracking problem: if we try to parse rule 1, and get into it a ways, and
find that it doesn't work, we have to "undo" all our parsing (and possibly
lexing) back to the starting point in order to try subsequent grammar rules
for a given nonterminal.
</li></ul>


<h3> Removing Left Recursion, part 2 </h3>

Left recursion can be broken into three cases
<p>
</p><h4>case 1: trivial</h4>

<pre>A : A &#945; | &#946;
</pre>

The recursion must always terminate by A finally deriving &#946; so you
can rewrite it to the equivalent
<pre>A : &#946; A'
A' : &#945; A' | &#949;
</pre>

Example:
<pre>E : E op T | T
</pre>
can be rewritten
<pre>E : T E'
E' : op T E' | &#949;
</pre>

<h4>case 2: non-trivial, but immediate</h4>

In the more general case, there may be multiple recursive productions
and/or multiple non-recursive productions.
<pre>A : A &#945;<sub>1</sub> | A &#945;<sub>2</sub> | ... | &#946;<sub>1</sub> | &#946;<sub>2</sub>
</pre>

As in the trivial case, you get rid of left-recursing A and introduce an A'

<pre>A :  &#946;<sub>1</sub> A' | &#946;<sub>2</sub> A' | ...
A' : &#945;<sub>1</sub> A' | &#945;<sub>2</sub> A' | ... | &#949;
</pre>


<h4> case 3: mutual recursion </h4>

<ol>
<li> Order the nonterminals in some order 1 to N.
</li><li> Rewrite production rules to eliminate all
     nonterminals in leftmost positions that refer to a "previous" nonterminal.
     When finished, all productions' right hand symbols start with a terminal
     or a nonterminal that is numbered equal or higher than the nonterminal
     no the left hand side.
</li><li> Eliminate the direct left recusion as per cases 1-2.
</li></ol>


<h4> Left Recursion Versus Right Recursion: When does it Matter? </h4>

A student came to me once with what they described as an operator precedence
problem where 5-4+3 was computing the wrong value (-2 instead of 4).  What
it really was, was an associativity problem due to the grammar:
<pre>E : T + E | T - E | T
</pre>

The problem here is that right recursion is forcing right associativity, but
normal arithmetic requires left associativity.  Several solutions are:
(a) rewrite the grammar to be left recursive, or (b) rewrite the grammar
with more nonterminals to force the correct precedence/associativity,
or (c) if using YACC or Bison, there are "cheat codes" we will discuss later
to allow it to be majorly ambiguous and specify associativity separately
(look for %left and %right in YACC manuals).


<h3> Recursive Descent Parsing Example #2</h3>

The grammar

<pre>S -&gt; A B C
A -&gt; a A
A -&gt; <em>&#949;</em>
B -&gt; b
C -&gt; c
</pre>

maps to pseudocode like the following. (:= is an assignment operator)

<pre>procedure S()
  if A() &amp; B() &amp; C() then succeed # matched S, we win
end

procedure A()
  if yychar == a then { # use production 2
     yychar := scan()
     return A()
     }
  else
     succeed # production rule 3, match &#949;
end

procedure B()
   if yychar == b then {
      yychar := scan()
      succeed
      }
   else fail
end

procedure C()
   if yychar == c then {
      yychar := scan()
      succeed
      }
   else fail
end
</pre>


  <h3> Mailbag </h3>
  <dl>
    <dt>
      Is there a way to debug syntax errors in our grammar .y file? We are really having a hard time to solve the syntax error ( incomplete sequence error) that we are getting from our bison file.
      <dd>
	You may use a combination of valgrind + gdb, but your best bet may be
	to turn on bison debugging:
 <ol>
   <li> <code>%{ #define YYDEBUG 1  %}</code> in your .y file header section
   <li> <code>extern int yydebug;</code> ... and <code>yydebug=1;</code> in
     your <code>main()</code> module
 </ol>
</dl>

<h3> Backtracking? </h3>


Could your current token begin more than one of your possible production rules?
Try all of them, remember and reset state for each try.
<pre>S -&gt; cAd
A -&gt; ab
A -&gt; a
</pre>

<em>Left factoring</em> can often solve such problems:

<pre>S -&gt; cAd
A -&gt; a A2
A2-&gt; b
A2-&gt; (&#949;)
</pre>

One can also perform left factoring <!--(Algorithm 4.2)--> to reduce or
eliminate the lookahead or backtracking needed to tell which production rule
to use.  If the end result has no lookahead or backtracking needed, the
resulting CFG can be solved by a "predictive parser" and coded easily in a
conventional language.  If backtracking is needed, a recursive descent
parser takes more work to implement, but is still feasible.

As a more concrete example:

<pre>S -&gt; <b>if</b> E <b>then</b> S
S -&gt; <b>if</b> E <b>then</b> S<sub>1</sub> else S<sub>2</sub>
</pre>

can be factored to:

<pre>S -&gt; <b>if</b> E <b>then</b> S S'
S'-&gt; else S<sub>2</sub> | &#949;
</pre>

<p>
<font size="1"> <a name="18">lecture #18</a> began here</font>
<p>

<h3> Reading Assignment </h3>

We are heading into semantic analysis.

<ul>
<li> Read the Thain textbook, Chapter 7
<li> (fwiw the corresponding Jeffery chapter is Chapter 6)
</ul>

<h3> Some More Parsing Theory </h3>

Automatic techniques for constructing parsers start with computing some
basic functions for symbols in the grammar.  These functions are useful
in understanding both recursive descent and bottom-up LR parsers.

<h3> First(&#945;) </h3>

First(&#945;) is the set of terminals that begin strings derived from &#945;,
which can include &#949;.

<ol>
<li> First(X) starts with the empty set.
</li><li> if X is a terminal, First(X) is {X}.
</li><li> if X -&gt; &#949; is a production, add &#949; to First(X).
</li><li> if X is a non-terminal and X -&gt; Y<sub>1</sub> Y<sub>2</sub> ... Y<sub>k</sub> is a production,
     add First(Y<sub>1</sub>) to First(X).
</li><li><pre>for (i = 1; if Y<sub>i</sub> can derive &#949;; i++)
        add First(Y<sub>i+1</sub>) to First(X)
</pre>
</li></ol>


<h3> First(a) examples </h3>

by the way, this stuff is all in section 4.3 in your text.
<p>
Last time we looked at an example with E, T, and F, and + and *.
The first-set computation was not too exciting and we need more
examples.

</p><pre>stmt : if-stmt | OTHER
if-stmt:  IF LP expr RP stmt else-part
else-part: ELSE stmt | &#949;
expr: IDENT | INTLIT
</pre>

What are the First() sets of each nonterminal?



<h3> Follow(A) </h3>

(The helper function that goes along with First(X)) <p>

Follow(A) for nonterminal A is the set of terminals that can appear
immediately to the right of A in some sentential form S -&gt; aAxB...
To compute Follow, apply these rules to all nonterminals in the grammar:

</p><ol>
<li> Add $ to Follow(S)
</li><li> if A -&gt; aB&#946; then add First(&#946;) - &#949; to Follow(B)
</li><li> if A -&gt; aB or A -&gt; aB&#946; where &#949; is in First(&#946;), then add
     Follow(A) to Follow(B).
</li></ol>


<h3> Follow() Example </h3>

For the grammar:

<pre>stmt : if-stmt | OTHER
if-stmt:  IF LP expr RP stmt else-part
else-part: ELSE stmt | &#949;
expr: IDENT | INTLIT
</pre>

It can get pretty muddy on the Follow() function, for even this simple grammar.
It helps if you follow the algorithm, instead of just "eyeballing it".

<pre>For all non-terminals X in the grammar do
   1. if X is the start symbol, add $ to Follow(X)
   2. if N -&gt; &#945;X&#946; then add First(&#946;) - &#949; to Follow(X)
   3. if N -&gt; &#945;X or N -&gt; &#945;X&#946; where &#949; is in
       First(&#946;) then add Follow(N) to Follow(X)
</pre>

Since the algorithm depends on First(), what are First sets again?
<pre>First(stmt) = {IF, OTHER}
First(if-stmt) = {IF}
First(else-part) = {ELSE, &#949;}
First(expr) = {IDENT, INTLIT}
</pre>


Because each non-terminal has three steps, and our toy grammar has
4 non-terminals, there are 12 steps.
When you just apply these twelve steps, brute force, it is clear
that the statement of what to do to compute them was not an algorithm,
it was only a declarative specification, and there is an ordering needed
in order to compute the result.
<pre>   1. stmt is the start symbol, add $ to Follow(stmt)
   2. if N -&gt; &#945; stmt &#946; then add First(&#946;) - &#949; to Follow(stmt)
	---- add First(else-part)-&#949; to Follow(stmt)
   3. if N -&gt; &#945; stmt or N -&gt; &#945; stmt &#946; where &#949;
	 is in First(&#946;) then add Follow(N) to Follow(stmt)
	---- add Follow(else-part) to Follow(stmt)
   4. if-stmt is not the start symbol (noop)
   5. if N -&gt; &#945;if-stmt&#946; then add First(&#946;) - &#949; to Follow(if-stmt)
	---- n/a
   6. if N -&gt; &#945;if-stmt or N -&gt; &#945;if-stmt&#946; where &#949; is in
       First(&#946;) then add Follow(N) to Follow(if-stmt)
	---- add Follow(stmt) to Follow(if-stmt)
   7. else-part is not the start symbol (noop)
   8. if N -&gt; &#945;else-part&#946; then add First(&#946;) - &#949; to Follow(else-part)
	---- n/a
   9. if N -&gt; &#945;else-part or N -&gt; &#945;else-part&#946; where &#949; is in
       First(&#946;) then add Follow(N) to Follow(else-part)
	--- add Follow(if-stmt) to Follow(else-part)
   10. expr is not the start symbol (noop)
   11. if N -&gt; &#945;expr&#946; then add First(&#946;) - &#949; to Follow(expr)
	---- add RP to Follow(expr)
   12. if N -&gt; &#945;expr or N -&gt; &#945;expr&#946; where &#949; is in
       First(&#946;) then add Follow(N) to Follow(expr)
	---- n/a
</pre>

What is the dependency graph? Does it have any cycles?  If it has cycles,
you will have to iterate to a fixed point.
<pre>Follow(stmt) depends on Follow(else-part)
Follow(if-stmt) depends on Follow(stmt)
Follow(else-part) depends on Follow(if-stmt)
</pre>
If I read this right, there is a 3-way mutual recursion cycle.


<h3> Can we First/Follow Anything Else </h3>

Like preferably, a real-world grammar example?  Please remember that real
world grammars for languages like ANSI C are around 400+ production rules,
so in-class examples will by necessity be toys.  If I pick a random* (*LOL)
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/unigram.y">YACC grammar</a>, can we First/Follow any of its non-terminals?




<h3> LR vs. LL vs. LR(0) vs. LR(1) vs. LALR(1) </h3>

The first char ("L") means input tokens are read from the left
(left to right).  The second char ("R" or "L") means parsing
finds the rightmost, or leftmost, derivation.  Relevant
if there is ambiguity in the grammar.  (0) or (1) or (k) after
the main lettering indicates how many lookahead characters are
used.  (0) means you only look at the parse stack, (1) means you
use the current token in deciding what to do, shift or reduce.
(k) means you look at the next k tokens before deciding what
to do at the current position.


<h3> Midterm </h3>

The midterm exam March 10 will be an in-class exam.
There will be a midterm review on Wednesday March 8.


<!--
</p><h3> Mailbag </h3>

<dl>
<dt> VGo spec says no colons, but then the map constructor uses colons
</dt><dd> Good catch. VGo has maps but not "map literals".  You should have
a colon token in your lexer, even though colons are a Go-not-VGo thing.
Here's a Pepsi Challenge question: is it right and good to just die if
you see a colon, or should you return the colon as a token, and in the
syntax check, distinguish between legal uses of Go that VGo doesn't
handle, versus crazy non-Go uses of a colon operator.
</dd><dt> ...
</dt></dl>
-->

<h3> LR Parsers </h3>

LR denotes a class of bottom up parsers that is capable of handling virtually
all programming language constructs.  LR is efficient; it runs in linear time
with no backtracking needed.  The class of languages handled by LR is a proper
superset of the class of languages handled by top down "predictive parsers".
LR parsing detects an error as soon as it is possible to do so.  Generally
building an LR parser is too big and complicated a job to do by hand, we use
tools to generate LR parsers.
<p>


The LR parsing algorithm is given below.<!--See Figure 4.29 for a schematic.-->
</p><pre>ip = first symbol of input
repeat {
   s = state on top of parse stack
   a = *ip
   case action[s,a] of {
      SHIFT s': { push(a); push(s') }
      REDUCE A-&gt;&#946;: {
         pop 2*|&#946;| symbols; s' = new state on top
         push A
         push goto[s', A]
         }
      ACCEPT: return 0 /* success */
      ERROR: { error("syntax error", s, a); halt }
      }
   }
</pre>



<!--
<h3> Little-known Mysteries of the BASIC Language </h3>

<ul>
<li> BASIC has arrays.  They default to a size of 11 elements.
     Other array sizes are specified via a DIM statement, as in:<br>
     10 DIM A(100)
<li> BASIC has three versions of every variable name (number, string, array)
<li> Variables in BASIC are preinitialized to 0.
<li> PRINT statements have multiple arguments (implicit concatenation?)
<li> PRINT statements can have commas or semicolons between their arguments
<li> Some of our tests have syntax errors; others use features (e.g. graphics)
     that are beyond our scope. Extra credit, but only if you catch up first.
<li> cocogram.y is not infallible, you are to fix it, and then brag about it
<li> Jimenez' COCO emulator is how I test what should and should not work.
</ul>
-->


<p>

</p>

<!--
<h3>Constructing SLR Parsing Tables: </h3>



<p>
<dfn>Definition: An LR(0) item of a grammar G is a production
of G with a dot at some position of the RHS.</dfn>
</p><p>
Example: The production A-&gt;aAb gives the items: 
</p><p>
A -&gt; . a A b<br>
A -&gt; a . A b<br>
A -&gt; a A . b<br>
A -&gt; a A b .
</p><p>
Note: A production A-&gt; &#949; generates
only one item:
</p><p>
A -&gt; .
</p><p>
Intuition: an item A-&gt; &#945; . &#946; denotes:
</p><ol>
<li>&#945; - we have already seen a string
derivable from &#945;
</li><li>&#946; - we hope to see a string derivable
from &#946;
</li></ol>

<h3>Functions on Sets of Items </h3>

<p>
<dfn>Closure: if I is a set of items for a grammar G, then closure(I)
is the set of items constructed as follows:</dfn>
</p><ol>
<li><dfn>Every item in I is in closure(I).</dfn>
</li><li><dfn>If A-&gt;</dfn>&#945; . <dfn>B</dfn>&#946;<dfn>
is in closure(I) and B-&gt;</dfn>&#947;<dfn>
is a production, then add B-&gt; .</dfn>&#947;<dfn>
to closure(I).</dfn> 
</li></ol>

<p>
These two rules are applied repeatedly until no new items can
be added.
</p><p>
Intuition: If A -&gt; &#945; . B &#946; is in
closure(I) then we hope to see a string derivable from B in the
input. So if B-&gt; &#947; is a production,
we should hope to see a string derivable from &#947;.
Hence, B-&gt;.&#947; is in closure(I).<br>

</p><p>
Goto: if I is a set of items and X is a grammar symbol, then goto(I,X)
is defined to be:
</p><p>
goto(I,X) = closure({[A-&gt;&#945;X.&#946;] | [A-&gt;&#945;.X&#946;]
is in I})
</p><p>
Intuition: 
</p><ul>
<li>[A-&gt;&#945;.X&#946;]
is in I =&gt; we've seen a string derivable
from &#945;; we hope to see a string derivable
from X&#946;.
</li><li>Now suppose we see a string derivable from X
</li><li>Then, we should "goto" a state where we've seen
a string derivable from &#945;X, and where
we hope to see a string derivable from &#946;.
The item corresponding to this is [A-&gt;&#945;X.&#946;] 
</li></ul>


<ul>
<li>Example: Consider the grammar
</li></ul>

<pre><font size="3">	E -&gt; E+T | T
	T -&gt; T*F | F
	F -&gt; (E) | id 
</font></pre>

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
Let I = {[E -&gt; E . + T]} then:
<pre><font size="3">        goto(I,+) = closure({[E -&gt; E+.T]})
		  = closure({[E -&gt; E+.T], [T -&gt; .T*F], [T -&gt; .F]})
		  = closure({[E -&gt; E+.T], [T -&gt; .T*F], [T -&gt; .F], [F-&gt; .(E)], [F -&gt; .id]})
		  = { [E -&gt; E + .T],[T -&gt; .T * F],[T -&gt; .F],[F -&gt; .(E)],[F -&gt; .id]}</font>
</pre>

-->

<!--
</p><h3> Mailbag </h3>

<dl>
<dt> What-all do you see in <a href="https://www.cs.nmt.edu/~jeffery/courses/423/Test2.go">this</a> example?
     It gives me errors on Vertex at the bottom.
</dt><dd> <ol>
<li>In general, if you have to debug something, simplify it to the simplest
     possible version that produces the error.  In this example, Vertex
     would not be legal unless it was previous declared via a <code>type</code>
     declaration.  Is that semantic analysis, or does it impact our parsing?
</li><li> In debugging VGo, using the Go compiler is a primary sanity check.
     Running the Go compiler, it sees a syntax error on line 69 unrelated to
     your question about Vertex.  See rule #1.
</li></ol>
I then boiled the Vertex part of your example down to the following, which
does compile with "go build":
<pre>package main
type Vertex struct {x, y float64}
func main() {
	var m map[string]Vertex
	m["Bell Labs"] = Vertex{ 40.68433, -74.39967 }
	m["Google"] = Vertex{37.42202, -122.08408 }
}
</pre>
As far as I can see, this parsed successfully with my reference VGo
lexer/parser, without Vertex posing any special problems.  If my
interpretation of this is correct, the lexer returning LNAME for Vertex
is OK as a type name according to the go grammar, so the part of HW#2
that reads "Resolve matters regarding type names" is a no-op this semester
thanks to our reference grammar. It has kicked the can down the road on
the question of legal type names, deferring that to semantic analysis
(i.e. HW#3-4) where arguably, it belongs.  If you get syntax errors, maybe
you have changed the grammar in some way that you may want to fix.
</dd></dl>
-->

<!--
<h3>The Set of Sets of Items Construction</h3>

<ol>
<li>Given a grammar G with start symbol S, construct the augmented
grammar by adding a special production S'-&gt;S where S' does
not appear in G.
</li><li>Algorithm for constructing the canonical collection of
sets of LR(0) items for an augmented grammar G': 
</li></ol>

<p>
<font size="3" face="Courier New"></font>
</p><pre><tt>	begin
	   C := { closure({[S' -&gt; .S]}) };
</tt>	   <tt>repeat
	      for each set of items I in C:
		  for each grammar symbol X:
   		     if goto(I,X) != 0 and goto(I,X) is not in C then
		 	 add goto(I,X) to C;
	   until no new sets of items can be added to C;
	   return C;
	end<br>
</tt>
</pre>




<p>
<dfn>Valid Items: an item A -&gt; </dfn>&#946;<dfn><sub>
1</sub>. </dfn>&#946;<dfn> <sub>2</sub>
 is valid for a viable prefix </dfn>&#945;<dfn>
</dfn>&#946;<dfn><sub> 1  </sub>if
there is a derivation:</dfn>
</p><pre><font size="3" face="Courier New">S' =&gt;<sup>*</sup><sub>rm</sub> </font>&#945;<font size="3" face="Courier New">A</font>&#969;<font size="3" face="Courier New"> =&gt;<sup>*</sup><sub>rm</sub></font>&#945; &#946;<sub><font size="3" face="Courier New">1</font></sub>&#946;<sub><font size="3" face="Courier New"> 2</font></sub>&#969;
</pre>

<p>
Suppose A -&gt; &#946;<sub>1</sub>.&#946; <sub>2</sub> is valid for &#945;&#946;<sub>1</sub>,
and &#945;B<sub>1</sub> is on the parsing
stack
</p><ol>
<li>if &#946;<sub>2</sub> != &#949;,
we should shift
</li><li>if &#946;<sub>2</sub> = &#949;,
A -&gt; &#946;<sub>1</sub> is the handle,
and we should reduce by this production 
</li></ol>

<p>
Note: two valid items may tell us to do different things for the
same viable prefix. Some of these conflicts can be resolved using
lookahead on the input string. 



</p><h3>Constructing an SLR Parsing Table</h3>

<ol>
<li>Given a grammar G, construct the augmented grammar by adding
the production S' -&gt; S.
</li><li>Construct C = {I<sub>0</sub>, I<sub>1</sub>,  I<sub>n</sub>},
the set of sets of LR(0) items for G'.
</li><li>State I is constructed from I<sub>i</sub>, with parsing action
determined as follows:
<ul>
<li>[A -&gt; &#945;.aB] is in
I<sub>i</sub>, where a is a terminal; goto(I<sub>i</sub>,a) = I<sub>j</sub>
: set action[i,a] = "shift j"
</li><li>[A -&gt; &#945;.] is in
I<sub>i</sub> : set action[i,a] to "reduce A -&gt; x"
for all a &#8712; FOLLOW(A), where A != S'
</li><li>[S' -&gt; S .] is in I<sub>i</sub> :
set action[i,$] to "accept" 
</li></ul>

</li><li>goto transitions constructed as follows: for all non-terminals:
if goto(I<sub>i</sub>, A) = I<sub>j</sub>, then goto[i,A] = j
</li><li>All entries not defined by (3) &amp; (4) are made "error".
If there are any multiply defined entries, grammar is not SLR.
</li><li>Initial state S<sub>0</sub> of parser: that constructed from
I<sub>0</sub> or [S' -&gt; S] 
</li></ol>


<h3>Constructing an SLR Parsing Table: Example</h3>

<pre><font size="3">	S -&gt; aABe		FIRST(S) = {a}		FOLLOW(S) = {$}
	A -&gt; Abc		FIRST{A} = {b}		FOLLOW(A) = {b,d}
	A -&gt; b			FIRST{B} = {d}		FOLLOW{B} = {e}
	B -&gt; d			FIRST{S'}= {a}		FOLLOW{S'}= {$}
</font>I<sub>0</sub><font face="Courier New"> = closure([S'-&gt;.S]
   = closure([S'-&gt;.S],[S-&gt;.aABe])
goto(I<sub>0</sub>,S) = closure([S'-&gt;S.]) = I<sub>1
</sub>goto(I<sub>0</sub>,a) = closure([S-&gt;a.ABe])
	    = closure([S-&gt;a.ABe],[A-&gt;.Abc],[A-&gt;.b]) = I<sub>2
</sub>goto(I<sub>2</sub>,A) = closure([S-&gt;aA.Be],[A-&gt;A.bc])
	    = closure([S-&gt;aA.Be],[A-&gt;A.bc],[B-&gt;.d]) = I<sub>3
</sub>goto(I<sub>2</sub>,b) = closure([A-&gt;b.]) = I<sub>4
</sub>goto(I<sub>3</sub>,B) = closure([S-&gt;aAB.e]) = I<sub>5
</sub>goto(I<sub>3</sub>,b) = closure([A-&gt;Ab.c]) = I<sub>6
</sub>goto(I<sub>3</sub>,d) = closure([B-&gt;d.]) = I<sub>7
</sub>goto(I<sub>5</sub>,e) = closure([S-&gt;aABe.]) = I<sub>8
</sub>goto(I<sub>6</sub>,c) = closure([A-&gt;Abc.]) = I<sub>9</sub></font>
</pre>


<h3> Fun with Parsing </h3>

Let's play a "new fun game"* and see what we can do with the following subset
of the C grammar:

<table>
<tbody><tr><th> C grammar subset </th><th> First sets
</th></tr><tr><td>
<pre>ats : INT | TYPEDEF_NAME | s_u_spec ;
s_u_spec : s_u LC struct_decl_lst RC |
	s_u IDENT LC struct_decl_lst RC |
	s_u IDENT ;
s_u : STRUCT | UNION ;
struct_decl_lst : s_d | struct_decl_lst s_d ;
s_d : s_q_l SM |
	s_q_l struct_declarator_lst SM ;
s_q_l : ats | ats s_q_l ;
struct_declarator_lst:
	declarator |
	struct_declarator_list CM declarator ;
declarator: IDENT |
	declarator LB INTCONST RB ;
</pre>
</td><td>
<pre>First(ats) = { INT, TYPEDEF_NAME, STRUCT, UNION }
First(s_u_spec) = { STRUCT, UNION }
First(s_u) = { STRUCT, UNION }
First(struct_decl_lst) = { INT, TYPEDEF_NAME, STRUCT, UNION }
First(s_d) = { INT, TYPEDEF_NAME, STRUCT, UNION }
First(s_q_l) = { INT, TYPEDEF_NAME, STRUCT, UNION}
First(struct_declarator_lst) = { IDENT }
First(declarator) = { IDENT }
</pre>
</td></tr></tbody></table>

<pre>Follow(ats) = { $, INT, TYPEDEF_NAME, STRUCT, UNION, IDENT, SM }
Follow(s_u_spec) = { $, INT, TYPEDEF_NAME, STRUCT, UNION, IDENT, SM }
Follow(s_u) = { LC, IDENT }
Follow(struct_decl_lst) = { RC, INT, TYPEDEF_NAME, STRUCT, UNION }
Follow(s_d) = { RC, INT, TYPEDEF_NAME, STRUCT, UNION }
Follow(s_q_l) = { IDENT, SM }
Follow(struct_declarator_lst) = { CM, SM }
Follow(declarator) = { LB , CM, SM }
</pre>

Now, Canonical Sets of Items for this Grammar:

<pre>I<sub>0</sub> = closure([S' -&gt; . ats]) =
	 closure({[S' -&gt; . ats], [ ats -&gt; . INT ],
	 	  [ ats -&gt; . TYPEDEF_NAME ], [ ats -&gt; . s_u_spec ],
		  [ s_u_spec -&gt; . s_u LC struct_decl_lst RC],
		  [ s_u_spec -&gt; . s_u IDENT LC struct_decl_lst RC],
		  [ s_u_spec -&gt; . s_u IDENT ],
		  [ s_u -&gt; . STRUCT ],
		  [ s_u -&gt; . UNION ]
		  })

goto(I<sub>0</sub>, ats) = closure({[S' -&gt; ats .]}) = {[S' -&gt; ats .]} = I<sub>1</sub>

goto(I<sub>0</sub>, INT) = closure({[ats -&gt; INT .]}) = {[ats -&gt; INT .]} = I<sub>2</sub>
goto(I<sub>0</sub>, TYPEDEF) = closure({[ats -&gt; TYPEDEF_NAME .]}) = {[ats -&gt; TYPEDEF_NAME .]} = I<sub>3</sub>
goto(I<sub>0</sub>, s_u_spec) = closure({[ats -&gt; s_u_spec .]}) = {[ats -&gt; s_u_spec .]} = I<sub>4</sub>

goto(I<sub>0</sub>, s_u) = closure({
		  [ s_u_spec -&gt; s_u . LC struct_decl_lst RC],
		  [ s_u_spec -&gt; s_u . IDENT LC struct_decl_lst RC],
		  [ s_u_spec -&gt; s_u . IDENT ]}) = I<sub>5</sub>

goto(I<sub>0</sub>, STRUCT) = closure({[ s_u -&gt; STRUCT .]}) = I<sub>6</sub>
goto(I<sub>0</sub>, UNION) = closure({[ s_u -&gt; UNION .]}) = I<sub>7</sub>

goto(I<sub>5</sub>, LC) = closure({[ s_u_spec -&gt; s_u LC . struct_decl_lst RC],
[ struct_decl_lst -&gt; . s_d ],
[ struct_decl_lst -&gt; . struct_decl_lst s_d ],
[ s_d -&gt; . s_q_l SM],
[ s_d -&gt; . s_q_l struct_declarator_lst SM],
[ s_q_l -&gt; . ats ],
[ s_q_l -&gt; . ats s_q_l ],
[ ats -&gt; . INT ],
[ ats -&gt; . TYPEDEF_NAME ],
[ ats -&gt; . s_u_spec ],
})
</pre>

<font size="1">* Arnold Schwartzenegger. Do you know the movie? </font>
-->

</p><h3> Mailbag </h3>

<dl>
<dt>
What exactly gives the
shape of the tree? I know that it is formed from the rules defined in bison,
but I am having trouble visualizing it.
</dt><dd>
At each node of the tree, the shape (a.k.a. "fan-out", or # of children)
is defined by the # of symbols on the
righthand side of the production rule used to construct that node.
For go.y, the ~273 rules after we've deleted a lot of "hidden" things,
the distribution is about as follows:
<p>

<table border="">
<tbody><tr><th> Size of RHS </th><th> # of Rules of that size
</th></tr><tr><td> 0 </td><td> 19
</td></tr><tr><td> 1 </td><td> 98
</td></tr><tr><td> 2 </td><td> 46
</td></tr><tr><td> 3 </td><td> 67
</td></tr><tr><td> 4 </td><td> 17
</td></tr><tr><td> 5 </td><td> 21
</td></tr><tr><td> 6 </td><td> 2
</td></tr><tr><td> 7 </td><td> 1
</td></tr><tr><td> 8 </td><td> 2
</td></tr></tbody></table>

<!--
<dt>
For homework #2, how should we handle user includes?  Should we open the
user include file(s) and generate/output the parse tree for everything in
that file?

<dd>
If HW#1 did the right thing, which was for includes to be handled seamlessly
with a continued sequence of yylex() tokens, HW#2 will generally not have to
do anything special or extra for the included file(s).  HW#2 does
need to clear out its type table and system-includes flags, reset the lexical
analyzer, and call a new yyparse() for each file named on its command line.
-->

</p></dd><dt> I totally have an example where a shift-reduce conflict was a Real
     Problem even though you said we could ignore shift-reduce conflicts!

</dt><dd> Ouch! When you showed me this in my office, you found that you could
     fix it by simply changing a right recursion to a left recursion!
     Very cool, we finally know why Bison warns of this kind of ambiguity
     in the grammar: sometimes it is really a problem.  I have taken the
     liberty of reducing your example to just about its simplest form:

<pre>%%
Program:	DeclarationList ProgramBody ;
ProgramBody: 	Function SEMICOLON ProgramBody	| ;
Function:	Declaration OPEN_PAREN CLOSE_PAREN ;
DeclarationList:Declaration SEMICOLON DeclarationList | ;
Declaration:		    INT IDENTIFIER ;
</pre>

The corresponding input that dies on this is:
<pre>int x;
int main();
</pre>

</dd><dt> How about a tool that would generate numbers
automatically from our grammar .y files?  It should perhaps use negative
numbers (to avoid overlap/conflicts with Bison-generated numbers for
terminal symbols).
</dt><dd> We looked again to see if Bison had an option to generate that, but I
am not aware of one.  Awhile back
I wrote a <a href="https://www.cs.nmt.edu/~jeffery/courses/423/nonterms.icn">cheap hack version 0</a>
of such a tool...feel free to adapt it or rewrite something similar.
</dd></dl>



<h3> On Trees </h3>

Trees are classic data structures.
<ul>
<li> Trees have nodes and edges; they are
a special case of graphs.
</li><li> Tree edges are directional, with roles "parent"
and "child" attributed to the source and destination of the edge.
</li><li> A tree has the property that every node has zero or one parent.
</li><li> A node with no parents is called a root.
</li><li> A node with no children is called a leaf.
</li><li> A node that is neither a root nor a leaf is an "internal node".
</li><li> Trees have a size (total # of nodes), a height (maximum count
     of nodes from root to a leaf),
     and an "arity" (maximum number of children in any one node).
</li></ul>
<p>

Parse trees are k-ary, where there is a
variable number of children bounded by a value k determined by the grammar.
You may wish to consult your old data structures book, or look at some books
from the library, to learn more about trees if you are not totally
comfortable with them.

</p><p>
</p><pre>#include &lt;stdarg.h&gt;

struct tree {
   short label;			/* what production rule this came from */
   short nkids;			/* how many children it really has */
   struct tree *child[1];	/* array of children, size varies 0..k */
				/* Such an array has to be the LAST
				   field of a struct, and "there can
				   be only ONE" for this to work. */
};

struct tree *alctree(int label, int nkids, ...)
{
   int i;
   va_list ap;
   struct tree *ptr = malloc(sizeof(struct tree) +
                             (nkids-1)*sizeof(struct tree *));
   if (ptr == NULL) {fprintf(stderr, "alctree out of memory\n"); exit(1); }
   ptr-&gt;label = label;
   ptr-&gt;nkids = nkids;
   va_start(ap, nkids);
   for(i=0; i &lt; nkids; i++)
      ptr-&gt;child[i] = va_arg(ap, struct tree *);
   va_end(ap);
   return ptr;
}
</pre>
<p>



<!--
<h3> Changes to Sigala's ISO 96 C++ Grammar Made for 120++ in 120gram.y </h3>

The actual draft ISO 96 C++ grammar was modified a fair bit for use
in this class, to produce a subset C++ grammar that was Bison-friendly.
For what its worth, here is a summary of those changes.  You are at least
nominally charged with looking at what grammar additions would be needed
to handle (as much as possible of) C++14, although such additions would
be met with "C++14 feature XXX is not part of 120++" error messages.

<ul>
<li> changes were motivated by a need to eliminate reduce/reduce
     conflicts.
<li> removing adjacent optional items was generally mandatory
<li> removing optional items at beginning and ending of a rule
       was usually required
<li> optional items in the middle of a rule were often OK
</ul>

Specific changes include:

<dl>
<dt> removed namespace_alias from namespace_name
<dd> ambiguity of these identifier-like rules not needed since we aren't
     doing namespaces properly in 120++.
<dt> removed :: prefixed primary expressions
<dd> overriding current namespace not necessary since we aren't doing
     namespaces properly in 120++.
<dt> removed template_id from unqualified_id
<dd> we aren't doing templates in 120++
<dt> refactored TEMPLATE_opt into two productions in qualified_id
<dt> refactored class_or_namespace_name and nested_name_specifier_opt in
      nested_name_specifier
<dd> class_or_namespace_name basically gave two ways to use an identifier;
      difference is semantic
<dt> removed a rule starting with simple_type_specifier in postfix_expression
<dt> factored out adjacent optionals in postfix_expression
<dt> remove pseudo_destructor names
<dt> pulled '*' and '&' out of unary_operator to avoid reduce/reduce conflicts
<dd> but allow them explicitly in unary_expression
<dt> factored out COLONCOLON_opt in new_expression and delete_expression
<dt> removed possibility of empty simple_declaration (empty ; is not a
     declaration) and init_declarator_list with no decl_specifier_seq
     in front of it
<dt> refactored adjacent optionals in
     simple_declaration,
     simple_type_specifier, elaborated_type_specifier
      qualified_namespace_specifier, using_declaration, direct_declarator,
      direct_abstract_declarator, parameter_declaration_clause,
      member_declaration, base_specifier
<dt> removed optionality of ENUM_opt in enum_specifier
<dd> not that 120++ has to do enum's
<dt> removed optionals at beginning and end of ptr_operator
<dt> refactored optional at end of cv_qualifier_seq
<dt> refactored optional begin of declarator_id
<dt> refactored optional beginning and internal element of function_definition
<dt> refactored class_head to avoid adjacent optionals, removed
      possibility of class head with no identifier
<dt> refactored optionals at end of member_declarator
<dt> removed optionality of identifiers in type_parameter
</dl>
-->

</p><h3> Having Trouble Debugging? </h3>

To save yourself on the semester project in this class, you should
learn gdb (or some other source level debugger) as well as you can.
Sometimes it can help you find your bug in seconds where you would have
spent hours without it.  But only if you take the time to read the manual
and learn the debugger.

<p>

To work on segmentation faults: recompile all .c files with -g and run your
program inside gdb to the point of the segmentation fault.  Type the gdb
"where" command.  Print the values of variables on the line mentioned in the
debugger as the point of failure.  If it is inside a C library function, use
the "up" command until you are back in your own code, and then print the
values of all variables mentioned on that line.

</p><p>

After gdb, the second tool I recommend strongly is valgrind.  valgrind
catches some kinds of errors that gdb misses.  It is a non-interactive
tool that runs your program and reports issues as they occur, with a big
report at the end.
</p><p>

<!--
There is another tool you should know about, although it is a little long in
the tooth at this point. It is useful for certain kinds of bugs, primarily
subtle memory violations.  It is called electric fence.  To use electric
fence you add

<pre>
	/home/.../libefence.a
</pre>

to the line in your makefile that links your object files together to
form an executable.  Assuming you can find or build a copy of libefence.a
somewhere.
-->


</p><h3> Reading Tree Leaves </h3>

In order to work with your tree, you must be able to tell, preferably
trivially easily, which nodes are tree leaves and which are internal nodes,
and for the leaves, how to access the lexical attributes.
<p>
Options:
</p><ol>
<li> encode in the parent what the types of children are
</li><li> encode in each child what its own type is (better)
</li></ol>
How do you do option #2 here?
<p>
There are actually nonterminal symbols with 0 children (nonterminal with
a righthand side with 0 symbols) so you don't necessarily want to use
an nkids of 0 is your flag to say that you are a leaf.

Perhaps the best approach to all this is to unify the tokens and parse tree
nodes with something like the following, where perhaps an nkids value of -1
is treated as a flag that tells the reader to use
lexical information instead of pointers to children:

</p><pre>struct node {
int code;		/* terminal or nonterminal symbol */
int nkids;
union {
   struct token { ...  } leaf; // or: struct token *leaf;
   struct node *kids[9];
   }u;
} ;
</pre>




<h3> Tree Traversals </h3>

Besides a function to allocate trees, you need to write one or more recursive
functions to visit each node in the tree, either top to bottom (preorder),
or bottom to top (postorder).  You might do many different traversals on the
tree in order to write a whole compiler: check types, generate machine-
independent intermediate code, analyze the code to make it shorter, etc.
You can write 4 or more different traversal functions, or you can write
1 traversal function that does different work at each node, determined by
passing in a function pointer, to be called for each node.

<pre>void postorder(struct tree *t, void (*f)(struct tree *))
{
   /* postorder means visit each child, then do work at the parent */
   int i;
   if (t == NULL) return;

   /* visit each child */
   for (i=0; i &lt; t-&gt; nkids; i++)
      postorder(t-&gt;child[i], f);

   /* do work at parent */
   f(t);
}
</pre>

You would then be free to write as many little helper functions as you
want, for different tree traversals, for example:
<pre>void printer(struct tree *t)
{
   if (t == NULL) return;
   printf("%p: %d, %d children\n", t, t-&gt;label, t-&gt;nkids);
}
</pre>


<!--
<h3> Compiling <A href="cgram.y">cgram.y</A> </h3>

It was ripped out of an anesthetized patient...for transplanting,
the buck ultimately stops with you.  Cgram.y was already legal Bison,
but to compile the resulting cgram.tab.c, cgram.y needed a %union
definition.  In order to link or work properly, it will still need
you to write helper functions and coordinate its token definitions
with your lexical analyzer / flex output.  The -d flag causes Bison
to write out a compatible header file to define tokens for flex.
-->

<h3> Parse Tree Example </h3>

Let's do this by way of demonstrating what yydebug=1 does for you, on a
very simple example such as:

<pre>int fac(unsigned n)
{
   return !n ? 1 : n*fac(n-1);
}
</pre>

Short summary: yydebug generates 1100 lines of tracing output
that explains the parse in Complete Detail.  From which we ought
to be able to build our parse tree example.


<h3> Observations on Debugging the ANSI C++ Grammar to be more YACC-able </h3>

<dl>
<dt>Expectation
</dt><dd> not that you pick it up by magic and debug it all yourself,
     but rather that you spend enough time monkeying with yacc grammars
     to be familiar with the tools and approach, and to ask the right questions.
</dd><dt> Tools
</dt><dd> YYDEBUG/yydebug, --verbose/--debug/y.output
</dd><dt> Approach
</dt><dd>
<ul>
<li> Run with yydebug=1 to study current behavior
</li><li> Do the minimum number of edits necessary to fix*
</li><li> reduce obvious epsilon vs. epsilon
</li><li>  Examine y.output to understand remaining reduce/reduce conflicts.
</li><li>  Delete the causes if they are not in our language
</li><li> Refactor the causes if they are in our language
</li></ul>
</dd></dl>
<p>

*why?  why not?
</p><p>

<!--
<h3> Bison debugging example </h3>

<ul>
<li> turned on yydebug=1
<li> trace shows reduce to ctor_initializer_opt before '{', looks good
<li> shift of '{' OK
<li> shift of INT leads to reduce of simple_type_specifier, seems OK
<li> should reduce to type_specifier, decl_specifier, decl_specifier_seq,
      decl_specifier_seq_opt: should be OK
<li> init_declarator_list_opt should go to init_declarator_list,
      init_declarator, declarator, direct_declarator, declarator_id,
      id_expresssion, unqualified_id, identifier, IDENTIFIER
<li> _opt grammar rules introduce epsilons, they were for the convenience
     of the ISO C++ committee, but we know epsilons are evil
<li> removed _opt grammar rules; adjacent ones, at least, were trouble
<li> removing adjacent ones helped, but removing others did not
<li> built with --verbose and --debug, looked at y.output
<li> before removing _opt's, reduce/reduce conflicts were very
     distributed 2,1,5,6,5,3,4,4,6,6,2,6,6,6,6,2,6,6,6,6,6
<li> after removing _opt's, reduce/reduce conflicts were more concentrated:
     45, 13, 9, 9, 9, 9 and a couple strays
<li> about half of reduce/reduce were due to "pseudo-destructors". delete
<li> 13 due to template_id's not knowing whether they are class_name or unqualified_id's. could delete trivially for 120++ (no templates)
<li> four batches of 9 reduce/reduce: type_name could be simple_type_specifier or declarator_id, COLONCOLON type_name not knowing if it is a simple_type_specifier or declarator_id, nested_name_specifier type_name not knowing if it is a simple_type_specifier or a declarator_id, and COLONCOLON nested_name_specifier type_name not knowing if it is a simple_type_specifier or a declarator_id
<li> a couple oddballs: class_key identifier not knowing if it is an elaborated_type_specifier or a class_head, with and without a nested_name_specifier after the class_key
<li> ^-- these latter two bullets identify grammar rules we will either
      delete (if not in 120++) or refactor
</ul>
-->
</p><p>


</p>
<p>

</p><h3> Suggestions on HW </h3>

<dl>
<dt> Did you Test your Work on lovecraft?
</dt><dd> Lots of folks doing work on lots of OSes, but if it doesn't run well
     on the test machine, you won't get many points.
</dd><dt> Warnings are seldom OK
</dt><dd> shift/reduce warnings are "usually" OK (not
     always). Get rid of other warnings so that when warning of a real
     issue shows up, you don't ignore it like "the boy who cried Wolf!".
</dd><dt> Using <code>{ $$ = $4; }</code> is probably a bad idea
</dt><dd> Q: Why?  Q: under what circumstances is this fine?
</dd><dt> Using <code>{ $$ = $1; }</code> goes without saying
</dt><dd> It is the default... but epsilon rules had better not try it.
</dd><dt> passing an fopen() or a malloc() as a parameter into a function is
     probably a bad idea
</dt><dd> usually, this is a resource leak. It gives you no clean and safe
     way to close/free.
</dd><dt> Some of you are still not commenting to a minimum professional level
     needed for you to understand your own code in 6 months
</dt></dl>



<a name="semantic">
<h3> Semantic Analysis </h3>
</a>

Semantic ("meaning") analysis refers to a phase of compilation in which the
input program is studied in order to determine what operations are to be
carried out.  The two primary components of a classic semantic analysis
phase are variable reference analysis and type checking.  These components
both rely on an underlying symbol table.
<p>

What we <em>have</em> at the start of semantic analysis is a syntax tree that
corresponds to the source program as parsed using the context free grammar.
Semantic information is added by annotating grammar symbols with
<em>semantic attributes</em>, which are defined by <em>semantic rules</em>.
A semantic rule is a specification of how to calculate a semantic attribute
that is to be added to the parse tree.
</p><p>
So the input is a syntax tree...and the output is the same tree, only
"fatter" in the sense that nodes carry more information. 
Another output of semantic analysis are error messages detecting many
types of semantic errors.
</p><p>

Two typical examples of semantic analysis include:
</p><dl>
<dt> variable reference analysis
</dt><dd> the compiler must determine, for each use of a variable, which
     variable declaration corresponds to that use.  This depends on
     the semantics of the source language being translated.
</dd><dt> type checking
</dt><dd> the compiler must determine, for each operation in the source code,
     the types of the operands and resulting value, if any.
</dd></dl>
<p>


</p><h3> Mailbag </h3>

<dl>
<dt> You marked me down for Valgrind, but I didn't have illegal memory
     reads or writes!  What gives?
</dt><dd> From hw1.html:
<blockquote>
     For the purposes of this class, a "memory error" is a
     message from valgrind indicating a
     read or write of one or more bytes of illegal, out-of-bounds,
     or uninitialized memory.
</blockquote>
The uninitialized memory part includes messages such as:
<pre>==25504== Conditional jump or move depends on uninitialised value(s)
</pre>
You've been told that the valgrind header and summary,
including memory leaks, are not going to cost you points, I am only
interested in valgrind error messages reported for behavior at runtime.
Any stuff you see in between the valgrind header and summary is either
your output, or valgrind messages that may point at bugs in your code.
</dd></dl>

<h3> Notations used in semantic analysis:</h3>
<dl>
<dt> <strong><u>syntax-directed definitions</u></strong> </dt>
<dd> high-level (<em>declarative</em>) specifications of semantic rules </dd>
<dt> <strong><u>translation schemes</u></strong> </dt>
<dd> semantic rules and the order in which they get evaluated </dd>
</dl>
<p>

In practice, attributes get <em>stored</em> in parse tree nodes, and the
semantic rules are evaluated either (a) during parsing (for easy rules) or
(b) during one or more (sub)tree traversals.
</p><p>


</p><h3> Two Types of Attributes:</h3>
<dl>
<dt> synthesized
</dt><dd> attributes computed from information contained within children.
     These are generally easy to compute, even on-the-fly during parsing.
</dd><dt> inherited
</dt><dd> attributes computed from information obtained from elsewhere in
     the tree, such as a parent or siblings.
     These are generally harder to compute.  Compilers may be able to jump
     through hoops to compute some inherited attributes during parsing,
     but depending on the semantic rules this may not be possible in general.
     Compilers resort to tree traversals to move semantic information around
     the tree to where it will be used.
</dd></dl>

<p>
<font size="1"> <a name="19">lecture #19</a> began here</font>
</p><p>

<h3> Attribute Examples </h3>

Semantic attributes are used for a lot of things from now on in the course,
such as type checking, but here are a couple easier examples.

<h4> Isconst and Value </h4>

Not all expressions have constant values; the ones that do may allow
various optimizations.
<p>

<table border="">
<tbody><tr>
<th> CFG</th><th> Semantic Rule</th></tr>
<tr>
<td>
E<sub>1</sub> : E<sub>2</sub> + T
</td>
<td>
E<sub>1</sub>.isconst = E<sub>2</sub>.isconst &amp;&amp; T.isconst<br>
if (E<sub>1</sub>.isconst)<br>
&nbsp;&nbsp;&nbsp; E<sub>1</sub>.value = E<sub>2</sub>.value + T.value<br>
</td></tr>
<tr>
<td>
E : T
</td>
<td>
E.isconst = T.isconst<br>
if (E.isconst)<br>
&nbsp;&nbsp;&nbsp; E.value = T.value<br>
</td></tr>
<tr>
<td>
T : T * F
</td>
<td>
T<sub>1</sub>.isconst = T<sub>2</sub>.isconst &amp;&amp; F.isconst<br>
if (T<sub>1</sub>.isconst)<br>
&nbsp;&nbsp;&nbsp; T<sub>1</sub>.value = T<sub>2</sub>.value * F.value<br>
</td></tr>
<tr>
<td>
T : F
</td>
<td>
T.isconst = F.isconst<br>
if (T.isconst)<br>
&nbsp;&nbsp;&nbsp; T.value = F.value<br>
</td></tr>
<tr>
<td>
F : ( E )
</td><td>
F.isconst = E.isconst<br>
if (F.isconst)<br>
&nbsp;&nbsp;&nbsp; F.value = E.value<br>
</td></tr>
<tr>
<td>
F : ident
</td><td>
F.isconst = FALSE<br>
</td></tr>
<tr>
<td>
F : intlit
</td><td>
F.isconst = TRUE<br>
F.value = intlit.ival<br>
</td></tr>
</tbody></table>





<h3> Symbol Table Module </h3>

<ul>
  <li> Symbol tables are used to resolve names within name spaces.
  <li> Symbol tables are generally organized hierarchically according to the
       scope rules of the language.
<li>  Although initially concerned with simply
storing the names of various that are visible in each scope, symbol
tables take on additional roles in the remaining phases of the compiler.
<li>
  In semantic analysis, symbol tables store type information.
<li> For code generation, symbol tables store memory addresses
  and sizes of variables.
  </ul>
<p>

The following very abstract API description from the red dragon book might
give you an idea of some of the operations you would want to implement.

</p><dl>
<dt> mktable(parent)
</dt><dd> creates a new symbol table, whose scope is local to (i.e. inside)
          a parent symbol table (the parameter). The outermost table has
          a null parent -- usually the "global" symbol table.
</dd><dt> enter(table, symbolname, type, offset)
</dt><dd> insert a symbol into a table.  Type and offset information will
           be discussed a little later. There might be more info about the
           symbol (i.e. more parameters) that you need to store.
</dd><dt> lookup(table, symbolname)
</dt><dd> lookup a symbol in a table; returns a pointer to a structure (or
object) that has type and offset information.  lookup operations are often <em>chained</em> together progressively from most local scope on out to global scope.
</dd><dt> compute_width(table)
</dt><dd> sums the widths of all entries in the table.
<ul>
<li> "widths" are units of #bytes.
<li> The sum of widths is the #bytes needed for the entire memory region
   reserved for this scope.
<li> There might be padding bytes to comply with word-alignment rules
<li> Examples: activation record (for a function call),
     global data section, or class/struct instance.
</ul>
   Worry not about method compute_width() until code generation
   you wish to implement.

</dl>

As we may have mentioned in a previous lecture, these symbol tables are
attached to scopes, which in most languages are nested inside enclosing
scopes, forming a tree of scopes.  As one walks around the parse tree
one needs to remember which symbol table you are in at any given time.
You can implement a stack of symbol tables that you push and pop in parallel
with entering and exiting tree nodes that introduce scopes, or you can
implement a semantic attribute in your tree nodes so each node knows its
scope/symbol table.  The "stack" push and pop symbol table API might have

<dl>
<dt>newscope = enterscope(table, name)
<dd> enters (pushes) the local scope of the named entity, looking up name in table
<dt>newscope = exitscope()
<dd> exits/pops a local scope, returning to the previous scope
<dt> currentscope()
<dd> return the current scope, i.e. the top of the stack
</dl>



<h3> Symbol Table Basics </h3>

The goal of a symbol table is to allow storage and retrieval of variable
(and related) information by name.  We are <em>associating</em> a data payload
with that name, so we need a struct with the name and the data payload, and
lookup and insert functions on it.  What is the data payload?

<pre>struct symtab_entry {
   char *sym;
   struct typeinfo *type; /* what type is this variable? forthcoming */
   /* ... more stuff added later ... */
}
</pre>

We have to be able to look up stuff by name.
We could just do this with a linked list:

<pre>struct elem {
   struct symtab_entry *ste; // information about a symbol
   struct elem *next;
   };
struct elem *theEntireSymbolTable;
struct symtab_entry *lookup(struct elem *st, char *name) {
   if (st==NULL) return NULL;
   if (!strcmp(st-&gt;ste-&gt;sym, name)) return st-&gt;ste;
   return lookup(st-&gt;next, name);
}
struct elem *insert(struct elem *st, char *name, struct typeinfo *t) {
   struct elem *n;
   struct symtab_entry *ste = lookup(st, name);
   if (ste != NULL) {
      fprintf(stderr, "symbol is already inserted\n");
      exit(3);
      }
   /* ste was NULL, make a new one */
   ste = malloc(sizeof (struct symtab entry));
   ste-&gt;sym = strdup(name);
   ste-&gt;type = t;
   n = malloc(sizeof (struct elem));
   n-&gt;ste = ste;
   n-&gt;next = theEntireSymbolTable;
   theEntireSymbolTable = n;
}
</pre>

<ul>
<li> Pros: simple
</li><li> Cons: O(n) does not scale well as n gets big
</li></ul>

<h3> Aside on malloc() </h3>

malloc() can fail and return NULL. Consider something like the following,
that you can use everywhere in place of malloc():

<pre>void *ckalloc(int n) // "checked" allocation
{
  void *p = malloc(n);
  if (p == NULL) {
     fprintf(stderr, "out of memory for request of %d bytes\n", n)
     exit(4);
  }
  return p;
}
</pre>


<h3> Hash Functions and Hash Tables for Symbol Tables </h3>

<ul>
<li> purpose: array-like performance for string lookups in large
     collections of strings.
</li><li> will be O(1) on average iff
<ul> <li> you have enough buckets and if
     </li><li> hash function is O(1) and if 
     </li><li> hash function distributes symbols perfectly across buckets
</li></ul>
</li><li> recommended implementation: array of linked lists
</li><li> goal of hash <em>function</em>: produce a unique random integer for
     each unique symbol. Then modulo it by # of buckets to pick array index
</li><li> How many buckets? Ideally, sized proportionally slightly larger than the
     # of symbols, but number of symbols varies widely across all possible
     source codes. We can certainly calculate averages and choose # of
     buckets large enough to handle the average case well.
     Serious/real compilers will grow the # of buckets if necessary.
</li></ul>

<pre>int hash(char *s) { return 0; }   // linked list, O(n)
int hash(char *s) { return s[0];} // hash using first char, x1 x2 x3 hash same
int hash(char *s) {               // what does this one do?
   int len = strlen(s);
   return s[0] + (len&gt;1 ? s[len-1] : 0);
}
int hash(char *s) {               // "good enough"; what's weak here?
   int i=0, sum = 0, len = strlen(s);
   for( ; i&lt;len; i++) sum += s[i];
   return sum;
}
</pre>

<h3> Looking at More Symbol Table Examples </h3>

<ul>
<li> You may find the symbol tables in [Jeffery21] or in [Thain] to be
particularly helpful to you.
<li> The <A href="symt.c.html"> symt.c</A> and <A href="symt.h.html">symt.h</A> examples may regurgitate the lecture notes symbol tables or vice versa; do
  they have any missing pieces or provoke any useful questions/discussion?
</ul>

<p>

<p>
<font size="1"> <a name="20">lecture #20</a> began here</font></p><p>
</p><p>

<h3> Varying Project Requirements Based on Group Size </h3>

<ul>
<li> We have group sizes ranging from 1-5+ in this class.
<li> Making the requirements vary based on group size is a pain for
  grading, and leaving the requirements the same regardless of group
  size provides some incentive to join a group
<li> But, maybe I should have some extra expectations performance for groups,
  correlated but not proportional to their additional human resource capacity.
</ul>

<h3> Mailbag </h3>

<dl>
  <dt> Can PunY have multiple classes inside a source file?
    <dd> Yes.
  <dt> What are the built-ins? Where are they described?
       How are we supposed to implement them?
    <dd> Good questions. I have not taken CSE 107. What do you think
      should be in this list?  I have taken a first stab over at
<A href="http://www.cs.nmt.edu/~jeffery/courses/423/punyref.html#Functions">
punyref</A> and have asked a couple folks.
<!--  <dt> Are all numeric data types supposed to be stored as doubles?
    <dd> No, floats and doubles are to be stored as doubles.
      Integer types are to be stored as longs.-->
<!--  <dt> What type of expression is acceptable inside a while-loop header?
    <dd> Trying to be consistent with spec language for for-loops:

<dt> What type of expression is acceptable inside an if-statement header?
  <dd> "If statements use syntax simlar to while loops", so:
    <dt>-->
</dl>


<h3> Lessons From the Godiva Project </h3>

By way of comparison, it may be useful for you to look at
some symbol tables and type representation code that were written for
the Godiva programming language project. Check out its hash function.
Being a dialect of Java, Godiva
has compile-time type checking and might provide relevant ideas for OOP
languages.

<ul>
<li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/type.h">type.h</a>
</li><li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/type.c">type.c</a>
</li><li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/symtab.h">symtab.h</a>
</li><li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/symtab.c">symtab.c</a>
</li></ul>

<h3> Symbol Table Example </h3>

Consider this simple nonsense program:

<pre>int foo(int x, char *y) {
   return x;
   }

int main()
{
   int z;
   z = foo(5, "funf");
   return 0;
}
</pre>

or, in Python

<pre>def foo( x:int, y:str) -> int :
   return x

z : int
z = foo(5, "funf")
</pre>



What does its syntax tree look like?  Can we (by hand) simulate the symbol
table population process?  Even a small example like this is a pain to do
by hand!

<p>

<img src="symtab_exampletree.png" width=1000>



<p>
<font size="1"> <a name="21">lecture #21</a> began here</font>
</p>

<h3> Mailbag </h3>

<dl>

<dt> Suppose the following code with the types after the execution of the
line in the parenthesis:

<pre>
1 z : int   (z => type int, x => type any)
2 z = 4    (z => type int, x => type any)
3 x = 5    (z => type int, x => type int)
4 x = "string" (z => type int, x => type string)
5 z = "string" (error!)
</pre>

How do we handle this?

<dd> In PunY if z is declared to be of type int in a given scope, it is an
error to assign any other type to it.  Line 1 causes line 5 to be an error.
In the absence of a declaration, variables are of type Any and may be
assigned any type.  So, line 3 is not performing also the equivalent of line
1, and neither is line 4.  They both assign values of different types to a
variable of type Any.

x is a variable of type Any that happens to hold an int at one particular time,
but z is a variable of type int that can only be asked to hold ints.

<dt> At run time, we have variables with type any.  How is
it that we get their value? The following is why I am unclear:
<ul>
<li>  If string => Easy, sval will not be NULL
<li>  If int (though called number as a token) => can't check against dval,
    because 0.0 is a valid dval
<li>  If float/double/cool word to describe real number => can't check against
  ival because 0 is a valid ival
<li>
Additionally we cannot check the token type because token NUMBER
does not tell us if it is a float/int.
</ul>

<dd> ival, sval and dval are lexical attributes: compile-time things that
apply to literal constant tokens only.

For variables with type any, we will need a strategy for runtime, and we
will need to emit instructions to read and write values at runtime.

The virtual machine we will target by default is in fact very well-suited
for a lot of this, since it is one of Python's ancestors.
  From a recent addition to punyref.html:

<blockquote>

The rules are: if you assign a value to a variable without a declaration,
the variable is implicitly declared to be of type Any. For example you can
say

<pre>
x  = 5
</pre>

Since anything can be assigned to variable of type Any, it is fine receiving
a 5. Suppose now that you declare a variable of type int, and assign x to
it.

<pre>
y : int
y = x
</pre>

If the compiler does not know the type of x, the generated code for
assignment to y must look like

<pre>
y = int(x)
</pre>

Note that the conversion-to-int is more tied to the assignment-to-an-int
rather than to the x that is to be converted.  One almost wants to define
typed assignment operators like =<sub>int</sub> and to modify your syntax
tree to make it look like:

<pre>
y =<sub>int</sub> x
</pre>

But I am a pragmatist. You could encode this by modifying the syntax tree to
explicitly call the int() function if you want.

</blockquote>

</dl>

<h3> Old Mailbag </h3>

<dl>
<dt> How should I focus my midterm studying? There is a lot of material
     in this class and I would like to try to optimize my study time.
     Should I focus on the lecture notes? Should I be studying the textbooks?
</dt><dd> The best way to study for the exams in this course is to do
     your homework assignments.  I try to write exam questions that you
     should know if you have done your assignments.  Having said that,
     if I were picking and choosing between the lecture notes or the books
     I would hit the lecture notes the hardest, referring to the books
     when more (or different) explanations are needed.

<dt> I still have no idea where to start my symbol table HW!  What do I do?
</dt><dd>The symbol table HW (and next few HW's) are tree traversals.
     There is but a single, powerful magic tool at your
     disposal: recursion. Start with basis cases, at leaves.
     Make it work for the MOST SIMPLE CASES POSSIBLE before
     you worry about anything bigger.
     Work your way up the tree.
</dd><dt> Where do I store my symbol tables?
</dt><dd> If I were you, I'd just get a single (global) symbol table working
     before worrying about local scopes, but... the obvious alternative
     answer to your question are:
<ul>
<li> in the node at the top of each local scope, such as class or function
       declaration nodes.
  In this case, it is an attribute that can be inherited, so it might
  be in all the tree nodes.
</li><li> in the symbol table entry for the symbol that owns the scope. For example
     main's local symbol table in main's symbol table entry.
</li></ul>
It may well be easier to do both, than to do either one by itself. So from now
on, I am going to pretend that you stick pointers to your symbol tables
in both places.

<dt> Do we have to check whether array (or map, if writing a language
      with maps/dictionaries) subscripts are legal (correct type, in-range)
 in this homework?
</dt><dd> Checking "legality" is the next (type checking) HW's job.
    Even then, some checks are not do-able by the compiler and if required,
    entail generating code that does the checks at runtime.

</dd><dt> My tree's attributes aren't propagating from parent to child, why not?
</dt><dd> If there are tree nodes in the middle, there have to be semantic
    rules that copy attributes
up or down in order for the information to get from source to destination.
</dd>

</dd><dt> What is wrong with this hash?
<pre>for(i=0; i &lt; strlen(s); i++) {
   sum += s[i];
   sum %= ARRAYSIZE;
   }
</pre>
</dt><dd> How many potential problems can <em>you</em> find in this code?

<!--
<dt>

In the enter_newscope() function in your sample code, what is
<pre>t = (typ==CLASS_TYPE) ?
      alcclasstype(s, new):alcmethodtype(NULL,NULL,new);
</pre>
It is code to deal with methods and classes, but what is
different about member functions ("methods") than ordinary functions?

<dd> Both regular functions and class member functions introduce a new
scope, the difference is that class member functions' enclosing scope is
the class, and within that class, they can find and use other members
(variables and functions) of the class, including private members.
In order to do this, they use an extra parameter (named "this" or "self"),
which will affect us mainly in code generation.
-->
</dd>

<dt>  I was wondering if it would be better for the hash table to build
      it based on the terminals I find in the tree or the non-terminals?
</dt><dd> the keys you are inserting and looking up in hash tables are
     the variable names declared in the program you are parsing --
     those names came into your tree as terminals/leaves, and not
     all the leaves -- only leaves that are names of things (identifier, or
     LNAME, or whatever you are calling them), and only when those leaves
     appear in particular subtrees/production rules where new variables or
     functions (or type names) are being introduced.
</dd><dt> As I am traversing the tree, should I be looking for NAMEs
     and other terminal symbols, and then to determine if I should insert
     them, or should I look for nonterminals and then as I see those
     non terminals grab the LNAME and the other important data
</dt><dd> Sorta the latter, you are usually looking for non terminals or
     specific production rules, and then traversing selected children
     within which you know you have a list of names being declared.
</dd></dl>



<h3> Variable Reference Analysis </h3>

The simplest use of a symbol table would check:

<ul>
<li> for each variable, has it been declared?  (undeclared error)
<li> for each declaration, is it already declared? (redeclared error)
</ul>

<p>


</p><h3> Semantic Analysis in Concrete Terms </h3>

Broadly, we can envision the semantic analysis as two passes:

<dl>
<dt> Pass 1: Symbol Table Population
</dt><dd> Symbol table population is a syntax tree traversal in which
we look for nodes that introduce symbols, including the creation
and population of local scopes and their associated symbol tables.
As you walk the tree, we look for specific nodes that indicate
symbols are introduced, or new local scopes are introduced. What
are the tree nodes that matter (from <a href="https://www.cs.nmt.edu/~jeffery/courses/423/cgram.y">cgram.y</a>)
in this particular example?
<ol>
<li> create a global symbol table (initialization)
</li><li> each function_declarator introduces a symbol.
</li><li> each init_declarator introduces a symbol.
</li><li> oh by the way, we have to obtain the types for these.
</li><li> "types" for functions include parameter types and return type
</li><li> "types" for init_declarators come from declaration_specifiers,
     which are "uncles" of init_declarators
</li></ol>

</dd><dt> Pass 2: Type Checking
</dt><dd> Type checking occurs during a bottom up traversal of the expressions
within all the statements in the program.
</dd></dl>



<h3> Discussion of <a href="https://www.cs.nmt.edu/~jeffery/courses/423/semantic.c.html">a Semantic Analysis Example</a></h3>

<ul>
<li> When talking about semantic analysis, it is easy to quickly get lost in
    the weeds, for example
     how to represent type information -- we need all that, but
     we need tree traversal examples worse, and symbol table examples.
</li><li> semantic.c has example tree traversals that do different tasks
     during semantic analysis.
</li><li> this example's treewalks best understood in context of
    <a href="https://www.cs.nmt.edu/~jeffery/courses/423/cgram.y">cgram.y</a>.
<li> this was "ripped out" of a past project;
    your project this semester will need similar treewalks but you will have
    different non-terminals and production rules.
</li><li> goal: give you ideas
</li><li> not meant to force you to use this code, or do things this way
</li></ul>

<p>

</p><h3> Old Mailbag </h3>

<dl>
<dt> I feel like I am just staring at a wall...
     I am just kinda lost as to how to start.
</dt><dd> Start by copying modifying your tree printer to only print
     out the names of variables at the point at which they are declared.
</dd>
<dt>As I am creating new symbol tables, how should I keep track of them?
    Should I include like a *next pointer?
</dt><dd>
 There is logically a tree of symbol tables.  Parent symbol tables (in our
 case the symbol table for our "global" package, package main) contain
 entries for symbols defined within them, such as functions, so the parent
 should be able to reach the children's symbol tables by looking them up by
 name within the parent symbol table.  On the other hand, children's symbol
 tables might want to know their parent enclosing symbol table. For general
 nested programming language the child symbol table should contain a parent
 pointer.  For the special case that is our language this semester,
 there isn't much nesting and
 you could just have a global variable that knows the root symbol table (for
 package main) and every symbol table that is not the root, can rest assured
 that its parent is the root.

</dd>
<dt> So, how many symbol tables do we have to have?  More than one?
</dt><dd> One for each package, one for each function, one for each struct type.
</dd><dt> How do I know what symbol table I am using?
</dt><dd> One could implement this as an inherited attribute, or one can
     track it with an auxiliary global as one walks around the tree.
     If you don't do the inherited attribut, you may have to maintain a
     stack of scopes.
     When you walk into something that has a more local scope, make that
     scope current and use enclosing scopes when more local scopes don't
     find a particular symbol you are looking for.  
</dd></dl>


</p>




<p>
<!--<em> Ask about packages and "import" declarations
here, if the source language this semester supports them.</em>-->
</p><p>

</p>

<p>
<font size="1"> <a name="22">lecture #22</a> began here</font>
</p>

<h3> Mailbag </h3>
     
<dl>
<dt>
It seems like my approach to finding different cases of variable
declarations is not ideal. I'm just looking for some more of the
"parse tree theory" behind the variable declarations, and then a
little bit of guidance for putting that theory into efficient code.
<dd>

You should spend some time getting familiar with your trees.  Mostly they
will reflect your PunY grammar, which you should also get familiar with.
And while I am not familiar with much "parse tree theory" or "syntax tree
theory", we can certainly talk about "tree theory". It is all about
recursion, since trees are recursively defined: what do we do for basis
cases (leaves) and recursion steps (internal nodes)?

<blockquote> "Grok recursion deeply and you can do anything that
  needs doing on computers"</blockquote>
is a grotesque paraphrase of my grad
school algorithms prof Udi Manber, former VP of Search at Google.
<p>

However you represent it in the actual bits, you have to be able to tell for
each tree node what production rule built it. And you have to be able to
look for specific nodes, and traverse the unique shapes that they have
underneath them.

<p>

  Other than that, the main way for me to help you might be to draw the
  shapes of your (syntax tree) subtrees for various grammar rules, but of
  course, that depends on what you did in your version of cgram.y

</dl>

<h3> Old Mailbag </h3>


<dl>
<!--
<dt> Does our language require the type to be given for every parameter?
sounds like it does.
</dt><dd> The VGo spec mentions having to know the name and type for every
parameter. But the VGo spec also says you can omit the type of the next
item in a comma separated parameter list is the same type.
</dd>-->
<dt> Does our language support calling a function inside another call, as in
<pre>   printf(Compare(t1, New(99,1)));
</pre>
<!--
<pre>   fmt.Println(Compare(t1, New(99,1)));
</pre>
-->
</dt><dd> Yes.

</dd><dt>How to deal with includes/imports: what does -in general- a compiler do?
For example, when it includes math.h (or in other languages, imports a math
package), does it copy the functions'
declarations? Where can I find the math package file? Are there in Bison
built-in function to copy these stuff and added them to the source file, or
should I do copy content and edited the source file in C at the main
function?

</dt><dd> Great question.  In a real compiler, an include or import is a
    pretty big operation. #include textually inserts another file, while
    import is probably reading from a database to get the
declarations of the package being imported.  For our language we are doing a
hardwired special case, treating these as "built-ins", so the
    compiler can do whatever it wants in order to get the runtime library
    functionality it needs. <!--"fmt" and "math/rand" and
"time" to work, just enough to do fmt.Println, rand.Intn, and time.Now.-->


</dd><dt> What about symbol table lookups related to structs in the next HW,
     Dr. J?  The homework doesn't talk about them much.
</dt><dd> You should catch redeclared variables in all scopes. You should catch
    undeclared variables in all scopes... But you will have to have
    type information (next HW) before you know the type of a struct in order
    to look up a symbol used after a dot operator. If you see <code>x.y</code> in
     the source code, how many symbol lookups is that?
</dd><dt> Are we supposed to create a separate symbol table for each function?
     Or just a symbol table for functions in general?
</dt><dd> You are supposed to create one "global" symbol table,
     one local symbol
     table for each function, and one local symbol table for each struct type.
</dd><dt> I am struggling on figuring out how to detect undeclared variables.
</dt><dd> We should talk about this in detail looking at the non-terminals used in
     your grammar. With any big vague software task,
     it is wise to break it up into smaller, well-defined pieces.  Before you
     try to find all undeclared variables, you could:
<ol>
<li> write a tree traversal that just lists
     all the <em>uses</em> of a variable (in expressions, where values are
     read or written), showing the variable name and line number.  These are
     the things that must be checked.
     <br> Still too big a job?  Break it into even smaller pieces:
     <ul>
     <li> write a tree traversal that just lists the names of functions for
          which you have a function body, and therefore a compound statement
          that contains executable expressions.
     </li><li> are there anything besides function bodies where you would have to
          check for undeclared variables?
     </li></ul>
</li><li> write a tree traversal that inserts all the variable declarations.
     print out the whole symbol table when finished, to show what you've got.
</li><li> modify the tree traversal #1 to lookup within the symbol table(s) and
     print semantic errors if any lookup fails.
</li></ol>
</dd></dl>


<h3> Discussion of "Import", and more Generally, Packages </h3>

Not all languages have them, but when you do...
<p>
  
Suggested approaches for implementing semantic analysis of packages/imports:

<dl>
<dt> treat "import" like a special "include"
</dt><dd>
<ul>
<li> Pros: moderately easy to implement (<a href="https://www.cs.nmt.edu/~jeffery/courses/423/fmt.go">fmt.go</a>,
     <a href="https://www.cs.nmt.edu/~jeffery/courses/423/mathrand.go">mathrand.go</a>, <a href="https://www.cs.nmt.edu/~jeffery/courses/423/time.go">time.go</a>)
</li><li> <code>import x.y.z</code> means class <code>z</code> out of
     package <code>x.y</code>.  (This is a Java thing. Can we dodge it?)
</li><li> In a language such as Go, <code> import "math/rand"</code> means import the rand package from
     the math directory.  From the official
     <a href="https://golang.org/doc/code.html">Go site</a>:
<ul>
<li> a workspace contains repositories
</li><li> repositories contain packages
</li><li> packages consist of source files <b><em>in a single directory</em></b>
</li></ul>
Directories in some language (e.g. Go; C++ ?) can contain multiple packages,
while in others (Java) maybe not, other than nested ones.

</li><li> Cons: pain to make the lexer/parser do this work.
</li></ul>
</dd><dt> respond to "import" by inserting some symbol table entries (hardwired
     to the package name)
</dt><dd>
<ul>
<li> Pro: don't have cons of the include approach
</li><li> Con: either have to reparse whole files in order to suck in types
     for symbols we import OR have to write out symbol tables as external
     files/repositories of info about compiled packages/classes
</li></ul>
</dd></dl>



<h3> Representing Types </h3>

In statically-typecheck'ed languages,
the target language's type system must be represented using data
structures in the compiler's implementation language.
In the symbol table and in the parse tree attributes used in type checking,
there is a need to represent and compare source language types.  You might
start by trying to assign a numeric code to each type, kind of like the
integers used to denote each terminal symbol and each production rule of the
grammar.  But what about arrays?  What about structs?  There are an infinite
number of types; any attempt to enumerate them will fail.  Instead, you
should create a new data type to explicitly represent type information.
This might look something like the following:
<p>

</p>
<pre>struct type {
   /*
    * Integer code that says what kind of type this is.
    * Includes all primitive types: 1 = int, 2=float,
    * Also includes codes for compound types that then also
    * hold type information in a supporting union...
    * 7 = array, 8 = struct, 9 = pointer etc. */
   int base_type;
   union {
      struct array {
         int size; /* allow for missing size, e.g. -1 */
	 struct type *elemtype; /* pointer to type for elements in array,
	 				follow it to find its base type, etc.*/
      } a;
      struct struc {		/* structs */
         char *label;
	 int nfields;
         struct field **f;
	 } s;
      struct type *p;		/* pointer type, points at another type */
   } u;
}

struct field {			/* members (fields) of structs */
   char *name;
   struct type *elemtype;
}

</pre>




Given this representation, how would you initialize a variable to
represent each of the following types:

<pre>int [10][20]
struct foo { int x; char *s; }
</pre>

  <p>
    For PunY, this might look like:

<pre>struct type {
   /*
    * Integer code that says what kind of type this is.
    * Includes all primitive types:
    * 1 = int, 2=float, 3=string, 4=bool,
    * Also includes codes for compound types that then also
    * hold type information in a supporting union...
    * 5=list, 6=dict., 7=func, 8=class */
   int base_type;
  /* gone away! for PunY */
  union {
   struct funcdef {
      struct type *return_type;
      int nparams;
      struct params **p;
      } f;
/* maybe we can get away with just "knowing" for only predefined class info
   struct classdef {
      struct methods **meth;
      struct members **mem;
      } f;
 */
   } u;
}

struct field {			/* members (fields) of structs */
   char *name;
   struct type *elemtype;
}
</pre>

<p>

</p>

<h3> Midterm Exam Review </h3>

The Midterm will cover lexical analysis, finite automatas, context free
grammars, syntax analysis, parsing, and semantic analysis*.
*except type checking
<p>

Q: What is likely to appear on the midterm?
</p><p>

A: questions that allow you to demonstrate that you know
</p><ul>
<li> regular expressions
</li><li> the difference between an DFA and an NFA
</li><li> lex and flex and tokens and lexical attributes
</li><li> the %union and yylval interface between flex and bison
</li><li> context free grammars:
   ambiguity, factoring, removing left recursion, etc.
</li><li> bison syntax and semantics
</li><li> parse trees
</li><li> symbol tables
</li><li> semantic attributes, type checking
</li></ul>


<p>

Sample problems:

</p><ol>
<li> Write a regular expression for numeric quantities of U.S. money
     that start with a dollar sign, followed by one or more digits.
     Require a comma between every three digits, as in $7,321,212.
     Also, allow but do not require a decimal point followed by two
     digits at the end, as in $5.99
</li><li> Write a non-deterministic finite
     automaton for the following regular expression, an abstraction
     of the expression used for real number literal values in C.<pre>     (d+pd*|d*pd+)(ed+)? </pre>
</li><li> Write a regular expression, or explain why you can't write a
     regular expression, for Modula-2 comments which use (* *) as
     their boundaries.  Unlike C, Modula-2 comments may be nested,
     as in (* this is a (* nested *) comment *)
</li><li> Write a context free grammar for the subset of C expressions
     that include identifiers and function calls with parameters.
     Parameters may themselves be function calls, as in f(g(x)),
     or h(a,b,i(j(k,l)))
</li><li> What are the FIRST(E) and FOLLOW(T) in the grammar: <pre>     E : E + T | T
     T : T * F | F
     F : ( E ) | <b>ident</b></pre>
</li><li> What is the &#949;-closure(move({2,4},b)) in the following NFA?
     That is, suppose you might be in either state 2 or 4 at the time
     you see a symbol b: what NFA states might you find yourself in
     after consuming b?<br> (<em>automata to be written on the board</em>)
</li><li> 



 (20 points) (a) Explain why a compiler might be less able to recover and
continue from a lexical error than from a syntax error. (b) Explain why a
compiler might be less able to recover and continue from a syntax error than
from a semantic error.



</li><li> (30 points) (a) Write a regular expression (you may use Flex extended
regular expression operators) for declarations of the form given by the
grammar below. You may use the usual regular expression for C/C++ variable
names for IDENT. (b) Under what circumstances is it better to use regular
expressions, and under what circumstances is it better to use context free
grammars?

<pre>declaration : type_specifier decl_list ';' ;
type_specifier : INT | CHAR | DOUBLE ;
decl_list : decl | decl ',' decl_list ;
decl: IDENT | '*' IDENT | IDENT '[' INTCONST ']' ;
</pre>

<p>

</p></li><li> (30 points) Some early UNIX utilities, like grep and lex, implemented a
non-deterministic finite automata interpreter for each regular expression,
resulting in famously slow execution. Why is Flex able to run much faster
than these early UNIX tools?

<p>

</p></li><li> (20 points) Perhaps the most important thing to learn in homework #2
about Flex and Bison was how the two tools communicate information between
each other. Describe this communications interface.

<p>

</p></li><li> (30 points) Perhaps the second most important thing to learn in homework
#2 was how and when to build internal nodes in constructing your syntax
tree.
<br>
(a) Describe how and when internal nodes need to
be constructed, in order for a Bison-based parser to end up with a tree that holds all leaves/terminal
symbols. (b) Under what circumstances might a new non-terminal node construction site be skipped?
(c) Under what circumstances might some of the leaves/terminal symbols not be needed later during
compilation?


</li><li> (40 points) Consider the following grammar for C variable declarations,
given in YACC-style syntax.  sm  stands for semi-colon. cm stands for
comma. id stands for identifier. lb stands for left square
bracket. intconst stands for integer constant. rb stands for right
square bracket.

<pre>VD : CL T DL sm ;
CL : static | register | /* epsilon */ ;
T : int ;
DL : D | D cm DL ;
D : id | AST D | D lb intconst rb ;
</pre>

a) What are the terminal symbols? b) What are the nonterminal symbols? c) Which nonterminals have
recursive productions? d) Remove left recursive rules from this grammar if there are any.


</li><li>(30 points) Write C code that is error free and produces no warnings,
which performs the following tasks: a) declare a variable of type pointer to
struct token, where struct token has an integer category, a string lexeme,
and an integer lineno, b) allocate some memory from the heap large enough to
hold a struct token and point your variable at it, and c) initialize your
memory to all zero bits. You may assume <code>struct token</code> with
its field definitions, has already been defined earlier in the C file
before your code fragment.


</li><li> (20 points) In looking at your yydebug output, several of you noticed
that it appeared like the same terminal symbol (for example, a semi-colon)
was repeated over and over again in the output, even through sections of
parsing where no syntax error occurred. Why might the same terminal symbol
appear on the input repeatedly through several iterations of a shift-reduce
parser. (30 points) What are semantic attributes? Briefly define and give
an example of the major kinds of semantic attributes that might be used in
semantic analysis for a language such as C++.

</li><li> (30 points) Symbol tables play a prominent role in semantic
analysis. How are symbol tables used in type checking? Give an example, with
a brief explanation of how the symbol table is involved.


</li></ol>


</p><p>
<font size="1"> <a name="23">lecture #23</a> began here</font>
</p><p>

<h3> Midterm Distribution </h3>

270 points possible. Grading is relative to the top score earned.

<pre>
  245
  231 234
  221 225
  215
----------------- 87% of max
  208 209 210
  200 200 204 205
  198
  181 181
----------------- 74% of max
  172 176 179
  167
  154 157 158
----------------- 61% of max
  141 142 145
  131 132 132
  122 127
  119
----------------- 48% of max
  72
</pre>

<h3> A <A href="cse107/">CSE 107 Test Suite</A> for PunY </h3>

<ul>
<li> One student's real-world code base
<li> ~49 modules ranging from 1-262 LOC
<li> What can we learn (and update our punyref doc) from it?
<li> Functions used: int, str, len, del, input, open,
     print(L), print(s), print(s,i),
<li> String methods: replace, split
<li> List methods: append, remove
<li> File methods: read(), write(), close
<li> While loops, nested while loops
<li> If statements with x == y or x == z (up to 4 "or" clauses)
<li> == used for integer, string comparison
<li> Multiline """..."""
<li> Standard imports used: os, random, math, turtle, date, matplotlib.pyplot
<li> random.choice(), math.sqrt, math.gcd, math.asin, math.acos, math.atan,
    turtle.speed(), turtle.Turtle(), turtle forward/left/right/done
<li> User-defined imports! (<code>import module as foo</code>, followed
  by foo.main(), etc.)
</ul>

<h3> Mailbag </h3>

<dl>
<dt>

I'm trying to make a given node's symbol table into an inherited
attribute. However, whenever I <code>#include "symtab.h"</code>
in my <code>tree.h</code> file
so that I can add a SymbolTable attribute to my tree nodes, I get
function redeclaration errors for everything that's in my <code>symtab.h</code>
file. Basically, I think the problem is that <code>symtab.h</code> is getting
included in too many places. Do you have any suggestions on
how to share <code>symtab.h</code> into <code>tree.h</code>?

<dd> Consider which case each <code>.h</code> file falls into:
<ul>
<li> If a <code>.h</code> file gets included multiple times,
    and all it has are prototypes and <code>extern</code>s, it is harmless.
<li> If a <code>.h</code> file gets included multiple times and it
  has <code>typedef</code>s, those cause errors and have to be
  protected, e.g.  by a clever <code>#ifdef</code>.
<li> If a <code>.h</code> file contains actual bodies of C functions
  (definitions), or if <code>.c</code> files get included, then you
  were asking for trouble.  Cut that out.
</ul>

The typical way of protecting a file <code>foo.h</code> from being multiply
included is:

<pre>
#ifndef FOO_H
#define FOO_H
...rest of your .h file
#endif
</pre>

I've seen folks manage to get into trouble despite such a protection,
or implement such a protection incorrectly, but it takes work to do so.
</dl>



<h3> Building a Type struct from a Syntax Tree Fragment </h3>

<ul>
<li> Given some type representation, and
<li> a constructor (or helper function, or factory method) that
   allocates/creates instances of that type representation,
<li> How do we synthesize and/or inherit that type to everywhere
    in the syntax tree that needs/uses the type?
<li> Possible Answers...
<ul>
  <li> synthesize in the subtrees where the type information originates
  <li> inherit in the subtrees where the type information is associated
       with names (declarations)
  <li> insert the type information at the points where names go into the
       symbol table
  <li> lookup the type information at the points where names get used in
       executable code
</ul>
<li> You may use as many passes through the tree as you need!
<li> For some languages it may be possible to do in one pass, but often
  that's only because the language syntax was contorted to make that happen
</ul>



<pre>/*
 * Build Type From Prototype (syntax tree) Example
 */
void btfp(nodeptr n)
{
   if (n==NULL) return;
   for(int i = 0; i &lt; n-&gt;nkids; i++) btfp(n-&gt;child[i]);
   switch (n-&gt;prodrule) {
   case INT:
      n-&gt;type = get_type(INTEGER);
      break;
   case CHAR:
      n-&gt;type = get_type(CHARACTER);
      break;
   case IDENTIFIER:
      n-&gt;type = get_type(DONT_KNOW_YET);
      break;
   case '*':
      n-&gt;type = get_type(POINTER);
      break;
   case PARAMDECL_1:
      n-&gt;type = n-&gt;child[0]-&gt;type;
      break;
   case THINGY:
      n-&gt;type = n-&gt;child[0]-&gt;type;
      break;
   case PARAMDECL_2:
      n-&gt;type = clone_type(n-&gt;child[1]-&gt;type);
      n-&gt;type-&gt;u.p.elemtype = n-&gt;child[0]-&gt;type;
      break;
   case PARAMDECLLIST_2:
      n-&gt;type = get_type(TUPLE);
      n-&gt;type-&gt;u.t.nelems = 1;
      n-&gt;type-&gt;u.t.elems = calloc(1, sizeof(struct typeinfo *));
      n-&gt;type-&gt;u.t.elems[0] = n-&gt;child[0]-&gt;type;
      break;
   case PARAMDECLLIST_1:
      n-&gt;type = get_type(TUPLE)

      /* consider whether left child, guaranteed to be a PARAMDECLLIST,
         is guaranteed to be a tuple.  Maybe its not. */
      n-&gt;type-&gt;u.t.nelems = n-&gt;child[0]-&gt;type-&gt;u.t.nelems + 1;
      n-&gt;type-&gt;u.t.elems = calloc(n-&gt;type-&gt;u.t.nelems,
				      sizeof(struct typeinfo *));
      for(i=0;i &lt; n-&gt;child[0]-&gt;type-&gt;u.t.nelems; i++)
         n-&gt;type-&gt;u.t.elems[i] = n-&gt;child[0]-&gt;type-&gt;u.t.elems[i];
      n-&gt;type-&gt;u.t.elems[i] = n-&gt;child[1]-&gt;type;

      break;
   case INITIALIZER_DECL:
      n-&gt;type = get_type(FUNC)
      n-&gt;type-&gt;u.f.returntype = get_type(DONT_KNOW);
      n-&gt;type-&gt;u.f.params = n-&gt;child[1].type;
      break;
   case SIMPLE_DECLARATION_1:
      n-&gt;type = clone_type(n-&gt;child[1]-&gt;type);
      n-&gt;type-&gt;u.f.returntype = n-&gt;child[0]-&gt;type;
   }
}
</pre>


</p><p>
<font size="1"> <a name="24">lecture #24</a> began here</font>
</p><p>

<h3> Mailbag </h3>

<dl>
<dt> Our PunY compiler doesn't accept your sample 107 tests because they
       have carriage returns in front of the newlines. What do we do?
<dd> Before the next homework, plan to fix your lexical analyzer
  to accept either UNIX or MS-DOS line endings (NEWLINE can be either
  \n or \r\n in various regular expressions).

<dt> Can you explain to me again what is the worst-case I might need to
    handle in my symbol tables?
<dd> Before the next homework, you may need to upgrade your symbol tables
  to handle the extent of what can be known at compile-time in PunY as
  shown in the CSE 107 tests.
  As far as I have noticed, the biggest program there consists of three .py
  files that are used together:
  <pre>arcade.py hangman.py minesweeper.py</pre>
<p>

Before we dive further into the symbol tables, a brief discussion of
terminology is in order.  In the full Python language, as far as I know,
there are at least the following scopes:
<ul>
<li> global: symbols built-in to the language
<li> package: symbols that denote modules that live in a particular directory
<li> module: (global, file-scope) symbols that live in a .py file.
     (Every module also has an implicit function for the code that
     executes outside any function definition when the module is loaded.)
<li> class: (class-scope) symbols that live in instances
<li> function/method: (local) symbols that live in a function call
</ul>

In PunY we want to simplify as much as possible; for example in HW#4 you
just have to distinguish globals (which are really module-scope) from
locals (function-scope). But to properly handle arcade/hangman/minesweeper
we need to add one more level of scope, properly it is module scope.
<p>

The symbol tables look (very approximately; this is probably incomplete)
like this. Symbols could be
in any order depending on your hash implementation. While most symbols will
be inserted during semantic analysis, (built-in) symbols
would be inserted by hardwired code before your semantic analysis starts,
possibly before yyparse() is even called.
<pre>
GLOBAL
  input - (built-in) function
  print - (built-in) function
  os - (built-in) module. if user imports os, populate it w/ predefined syms
  len - (built-in) function
  list - (built-in) function
  open - (built-in) function
  file - (built-in) class
    write - (built-in) method   
    read - (built-in) method
    close - (built-in) method   
  random - (built-in) module.
    choice - (built-in) function
  arcade - module that you populate when compiler compiles arcade.py
    stats - function 6 parameters
      scoresh
      winsh
      lossesh
      scoresm
      winsm
      lossesm
      Geronimo
      CrazyHorse
      Redcloud
      t
      highscore
      q
      lowscore
      gamesm
      highscorem
    menu - function 6 parameters
      scoresh
      winsh
      lossesh
      scoresm
      winsm
      lossesm
      Oakley
      z
      j
      y
      w
      p
      v
    main - function 0 parameters
      Greetings
      Billy
      Villa
      Butch
      Wyatt
      Buffalobill
  h - module that you populate when compiler imports hangman as h
      tombofhorrors - function 2 parameters
        hickman
        tharizdun
        strahd
        lolth
        z
        score
        win
        loss
        e
      ravenloft = function 6 parameters
        hickman
        tharizdun
        lolth
        score
        win
        loss
        strahd
        balrog
        catoblepas
        beholder
        demagorgon
        y
        x
        lich
        dungeon
        dragon
        acerak
      main
        difficulty
        gygax
        hommlet
        zuggtomy
        giants
        drow
  m - module that you populate when compiler imports minesweeper as m
      main.  (to be filled in)
</pre>

<dt> Can you give me a more concrete example of how type information is
      produced and placed in symbol table entries?
<dd> Let's look at
      <pre>x : integer</pre>
It takes some digging to even figure out where in the grammar this is.
YOUR grammar may have it differently, but in Grammar.html, I guess it is
<pre>
              expr_stmt
             /         \
testlist_star_expr    annassign
              /           /    \
	    NAME        ':'    test
              x                  \
	                         expr
                                   \
                                  NAME
                                    int
</pre>

To place type int as the type of x, you would
<ol>
  <li> do a pass in which types
are synthesized up (type of int is int, type of expr is int, type of
test is int, type if annassign is int, type of expr_stmt is int), and then
<li> do a tree traversal in which symbol tables are populated and at the
expr_stmt that would insert x with type int.
</ol>

</dl>


<h3> From Types to Type Checking </h3>

What we saw last time:
<ul>
<li> add a <code>.type</code> field to struct treenode.
</li><li> some nodes can synthesize their type from their kids
</li><li> some nodes can pass type info from one kid down into another
</li></ul>


<h3> What to do about predefined things </h3>

<ul>
  <li> Some predefined things (Java: <code>System</code>, Python: math, os, ...)
    need to be in a global symbol table.
<li> Maybe
  what I call a "global symbol table" is really the symbol table
  for the current (default, aka anonymous) package.
<li> OK, what is a package?
<li> Well, like a function, it defines a scope and has a symbol table...
     Like a class its names include methods/functions and variables...
<li> So a package is somewhat similar to a static class, or a class where
     every name is static...
<li> <code>X.y</code> means a name <code>y</code> is defined within
  package <code>X</code>.  What is <code>y</code>'s type?
<li> <code>X.y.z</code> means a name <code>y</code> is defined within
  package <code>X</code>. What about z?
</ul>

<!--
<h3> What to do about Printf </h3>

<ul>
<li> print out ints and strings and floats (and address)
<li> OK to allow printf hardwired to take one % value
<li> check the format string for the % in order to check
     the wildcard second parameter type
</ul>
-->


  <h3>Syntax Trees to Type Representation Example</h3>


Let's consider an example parse tree for a function header.
In C it would be
<pre>int f(int x, int y, float z)
</pre>

<!--
In Go the equivalent is
<pre>func f(x int, y int, z float64)
</pre>
-->

We are studying tree shapes in order to write traversal functions.
We might broach questions such as:
<ul>
<li> How is the parse tree different under a left recursive
     grammar than it is under a right recursive (for example C) grammar?
</li><li> why not just use the parse tree of the function header as the
     "type information" that we store in the symbol table entry for
     function f?
</li><li> how to construct type information for this function type?
</li></ul>



<!--
<h3>Midterm Solutions</h3>

<A href="http://www.cs.nmt.edu/~jeffery/courses/423/423midterm-s22.pdf">midterm</A>
-->

<p>
<font size="1"> <a name="25">lecture #25</a> began here</font>
</p><p>

<h3> Where we are at </h3>

<ul>
<li> This week: type checking lectures
<li> Jeffery is working on grading
<li> If you haven't gotten HW#4 working/submitted
   <ul>
     <li> you are not alone
     <li> all is not lost
     <li> Come to class. Do the work. Get help.
   </ul>
</ul>

<h3> Reading Assignment </h3>

<ul>
<li> Read Thain Chapter 7
<li> If you have it, read the Jeffery textbook, Chapters 7-8
</ul>

<h3> Comments on HW#3 </h3>

<ul>
<li> Its important to get syntax trees working. Some of you should have gotten
    help several weeks ago.
<li> We are doing type checking, so please add support for type hint syntax
  if you have not done so yet.
<li> Many folks need to fix and resubmit, fine.
</ul>

<h3> Mailbag </h3>

<dl>

<dt> Given that Python is not normally invoked with multiple files on the
    command line, what are the PunY semantics of that?
<dd> The good news is: if Python doesn't do it we shouldn't have to.
    The only exception is we are enforcing type hints.
  The bad news is: if Python does it and CSE 107 uses it, we should.
  And this includes multiple files via imports.

<dt> If module a imports module b, and module b imports module a, what?
<dd> Real Python behavior in this instance is laughable. Our approximation
  is: each module is installed into the global symbol table the first time
  it is imported. Importing it again would have no effect.  An "import" is
  equivalent to invoking the compiler on that module, in its own name space.
  The code that is outside of any function definition in a module goes in an
  implicit function (is it __main__?) that is executed when that file is to
  be first imported.  An ordered list of modules' mains is executed from a
  "global main". So if a imports b and b imports a:
<pre>
main() # global
   a.__main__()
   b.__main__()
</pre>
Note that the python3 interpreter on login.cs.nmt.edu seems to do this
with an extra twist: whomever is invoked from the command line, their
__main__() is executed without counting against the "run the first time
you are imported" rule. Wild.

<dt> Python's type hint syntax is really wild. What-all should we allow as
    types there?

<dd> Although Python's type hint syntax is way too loose and allows arbitrary
  expressions, for PunY syntactically we almost only need to support NAME as
  the only kind of
thing allowed as a type in a type hint. (Does this omit anything?) And although
  NAME denotes any identifier, semantically we only want to allow those NAMEs
  that are the names of types. Maybe this means look them up in the symbol
  table and pre-initialize the symbol table with the names of built-in types.
  It might mean the type representation needs a code for a TYPENAME.

<dt> What about variable # of arguments syntax, or applying a list to a
    function as its argument list?
<dd> PunY does not support user-defined variable # of arguments, but maybe
  print() is a built-in variable# of arguments function.  Maybe you should
  record its # of arguments as -1 to denote that it is a vararg function,
  and check for that before checking for a legal # of arguments in a call.

<!--
<dt> Do we need to support things like this:
    <pre>
int w=0, x, y=0, z=0, q=0;
    </pre>
    You used this in a test, but the spec says "only simple initializers
    including int, float and char".
<dd> Great question. These are simple initializers of integers. The real
  question is whether the spec says you have to support lists of variables
  in a single declaration. If not, the test is wrong. At this point in the
  spec, the spec does not say.  So now I will say: this is a Jzero Level Two
  test, and I will regrade level 1 folks with a test case where there are
  five separate variables declared on 5 separate lines. Not sure that helps
  much, but there it is.  What does a Jzero Level 1 person do  with a list
  of variables like this?  Claim it is a syntax error?  Probably not; instead
  they should write an error message that says the declaration is not in
  Jzero Level 1.

  <dt> Many ambiguities exist in the Jzero Spec. I feel like I am playing
    "Guess and Pray".
  <dd>Sorry. For each Jzero language question, we need to not only get me
    to give an answer, we need to get me to write that answer down in the
    Jzero spec, where we can all see it in perpetuity.
-->

    <dt> Can we setup a quick meeting?
    <dd> I am happy to meet by appointment, when I am not elsewhere obliged.
	This has been known to include evenings and weekends from time to time.
      Usually a specific request of day/time helps, and a bit of lead-time is
      needed, enough for me to see the message and tell you if I'm available
      then or not.

    <dt> for "case: FieldDeclaraction" the symtab.c file loops while "tree && tree->id == VarDeclarators_2" before calling variabledeclarator() but I can not find where VarDeclarators_2 is defined. What exactly is that check?

	<dd> The check is whether a given tree node is non-null, and if non-null, whether it happens to be a tree node corresponding to the second production
	  rule that constructs a VarDeclarators non-terminal.  Unfortunately,
	  the production rules for many examples in the code and lecture notes
	  do not correspond to your grammar, and you have to define your own
	  encoding of how in your tree can you tell which production rule
	  (or terminal symbol) each tree node was made from.

<!--
      <dt> In Java, you can have a method defined below where it is used. Does this
    mean we can skip checking that a method is defined?
<dd> Correct statement about Java, but no you can't skip checking if things
  are declared. C's semantics are lame partly because it was designed to be
  easy-ish to do the entire compiler in one pass through the input, i.e. for
  speed. Back when CPU speeds were measure in KHz instead of GHz, this
  mattered.  A lot.
  Commercial compilers gained market share back then based on how many
  lines per minute they could compile. For example Microsoft Pascal might take
  minutes to compile something that Borland Turbo Pascal could compile in
  seconds. Java was invented after speed was not a problem, and it is not a
  problem for you. So use separate passes for population and lookups on your
  symbol tables.
-->

<!--
  <dt> What up with the built-in classes and methods?
       Earlier the  spec had a bunch of library functions, now it is empty
  <dd>
<ul>
<li> I thought I had done up a set of built-ins near the start of the semester
    but unless it turns up, we must regenerate a bit.
<li>    The "Build Your Own Programming Language" book suggests a set of
    predefined symbols for j0...Chapter 6 for example shows how to insert
    "System" into the global symbol table, then insert "out" into System's
  symbol table, and "println" into out's symbol table.  We could look in
  the later chapters of the BYOPL book to see how many built-ins it gets
  around to, but it is probably too barebones.
<li> From your HW#1's the ones I liked were:
  <pre>
array .get() and .set() ?
System.out.print(s)
System.out.println(s)
String.charAt(n)
String.equals(s)
String.compareTo(s)  // ? do we need both this and equals()?
String.length()
String.toString(i) vs. String.valueOf()  ??
InputStream.read()   // ? is there a better input?
System.in.read() ?
  </pre>

At Jzero Level 2, add:

<pre>
String.substring(x,y)
java.util.Random.nextInt()
java.lang.Math.abs()
java.lang.Math.max()
java.lang.Math.min()
java.lang.Math.pow()
</pre>

At Jzero Level 3, add:

<pre>
String.indexOf()
String.split()
java.lang.Math.cos()
java.lang.Math.sin()
java.lang.Math.tan()
</pre>

</ul>

-->
</dl>


<h4> Constructing Type Representation for a Function (cont'd) </h4>

The function:
<p>
<pre>int f(int x, int y, float z);</pre>
<p>

The syntax tree:
<p>

<img src="fdecl.c.png" width=800>
<p>

  The type struct we are supposed to fill out from this tree:

  <table border>
<tr><th>C type<th> where in the tree?
    <tr><td>
<pre>
typedef struct typeinfo {
   int basetype;
   union { /* ... along with other union members */
      struct funcinfo {
	 char *name; /* ? */
	 struct sym_table *st;
	 struct typeinfo *returntype;
	 int nparams;
	 struct param *parameters;
	 }f;
   }u;
}</pre>
<td>
<pre>

FUNC_TYPE


n-&gt;kids[1]-&gt;kids[0]->leaf->text
new_st(...);
n-&gt;kids[0]-&gt;type
nparams_helper(n->kids[1]->kids[1])
params_builder(n->kids[1]->kids[1])



</pre>
</table>

<h3> Parameter "list" vs. "tuple" </h3>

<ul>
<li> How to represent the parameters in a function type?
<li> Whether parm <em>names</em> are part of the type is a good question...
<li> Existing type.h reference/sample uses a link list of a separate type,
  <code>struct param</code>
<li> Some of my other lecture notes, and famous compiler texts such as ASUL,
     would introduce a TUPLE basetype.
<li> Argument in favor of a linked list:
  <ul>
    <li> a bit simpler. easier to assemble.
      </ul>
<li> Arguments in favor of a tuple:
  <ul>
    <li> everything incrementally constructed along the way is still just a
         struct typeinfo
    <li> each function's parameters are fixed, lists are for dynamic structures
    <li> array representation easier to use afterwards
    <li> we will usually use many times after a single construction
  </ul>
</ul>

<h3> In-Class Exercise: helper Functions to construct param typeinfo</h3>

<h4> calc_nparams </h4>

Practice helper function, just count how many parameters there are

<pre>
int calc_nparams(struct tree *n)
{
   if (n->prodrule == PD) {
      return 1;
      }
   else if (n->prodrule == PL) {/* recursion/induction step */
      return 1 + calc_nparams(n->kids[0]);
      }
   return 0;
}
</pre>



<h3> Old Mailbag </h3>

<dl>
<!--
<dt> What is wrong with the following code? It compiles in Go but not VGo!
<pre>package main
func main(){
    for sum &lt; 1000 {
        sum += sum
    }
}
</pre>
</dt><dd>

Great catch. I think several folks had run into this -- I heard rumors --
but until someone gave me a concrete example it was easy to ignore as a
possible case of operator error. But here it is. Not too shockingly, it is
related to the LBRACE vs. '{' hack that was previously addressed.  Due to
the syntax of compound literals, the curly brace in this for loop was being
parsed as the start of a compound literal expression, instead of the
for-loop body. I performed the following changes to the official CSE 423
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/go.y">go.y</a> in
order to address the problem:
<ul>
<li> removed epsilon non-terminal <code>start_complit</code>
</li><li> replaced nonterminal <code>lbrace</code> with <code>'{'</code>
</li></ul>

These changes got this sample program to parse OK for me. We may
yet find some other Go code that won't parse in VGo, particularly related to
the '{' vs LBRACE hack.  We shall see.

</dd>
<dt> Is the following legal in VGo?  It is legal Go!
<pre>func hello(int) {}
</pre>
</dt><dd>
Interesting. <a href="https://stackoverflow.com/questions/40950877/is-unnamed-arguments-a-thing-in-go">Here</a> is a discussion of the feature in Go.
No, this is not legal in VGo. Per the VGo spec, parameters are "a
comma-separated list of zero or more variable names and types".
</dd>-->
<dt>
What is the difference between a function declaration and a variable
declaration, when it comes to adding the symbols to the table?  as far as
the tree is concerned they are almost exactly the same, with the exception
of which parent node you had.  Is there (or should there be) a line in the
symbol entry which states the entry as a function vs a variable?

</dt><dd>
You add the symbols to the same table. For HW#4 they are thus treated
basically identically. For HW#5 you put in different type information for
functions (whose basetype says they are a function, and whose typeinfo
includes their parameters and return type) than for simple variables.

</dd><dt>

I have code written which (hopefully) creates the symbol table entry for
variables.  This code uses a function which spins down through non-terminals
to get the identifier. Can I use this same function to get the identifier for
a function? A function is
<pre>direct_function_declarator: direct_declarator LP ... RP ...</pre>
so after the direct_declarator it has other useful things that I'm not sure
need to be in the symbol table entry.

</dt><dd>

You can sometimes re-use tree traversal functions that work through similar
subtrees, either as-is (if the subtrees really use the same parts of the
grammar) or by slightly generalizing or making generic the key decisions
about what to do based on production rule.  For example, you might add a
flag parameter to a function that spins through nonterminals, indicating
whether this was in a function declaration or not; that might allow you to
tweak the tree traversal to adjust for minor differences.  Or maybe you
just add cases to the switch statement to account for additional production
rules in the various similar kinds of subtrees.

</dd>

<!--
<dt>

You state "You do not have to support nested local scopes".  Does this mean
there will only be a global scope, or will there be a global + function
scopes, but no secondary scopes inside the local functions?

</dt><dd> Correct, function scopes for locals and parameters, but not nested
local scopes inside those.
</dd>-->
</dl>


<h4> mk_params </h4>

Helper function: construct type representation for parameters.
After agonizing a bit over the "linked list" versus "tuple" question...

<pre>
struct param * mk_nparams(struct tree *n)
{
   if (n->prodrule == PD) {      /* basis case */
      struct param *p = malloc(sizeof (struct param)); /* check for NULL */

      p->type = n->kids[0]->type; /* if we synthesized it already */
/*or*/
      if (n->kids[0]->prodrule == VOID)
         p->type = void_typeptr; /* ...and more like this, INT etc. */
      else
         p->type = synthesize_type_from_declspecs(n->kids[0]);

      if (n->kids[1]->prodrule == IDENTIFIER)
         p->name = n->kids[1]->leaf->text;
      else { /* non-simple declarator, pointer or something */
         p->name = get_name_from_declarator(n->kids[1]);
         /* type is modified by declarator; it's a pointer or something */
         p->type = inherit_type_into_declarator(p->type, n->kids[1]);
         }
 
      p->next = NULL;
      return p;
      }
   else if (n->prodrule == PL) { /* recursion/induction step */
      struct param *p1 = mk_nparams(n->kids[0]);
      struct param *p2 = mk_nparams(n->kids[1]);
      struct param *p3 = p1;
      while (p3->next != NULL) p3 = p3->next;
      p3->next = p2;
      return p1;
      }
   return NULL;
}
</pre>


<!--
<h3> Recursing through Trees Built from <a href="https://www.cs.nmt.edu/~jeffery/courses/423/go.y">go.y</a> </h3>

<ul>
<li> start at the beginning
</li><li> compile programs with <code>go tool compile foo.go</code>
     when testing Go fragments too small to link.
</li><li> In the trees, the node names ending
with _N denote production rule #N that builds that nonterminal.
If no _N is given it is presumed to be production rule #1 for
that non-terminal.
</li></ul>

<p>

<table border="">
<tbody><tr><th>code</th><th>tree</th><th>comments and/or symbol table
</th></tr><tr><td>
<pre>// empty file
</pre>
</td><td>n/a
</td><td> syntax error, missing package statement

</td></tr><tr><td>
<pre>package main
</pre>
</td><td>
<pre>    FILE
     |
  PACKAGE_2
   /      \
package   LNAME
          "main"
</pre>
</td><td>
verify package LNAME (must be "main") <br>
create empty symbol table <br>
(nothing to insert)

</td></tr><tr><td>
<pre>package main
var x int
</pre>
</td><td>
<pre>          FILE
        /      \
 PACKAGE_2     XDCLLIST_2
   /    \	|      \
package LNAME   &#949;     COMMON_DCL
        "main"          /     \
                      LVAR   VARDCL
                             /     \
                          LNAME   LNAME
                           "x"     "int"
</pre>
</td><td>
Construct a type from LNAME "int" because it is VARDCL kid #2.<br>
Insert "x" into current (global) symbol table because it is VARDCL kid #1.

</td></tr><tr><td>
<pre>package main
func main() { }
</pre>
</td><td>
<pre>          FILE
        /      \
 PACKAGE_2     XDCLLIST_2
   /    \	|      \
package LNAME   &#949;     XFNDCL
        "main"       /  |   \
                LFUNC FNDCL  FNBODY_2
                     /  |  \       \
                 LNAME ATL FNRES  STMTLIST
                "main"  |    |       |
                        &#949;    &#949;       &#949;
</pre>
</td><td>
Construct a FUNC type from FNDCL
<ul>
<li>   Construct an TUPLE of length 0 from empty ATL
</li><li>   Construct a VOID type from empty FNRES
</li></ul>
Insert "main" into global symbol table
<br>
Create a local symbol table <br>
Insert parameters into local symbol table <br>
Insert local variables into local symbol table
</td></tr></tbody></table>
-->

<h3> Recursing through Trees Built from some weird grammar that was not
  <A href="https://www.cs.nmt.edu/~jeffery/courses/423/cgram.y">cgram.y</a></h3>

<ul>
<li> start at the beginning
</li><li> compile programs with <code>gcc -c foo.c</code>
     when testing fragments too small to link.
</li><li> In the trees, the node names ending
with _N denote production rule #N that builds that nonterminal.
If no _N is given it is presumed to be production rule #1 for
that non-terminal.
</li></ul>

<p>

<table border="">
<tbody><tr><th>code</th><th>tree</th><th>comments and/or symbol table
</th></tr><tr><td>
<pre>// empty file
</pre>
</td><td>n/a
</td><td> is empty file a syntax error? or fine?

In any case, create empty symbol table <br>
(nothing to insert)

</td></tr><tr><td>
<pre>
int x;
</pre>
</td><td>
<pre>          FILE
               \
               XDCLLIST_2
         	|      \
                &#949;     COMMON_DCL
                        /     \
                      LVAR   VARDCL
                             /     \
                           INT    IDENT
                          "int"    "x"
</pre>
</td><td>
Construct a type from INT "int" because it is known type basis case.<br>
Synthesize it up to VARDCL. Inherit it down into declarator list (including x)
Insert "x" into current (global) symbol table because it is VARDCL kid #2.

</td></tr><tr><td>
<pre>int main() { }
</pre>
</td><td>
<pre>          FILE
               \
               XDCLLIST_2
         	|      \
                &#949;     XFNDCL
                     /  |   \
                FNRES FNDCL  FNBODY_2
               /     /  |  \       \
            INT  IDENT ATL        STMTLIST
          "int" "main"  |    |       |
                        &#949;    &#949;       &#949;
</pre>
</td><td>
Construct a FUNC type from FNDCL
<ul>
<li>   Construct an TUPLE of length 0 from empty ATL
</li><li>   Construct a INT type from FNRES
</li></ul>
Insert "main" into global symbol table
<br>
Create a local symbol table <br>
Insert parameters into local symbol table <br>
Insert local variables into local symbol table
</td></tr></tbody></table>



<h3> Mailbag </h3>

<dl>
<dt> My code segfaults!  Help!
<dd> I used to debug my segfaults with gdb.  Then I found that valgrind was
    more effective, including cases gdb missed, and saves me a lot of time.
    Of course, the real secret is building a mental model (literally, pictures
    in your head) of the memory, and getting to the point where that mental
    model somewhat corresponds to reality.
<dt>
In some example code on the class site,
you have the type checking done at the same time as the symbol table entry.
Is there any reason not to break these out into 2 separate functions?
</dt><dd> No, no reason at all. In the old days there were reasons.

</dd><dt> Is it normal to feel like my code for adding to and checking the
symbol tables is messy, gross, and more hard-coded than I'd like?
</dt><dd>The Flex and Bison homeworks had an unfair advantage: they were using
    a declarative language. Later homeworks will be
    messy and gross by comparison, because from here on out we are using
    the imperative (and OO, which is "imperative with style") paradigm.
    Walking trees and getting the details all in
    there will require a lot of code. How gross it is, "Zis is all up to you"
    (from a Geronimo Stilton book).

</dd><dt> Does our language really require comma-separated lists of variables in
     declarations?  It would be <em>so</em> much easier if it only did one
     variable per declaration.
</dt><dd> Don't exaggerate.  It would not be that much easier.
This is now a j0 Level Two thing and Level One folks are off the hook,
<!--
We want to be able to handle declarations like
<pre>
int x, y
</pre>
So maybe we should talk about how hard is that.
<ul>
<li> Find a variable declaration (whatever you call it). Let's call its
     lefthand (the type) a "declaration specifier" and its
     righthand subtree a "declarator list"
<li> An declarator_list that consisted of just an IDENTIFIER leaf might
     be easier, I admit, but...
<li> a declarator_list that is
     just a linked list of identifiers isn't that much harder.
<li> Write a helper function that does nothing but walk through
     a chain of declarator_list nodes.
<li> When HW#4 comes along, pass type information obtained from synthesizing
     the declaration_specifier into the traversal of the declarator list.
     Options include:
     <ol><li> pass it as a parameter into the helper function, or
     <li> add it as (another) field in the tree structure, and copy
     it downwards
     in the tree from the declartion into the declarator list nodes.</ol>
</ul>
-->
But (even for Level Two/Three folks) it is FINE to start by just getting
it working for one-variable
declarations, then detect and handle two-variable declarations
as a special case, then generalize to 3+ variables.  You might pass
some test cases with only one-variable declarations working.

<!--
<dt> I am not sure what to do with
    <code>endl</code>, <code>cout</code>, and <code>cin</code>.
     I've checked that
    <code>namespace std</code> appears and that <code>iostream</code>
    is included, but I'm not sure what
    type to give them.  Should I mark them as methods... or perhaps class
    names?
<dd> There are different answers for: "what these really are in C++" and for
     "what our subset 120++ would find adequate".
     As you may recall, you are always allowed to do things more C++-ish
     than the toy behavior I will recommend.
<dt> OK so what about <code>endl</code>?
<dd> Really: <code>endl</code> is an "IO manipulator" that
     inserts a newline and flushes the stream.
     What 120++ could live with: insert into your global symbol table the
      equivalent of having seen:
<pre>
const char endl = '\n';
</pre>
<dt> And what about <code>cin</code> and <code>cout</code>?
<dd> Really: these are are predefined global symbols of type
     <code>ostream</code> and
     <code>istream</code>. What 120++ could live with: CS 120 does not
    distinguish <code>ostream</code> from <code>ofstream</code>, or
    <code>istream</code> from <code>ifstream</code>.
    Insert into your global symbol table the equivalent of:
<pre>
ofstream cout;
ifstream cin;
</pre>
<dt> Doesn't that beg the question of what to insert for these predefined
     classes?
<dd> Yes, and its worse than that.
     120++ does not go into operator overloading, but
     we need <code>&lt;&lt;</code> and <code>&gt;&gt;</code>
     to be predefined to work on them. Table A.5
     in Soule's appendix, also found in our 120++ reference manual, mentions
     a few methods defined on streams.

<dt> What about the class named <code>string</code>?
<dd> I would guess we need to predefine the class string, like we do
ofstream and ifstream.  I don't think defining it as char * will work,
unless 120++ never actually uses methods of class string, and only
passes them as parameters.
-->

<!--
<dt> Can you please clarify what to do with prototypes and what to do
    with Function Definitions?
<dd> You are not required to handle prototypes in g0. If you do,
     prototypes insert something into a global symbol table, enough to
     typecheck calls to the prototyped function.  They do not need
     a local symbol table, and would normally ignore names of parameters.
     They might have a boolean flag or other means of remembering
     in the global symbol table that they are just a prototype, so that
     they would not trigger a redeclaration error when the definition of that
     function finally shows up.  In fact, a prototype can appear multiple
     times with no redeclaration error.
     You would think that when the function definition occurs on a
     function that has an existing prototype, it should trigger a
     typecheck on the number and type of existing parameters.  In
     C++ there is function overloading, so the story is not so simple.
-->
</dd></dl>


<h3> Connecting Trees to Traversals </h3>

<ul>
<li> we've been looking at example code for building type
     information needed for declarations.
<li> for certain "interesting" tree nodes, we need to know not
     only what name goes in the symbol table, but what type
<li> examples given have been for some variant of the C language
     and its non-terminals
<li> for your homework you have to find corresponding nodes in your trees.
<li> if we look at  <a href="https://www.cs.nmt.edu/~jeffery/courses/423/j0gram.y">j0gram.y</a>, we find its functions (methods) described in rules such as
<pre>MethodReturnVal : Type | VOID ;
MethodDecl: MethodHeader Block ;
MethodHeader: PUBLIC STATIC MethodReturnVal MethodDeclarator ;
MethodDeclarator: IDENTIFIER '(' FormalParmListOpt ')' ;
</pre>

<li> We can compare what we need to a corresponding example from the
  Go language <a href="https://www.cs.nmt.edu/~jeffery/courses/423/go.y">go.y</a>, which has
     functions described in rules such as
<pre>xfndcl : LFUNC fndcl fnbody ;
fndcl : sym '(' oarg_type_list_ocomma ')' fnres ;
</pre>
</li></ul>

<pre>/*
 * Semantic analysis from syntax tree, Go (subset) Edition
 */
void semantic_anal(struct symtab *current_st, nodeptr n)
{
   if (n==NULL) return;
   for(int i = 0; i &lt; n-&gt;nkids; i++) semantic_anal(current_st, n-&gt;child[i]);
   switch (n-&gt;prodrule) {
   case XFNDCL : /* whole function */
      n-&gt;symtab = n-&gt;child[1]-&gt;symtab;
      populate_locals(n-&gt;symtab, n-&gt;child[2]);
      /*
       * visit body to check for undeclared/redeclared
       */
      check_variable_uses(n-&gt;child[2]);
      break;
   case FNDCL :  /* function header */
      char *name = get_func_name(n-&gt;child[0]);
      n-&gt;symtab = mk_symtab();

      n-&gt;type = get_type(FUNC);
      n-&gt;type-&gt;u.f.returntype = n-&gt;child[4]-&gt;type;
      n-&gt;type-&gt;u.f.params = n-&gt;child[2]-&gt;type;
      n-&gt;type-&gt;u.f.symtab = n-&gt;symtab;
      st_insert(current_st, name, n-&gt;type);

      populate_params(n-&gt;symtab, n-&gt;child[2]);
      break;
   }
}
</pre>


<h3>Discussion of Tree Traversals that perform Semantic Tests</h3>

This example illustrates just one of the
myriad-of-specialty-traversal-functions that might be used.
This mindset is one way
to implement semantic analysis. <p>

Suppose we have a grammar rule
</p><pre>AssignStmt : Var EQU Expr
</pre>

We want to detect if a variable has not been initialized, before it is
used.  We can add a boolean field to the symbol table entry, and set it
if we see, during a tree traversal, an initialization of that variable.
What are the limitations or flaws in this approach?

<p>
We can write traversals of the whole tree after all parsing
is completed, but for some semantic rules, another option is to
extend the C semantic action for that rule with
extra code after building our parse tree node:
</p><pre>AssignExpr : LorExpr '=' AssignExpr { $$ = alctree(..., $1, $2, $3);
	lvalue($1);
	rvalue($3);
	}
</pre>

<ul>
<li> In this example, <code>lvalue()</code> and <code>rvalue()</code>
are mini-tree traversals for the lefthand side
and righthand side of an assignment statement.
</li><li> Their missions are to
propagate information from the parent, namely, inherited attributes
that tell nodes whether their values are being assigned to (initialized)
or being read from.
</li><li> Warning: since this is happening during parsing,
it would only work if all semantic information that it depends on,
for example symbol tables, was also done during parsing.

</li><li> Side note: I might be equally or more interested in implementing a
semantic check to make sure the left-hand-side of an assignment is actually
an assignable variable. How would I check for that?
</li></ul>

<pre>void lvalue(struct tree *t)
{
   if (t-&gt;label == IDENT) {
      struct symtabentry *ste = lookup(t-&gt;u.token.name);
      ste-&gt;lvalue = 1;
   }
   for (i=0; i&lt;t-&gt;nkids; i++) {
      lvalue(t-&gt;child[i]);
      }
}
void rvalue(struct tree *t)
{
   if (t-&gt;label == IDENT) {
      struct symtabentry *ste = lookup(t-&gt;u.token.name);
      if (ste-&gt;lvalue == 0) warn("possible use before assignment");
   }
   for (i=0; i&lt;t-&gt;nkids; i++) {
      rvalue(t-&gt;child[i]);
      }
}
</pre>


</p>


<h4> Real Life vs. toy lvalue/rvalue example</h4>

This example illustrated walking through subtrees looking for specific
nodes where some information was inserted into the tree.  In real life...
<ul>
<li> information passed down (i.e. inherited attributes) may be passed
     as a (second or subsequent)
     parameter after the tree node the traversal is visiting.
</li><li> this example might apply mainly to local variables whose definition
     and use are in this same (function definition) subtree
</li><li> if you wanted to ensure a class or global variable was initialized before
     use, you might build a flow graph (often used in an optimization or
     final code generation phase anyhow)
</li><li> variable definition and use attributes are more reliably analyzed
     using a flow graph instead of the syntax tree.
</li></ul>

For example, if the program starts by calling
a subroutine at the bottom of code which initializes all the
variables, the flow graph will not be fooled into generating warnings
like you would if you just started at the top of the code and checked
whether for each variable, assignments appear earlier in the source
code than the uses of that variable.

<h3> <code>(x, y, z int)</code> vs. <code>var a, b, c int</code> </h3>

<table border="">
<tbody><tr><th>
In a parameter list
</th><th>
In a variable declaration
</th></tr><tr><td>
<pre>         ATL
       /  |  \
    ATL   ,    ARGTYPE
   / | \        |     \
ATL  , ARGTYPE  LNAME  LNAME
 |       |	 "z"   "int"
ARGTYPE LNAME
 |       "y"
LNAME
 "x"
</pre>
</td><td>
<pre>     COMMONDCL
    /       \
  LVAR    VARDCL
          /    \
       DNL     NTYPE
       /|\       \
    DNL , LNAME  LNAME
    /|\    "c"   "int"
 DNL , LNAME
  |     "b"
LNAME
 "a"
</pre>
</td></tr></tbody></table>

OK, how do we get type information down to the tree nodes where "x"?
Specialized subtraversals and/or multiple passes.  This sample is
probably a duplicate of some earlier sample code, just tied to the
non-terminal names of the go.y grammar a bit.

<pre>void populate(struct tree *n, struct symtab *st)
{   int i;
    if (n==NULL) return;
    for(i=0; i&lt;n-&gt;nkids; i++)
       populate(n-&gt;kids[i], st);
    switch (n-&gt;prodrule) {
    case VARDCL:
       n-&gt;type = n-&gt;kid[1].type;         // synthesiz
       n-&gt;kid[0].type = n-&gt;type;         // inherit
       insert_w_typeinfo(n-&gt;kid[0], st);
       break;
    case NTYPE:
       n-&gt;type = n-&gt;kid[0].type;
       break;
    case LNAME:
       if (!strcmp(n-&gt;token-&gt;text, "int"))
          n-&gt;type = T_INTEGER;
       break;
    case ARG_TYPE_LIST_1: /* ATL: arg_type */
       break;
    case ARG_TYPE_LIST_2: /* ATL: ATL ',' arg_type */
       break;
    case ARG_TYPE_1: /* AT: name_or_type */
       break
    case ARG_TYPE_2: /* AT: sym name_or_type */
       break
    case ARG_TYPE_3: /* AT: sym dotdotdot */
       break
    case ARG_TYPE_4: /* AT: dotdotdot */
       break
    }
}

/*
 * "inherited attribute" for type could go down by copying from
 * parent node to child nodes, or by passing a parameter. Which is better?
 */
void insert_w_typeinfo(struct tree *n, struct symtab *st)
{ int i;
  if (n == NULL) return;
  for(i=0; i&lt;n-&gt;nkids; i++) {
     if (n-&gt;kids[i]) {
        n-&gt;kids[i]-&gt;type = n-&gt;type;
        insert_w_typeinfo(n-&gt;kids[i], st);
	}
     }
  switch (n-&gt;prodrule) {
  case DNL: /* ?? nothing needed */
    break;
  case LNAME:
    st_insert(st, n-&gt;token-&gt;text, n-&gt;type);
    break;
  }
}
</pre>

<p>
<font size="1"> <a name="26">lecture #26</a> began here</font>
</p><p>

<A name="typechecking">
<h3> Type Checking </h3>
</A>

<ul>
<li> The primary component of semantic analysis in traditional
  compilers is the type checker.
<li> Starts with a representation of the types (a type system, such as
  our struct typeinfo *)
<li> Implement comparison and composition operators on those types using the
  semantic rules of the source language being compiled.
<li> add (mostly-) synthesized attributes through those parts of
     the language grammar (and treenodes) that involve expressions and values.
<li> Compute nodes' .type's via a tree traversal
</ul>

<h4> Type Systems </h4>

Type systems are a "CS theory" topic, semi-redundant
to what we talked about when we introduced struct typeinfo. The
point then and now is that you need to add whatever is needed to represent
the types that occur in the language for which you are writing a compiler.
A type system might start with rules like:

<ul>
<li> Base types (int, bool, etc.) are types
</li><li> Named types (via typedef, etc.) are types
</li><li> Types composed using other types are types, for example:
    <ul>
      <li> array(T, indices) is a type.
	<ul> <li> In some
         languages indices always start with 0, so array(T, size) works.
         <li> Some languages have lists intead of arrays.
         </ul>
    </li><li> T1 x T2 is a type (specifying, more or
         less, the tuple or sequence T1 followed by T2;
	 x is a so-called cross-product operator).
	<ul><li>Python has an actual tuple type, can PunY avoid it?
	  <li> Tuple types used for parameter lists
	  </ul>
    </li><li> record((f1 x T1) x (f2 x T2) x ... x (fn x Tn)) is a type
	<ul>
	  <li>Like a tuple type except with names/fields/labels for each value
	  </ul>
    </li><li> in languages with pointers: pointer(T) is a type
    </li><li> (T<sub>1</sub> x ... T<sub>n</sub>) -&gt; T<sub>n+1</sub> is a
         type denoting a function mapping parameter types to a return type
    </li></ul>
<li> In a language with classes, what would a class type be?
<li> In a language with dictionaries/tables, what would that type be?
<li> In some language type expressions may contain variables whose values
     are types.
</li></ul>

In addition, a type system includes rules for assigning these types
to the various parts of the program; usually this will be performed
using attributes assigned to grammar symbols.






<h3> Example Semantic Rules for Type Checking </h3>

<ul>
<li> We have previous seen: representation of types using C structs.
</li><li> We could maybe use an additional example of constructing such type
     structures from a syntax tree, but we saw a basic one, for parameters.
</li><li> Now it is time to consider: using such type structures to perform
     type checking.
</li><li> Type Checking is a primary example
     of using synthesized semantic attributes.
</li><li> Q before we start: what-all has to be checked?
</li></ul>

<table border="">
<tbody><tr>
<th> grammar rule </th><th> semantic rule
</th></tr><tr>
<td>E<sub>1</sub> : E<sub>2</sub> PLUS E<sub>3</sub>
</td><td>E<sub>1</sub>.type = check_types(PLUS, E<sub>2</sub>.type, E<sub>3</sub>.type)
</td></tr><tr>
</tr></tbody></table>

Where check_types() returns a (struct type *) value.  One of the values
it can return is TypeError.  The operator (PLUS, probably the binary addition
operator) is passed in to
the check types function because typecheck rules depend on the operator --
the result type for array subscripting works different than the result
type for the arithmetic operators, which may work different (in some
languages) than the result type for logical operators that return booleans.

<h3> In-class brainstorming </h3>

Consider the class project. What else will we need to check during semantic
analysis, and specifically during type checking?


<dl>
<dt> <A name="typerules">What should the type rules for PunY's PLUS be?</A>
  <dd>
    In the table below, blank entries are compile time errors. Parenthesized
    entries are possible runtime errors. At compile time, (int|float) could
    be interpreted as Any, or you could add a Numeric type to the type
    representation and to this table.
    <p>
<table border>
<tr><th>row PLUS col<td>int<td>float<td>str<td>bool<td>list<td>dict<td>func<td>Any
<tr><td> int    <td>int <td>float<td>    <td>int<td>    <td>    <td>    <td>(int|float)
<tr><td>float<td>float<td>float <td>    <td>float<td>    <td>    <td>    <td>(float)
<tr><td> str <td>    <td>    <td>str   <td>    <td>    <td>    <td>    <td>(str)
<tr><td> bool <td>int<td>float<td>    <td>bool <td>    <td>    <td>    <td>(bool)
<tr><td> list <td>    <td>    <td>    <td>    <td> list <td>    <td>    <td>(list)
<tr><td> dict <td>    <td>    <td>    <td>    <td>    <td>    <td>    <td>    
<tr><td> func <td>    <td>    <td>    <td>    <td>    <td>    <td>     <td>    
<tr><td> Any <td>(int|float)<td>(float)<td>(str)<td>(bool)<td>(list)<td>    <td>     <td> (Any)

</table>
      <p>


Codewise, all this might look like:
    <pre>
struct typeinfo *check_types(int operator,
                             struct typeinfo *e1,
                             struct typeinfo *e2) {
   switch(operator) {
      case PLUS: {
         /* implement <b>row PLUS col</b> table here */
         break;
         }
   }
}
</pre>
<dt> What other type-check rules for PunY can we derive?
<dd> <ul><li> Add switch cases for each operator
<li> Add checks for function calls (parameters, return types)
<li> ???
</ul>
</dl>
<p>





Let's look at a few lines of a
  <A href="typecheck-example.py.html">typecheck example</A>.

  <p>

In the break between lecture and lab, a student reported that I have
previously stated that redeclarations at the same level are OK so long
as they are the same type.  I believe I said that. Now: should that be
true for PunY???

  <p>

    
<h3> Type Checking Example </h3>

Work through a type checking example for the function call to
<code>foo()</code> shown in <b>bold</b> in the example below.
This is a C language
example. The Go would be pretty similar; how much would be
different?

<p>

<table border="" <tr=""><tbody><tr><th> C </th><th> Go
</th></tr><tr><td>
<pre>int foo(int x, char *y) {
   return x
   }

int main()
{
   int z;
   <b>z = foo(5, "funf");</b>
   return 0;
}
</pre>
</td><td>
<pre>func foo(x int, y string) int {
   return x
   }

func main() int {
   var z int
   <b>z = foo(5, "funf")</b>
   return 0
}
</pre>
</td></tr></tbody></table>

</p><p>

After parsing, the symbol table (left) and syntax tree for the call (right)
looks like:

</p><p>

<img src="typechk_args.png">
</p><p>

The typecheck of this tree proceeds as a post-fix traversal of the tree.
Type information starts from leaves, which either know their type if they
have one (constants) or look up their type in the symbol table
(identifiers).  Can you hand-simulate this in the correct order, filling in
.type fields for each tree node?


<p>
<font size="1"> <a name="27">lecture #27</a> began here</font>
</p>

<h3> <A href="#typerules">Type Rules</A> Progress </h3>

<h3>Mailbag</h3>

<dl>

<dt> I was wondering if names that are declared as function should be
treated similarly to names that have been type hinted. Essentially, if I
define a function with the name "stuff", can I, in the same scope, make the
statement "stuff = 5", or is that illegal? What about the inverse, trying to
declare a function with the same name as an existing variable?

<dd> 
Well, what does Python do? Following that: what should PunY do? Consider

<pre>
def stuff():
   stuff = 5
</pre>

I think the function <code>stuff()</code> should get inserted into the
module (file) scope, while
stuff = 5 introduces a new variable <code>stuff</code> within that local scope.

<p>

Python then allows you to say <code>stuff=5</code> <em>outside</em>
at the global level and
replace the function definition of <code>stuff</code> with an arbitrary
type, but I kind of agree with you that
maybe PunY wants to treat a def as a type hint, unless there is some other
type hint syntax that would specify that only functions are allowed for a given
symbol.  I tried

<pre>
stuff : function
stuff : func
</pre>

and those do not work. Maybe there is some other function type hint syntax,
but unless we find one, I say: once it is a <code>def</code> (i.e. a function)
it can be re<code>def</code>ed as
another <code>def</code> but cannot be turned into a different type in the same
scope.

<!--
<dt> I am working on ++ and --. They seem to be UnaryExpr's, which sit
  on top of PostFixExpr. But PostFixExpr is made from either Name or
  Primary. Name I get, but
  Primary is very difficult to understand, it can be a Literal, an Expr in parentheses, a FieldAccess, or a MethodCall. I'm not sure what the intended purpose is behind Primary being allowed as PostFixExpr, or what Primary's greater purpose is in the grammar as a whole.

<dd> ++ and -- are a little different from unary + and - not just that they
    can be suffixes instead of prefixes, but also because their operand
    must be a variable that can be modified.  That said, one
    reason to allow Primary in PostFixExpr is that the Jzero language
supports more than x++, it should also allow expressions such as (x)++,
o.x++, or a[i]++ as well. On the other hand, 12++ should be a semantic
error, and f()++ would be illegal except in languages where functions can
return references to variables.

-->
</dl>

<h3>Type Promotion, Type Equivalence, and Automatic Conversion</h3>

<dl>
<dt>  When is it legal to perform an assignment x = y?

<dd><ul>
<li>In most languages that will be legal when x and y are identical types...
<li> Many languages such as C have automatic <em>promotion rules</em> for
     combining related scalar types such as shorts and longs.
<li> Results of type checking may include not just a type attribute,
     they may entail a type <em>conversion</em> of operands, which can be
     represented by
     inserting a new node in the tree to denote the promoted value.
<li> A simple conversion might be a promotion of a smaller # of bits to
     a larger # of bits, such as short to long, or float to double.
     Maybe a machine instruction does that.
<li> Some languages feature more complex conversions such as converting
     a string "3.14" to a double. Often that will be implemented via a
     runtime system function call rather than a machine instruction.
</ul>
</dl>
<p>
Type Promotion / C Example:

<table border>
<tr><th>Implicit  <th> Explicit
<tr><td>
<pre>int x;
long y;
y = y + x;
</pre>
<td>
<pre>int x;
long y;
y = y + (long)x;
</pre>
</table>
<p>

Type Conversion / int to float
  <p>
In some languages, it is not about different sizes of integers.
<!--  Sure c113c might be able to duck the promote-shorter-integers stuff,
      but-->
What about floats/doubles vs. ints? What happens?  Could PunY users
  ever write code like this?
<!--
<pre>int x;
double y;
y = y + x;
</pre>
-->
<table border>
<tr><th>Implicit  <th> Explicit
<tr><td>
<pre>x : int
y : float
y = y + x
</pre>
<td>
<pre>x : int
y : float
y = y + float(x)
</pre>
</table>
<p>

This may come about in real life in parameters and return values, such
as an int parameter passed into a function that requires a float.

<pre>int x, y;
    ...
y = sqrt(y*y + x*x);
</pre>

<p>

<h4> Name equivalence vs. structure equivalence</h4>

For classes/records/structures, some languages use name equivalence,
  while others use structure equivalence.
<dl>
<dt> Features like typedef complicate matters. <dd> If you have a new
     type name MY_INT that is defined to be
an int, is it compatible to pass as a parameter to a function that
expects regular int's? In C, the answer is: yes.
<dt> Object-oriented languages also get interesting.
Do OOP languages use name equivalence or structure equivalence?
<dd> Name+inheritance. Subclasses usually are allowed anyplace
their superclass would be allowed.
</dl>
</p>

</p>

<h3> Implementing Structs </h3>

Some years, CSE 423 implements classes, not structs. But some languages such
as C or Go have structs. And structs seem to be a preliminary step towards
classes. How much of the following "structs" discussion is similar to what
classes would need, and how much needs to be different?

<ol>
<li> In C/C++, storing and retrieving structs by their label -- 
    the struct label is how structs are identified.
     In Go/VGo, the reserved word <code>type</code> is more like
     a C/C++ <code>typedef</code>.
    If you were doing C/C++-style struct labels,
    the labels can be keys in a separate hash table, similar to the global
    symbol table.  You can put them in the global symbol table so long as
    you can tell the difference between them and regular symbol names, for
    example by storing them as "struct foo" (not a legal name) instead of
    just storing them as "foo".

</li><li> You have to store fieldnames and their types, from where the struct is
    declared. This is conceptually a new local scope. In a production language
    you would use a hash table for each struct, but in CSE 423 a link list
    would be OK as an alternative. Then again, if you've built a hash table
    data type for the global and local symbol tables, why not just use it
    for struct field scopes?

</li><li> You have to use the struct's type information to check the validity of
    each dot operator like in <code>rec.foo</code>.  To do this you'll have
    to lookup <code>rec</code>
    in the symbol table, where you store rec's type.  rec's type must be
    a struct type for the dot to be legal, and that struct type should
    include the hash table or link list that gives the names and types of
    the fields -- where you can lookup the name <code>foo</code> to find
    its type.
</li></ol>


<!--
<h3> Brief Aside:<br>
     Are Compilers (and Programming Languages) Dead? </h3>

<ul>

<li> Recently an NMT grad student politely suggested to me
  that the field of programming languages research was dead
  (by which he meant all the important results were already discovered,
  I suppose), and all hip young researchers these days study data mining or
  cybersecurity.
<li> This makes me laugh, but it also gives me pause.
<li> CS has always been a field of Fads.  Data mining is a fine fad.
     If you want to study that, I think it is awesome.
<li> There will always be research on how to make higher and higher
     level languages run faster and faster on new types of hardware.
<li> It is true that compilers and programming languages was easier
     to work on (and get publication) in the 1970's and 80's.  Since
     then, though, a lot of
     important languages and compiler advances have occurred.
<li> these days it is not just "compiler research" it is
  "programming language support for ...(X <em>insert your domain here</em>)".
<li> A past research question: how do I reduce the cost of building/prototyping
     MMOs by, say, two orders of magnitude? (Partial answer: build very
     high level graphics and networking into my language.) <br>
<img src="../../vslc/npcs.jpg" width=600>
<li> You may notice the old Everquest-style 3D subwindow inside a 2D GUI.
     An ongoing research project is to rebuild my language's
     graphics facilities entirely in OpenGL, so that the GUI can
     transparently overlapy the 3D scene, game-style.
<li> Current research project: build a "compiler" that
     accepts All the major CS1 languages (C, C++, Java, Python)
     and generates code that will run CS1 programs under my Alamo program
     execution monitoring framework. I would welcome help with this.
<li> Next research project: generate visualizations ("cities") of CS1 programs
     and visualize their execution behavior as anthropomorphic animated
     entities within those cities, TRON-style. <br>
<img src="../../vslc/ucity_aged.jpg" width=600>

<li> So yeah, I work on open source languages and their compilers because I love
     the field.  And yeah, I don't think the field is dead.
</ul>
<p>

<h3> We Now Return You to Your Regular Programming </h3>
-->


<h3>"Old Mailbag"</h3>

<dl>
<dt> I am having a problem with a segmentation fault.  Can you help?
</dt><dd> When sticking print statements into your program no longer cuts it,
     your two best hopes are GDB and Valgrind.  Yes, I can usually help.
<ul>
<li> the first thing I will want to see is your valgrind run on your segfault
</li><li> the second thing I am going to want to see is your open gdb session
     at the point of the segfault, with the "where" output, and the "print"
     command run on each variable on the line where the segfault occurred
</li></ul>

</dd><dt>
The problem is, there is just so much to type check (I mean, literally
everything has a type!); can you suggest any ways to go about this in a
quicker manner, or anything that could be pruned/ignored?
</dt><dd>
<ul>
  <li> Not literally everything.
    <ul>
      <li> Only the expression grammar nodes have a type.
      <li> Plus the subset of declarations that you must support. They have types.
      <li> "expression grammar" in mainstream algol-like languages are the
	non-terminals in the grammar underneath Expr (or similar). In
	Python/Java grammars that includes expr_stmt or StmtExpr.
	The non-terminals above that, starting with
	Statement/Stmt typically don't compute values or have types.
	<li> In some so-called expression-based languages, it is more like:
	  everything is an expression. So be it. Not our problem.
    </ul>
</li><li>
     The type checking will typically not do anything on $$=$1 rules, so
     the expression grammar may have somewhere around 20 productions where
     type checking goes -- pretty much operators and calls.
</li><li> Feel free to rewrite the grammar to reduce the number of productions
     where you do type checking.
</li><li> Type checking rules for like-minded operators are identical; use that.
</li><li> Write helper functions, share common logic.
</li></ul>


</dd>
<!--
<dt> Hey, look how easy it is to modify our tree-print function to instead
generate a .dot file which the <code>dot(1)</code> program on cs-course42
can turn into a tree that looks like this:
<p>

<img src="am-tree.png">
</p><p>

[Student shows <a href="https://www.cs.nmt.edu/~jeffery/courses/423/graph.c">~110 lines of C code</a> that writes
two .dot files with different levels of detail via a traversal function
similar to your HW#2 tree printer.]

</p></dt><dd> That is pretty darned awesome, thank you. Folks are encouraged to check
out <a href="https://linux.die.net/man/1/dot"><code>dot(1)</code></a>.
This kind of tree could be extended with type info that might be really
useful for debugging HW#4!
</dd>
-->
</dl>



<h3> Need More Help with Type Checking? </h3>

<ul>
  <li> Read the textbooks, lecture notes, etc.
  <li> Implement the C Type Representation given previously,
       or something similar/equivalent
  <li> Figure out how to construct types for your basis cases (constants)
  <li> Figure out how to construct types while walking variable declaration
       subtrees (extension of how to find them for the symbol table)
  <li> Figure out how to construct types while walking function prototypes
       and function declaration subtrees
  <li> Implement a check_type() function to compute type for internal
     node. What OPERATIONS (functions) do you need, in order to check
     whether types are correct?  What parameters will they take?
</ul>

<h3> struct typeinfo with struct params </h3>

<ul>
<li> Last class we did a function call example where we were building
     a synthesized .type struct typeinfo attribute in each tree node.
<li> the interesting bits often occur at the sequence of struct params
  that we need to build in order to check formal params vs. actual params
<li> Option #1: build it in a different synthesized attribute, .params
<li> Option #2: implement a TUPLE type for stringing together multiple types
<li> Option #3: (if you really like linked lists)
     allow a parameter list as one of the things a struct typeinfo
     can hold (alternate representation of a tuple)
<pre>
struct type info {
  int basetype; // basetype PARAMLIST uses union member parms
  union {
    struct param *params; // linked list of parameters
   ...
  } u;
  };
</pre>
<li> Warning/gotcha: what is the difference between a single parameter with
     its native basetype, and a parameter list of length 1 that contains
  that type?  When do you convert from type to paramlist type?
<li> Warning/gotcha: struct param has names and types.  But some languages
 have prototypes that
  only have the types?  If you had to support that, how would we
  represent them?

</ul>  

<p>
  Note that if you stick parameter lists in the type representation, this means your
  struct typeinfo holds some things that are not C types in and of themselves, but are
  used in larger composite types.  I guess a TUPLE was a similar pseudo-type option.

<!--
<h3> g0 Language: what-all is under-specified? </h3>

We've had various reasonable requests for clarification, and corrections
needed for examples which were translated incompletely from C++. Are there
any for which you haven't got a straight answer yet?

<dl>
<dt> no need for prototypes
<dd> prototypes are a concession to single-pass
     compilers run on slow low-memory computers in the 1970's and 80's.
     Your g0 compiler is allowed to use a "big-inhale" model of compilation
     in which all source code is available and symbol tables can be fully
     populated before type checking.
<dt> switch to JSON syntax for list constructors
<dd> Yeah, I admit I like square bracket list constructors.
</dl>
-->

<p>
<font size="1"> <a name="28">lecture #28</a> began here</font>
</p><p>

<h3> Type Checking Function Calls </h3>

<ul>
<li> at every node in our tree, we build a .type field
</li><li> Probably logically two separate jobs:
<ul>
<li> Build types for declarations, insert them into symbol table(s).
      Performed during the declarations pass of semantic analysis.
</li><li> Build types for expressions, lookup symbols from symbol table(s)
      Performed during the typecheck pass of semantic analysis.
</li></ul>

</li><li> For the typecheck pass, a recursive function, typecheck(n), traverses the
     tree sticking types into expression nodes.
</li><li> you may choose to write a helper function check_types(OPERATOR,
operandtype, operandtype) to do the heavy lifting at each node
</li><li> What will type checking a function call need?
</li><li> Can we just check the type of the symbol against the type of the call
expression?
</li><li> Type of symbol: constructed as per last lecture. In symbol table.
</li><li> Type of call expression (built within expression part of grammar), SANS
     return type.
</li><li> Type check verifies it and replaces it with return type.
</li></ul>

<pre>void typecheck(nodeptr n)
{
   if (n==NULL) return;
   for(int i; i &lt; n-&gt;nkids; i++) typecheck(n-&gt;child[i]);
   switch(n-&gt;prodrule) {
   ...
   case POSTFIX_EXPRESSION_3: {
      n-&gt;type = check_types(FUNCALL, n-&gt;child[0]-&gt;type, n-&gt;child[2]-&gt;type);
      }
   }
}

...

typeptr check_types(int operand, typeptr x, typeptr y)
{
   switch (operand) {
   case  FUNCALL: {
      if (x-&gt;basetype != FUNC)
         return type_error("function expected", x);
      if (y-&gt;basetype != TUPLE)
         return type_error("tuple expected", y);
      if (x-&gt;u.f.nparams != y-&gt;u.t.nelems)
         return type_error("wrong number of parameters", y);

      /*
       * for-loop, compare types of arguments
       */
      for(int i = 0; i &lt; x-&gt;u.f.nparams; i++)
         if (check_types(PARAM, x-&gt;u.f.params[i], y-&gt;u.t.elems[i]) ==
	     TYPE_ERROR) return TYPE_ERROR;
      /*
       * If the call is OK, our type is the function return type.
       */
      return x-&gt;u.f.returntype;
      break;
      }
   }
}
</pre>

<!--
<h3> Building Type Information </h3>

<ul>
<li> So far, the main discussion and pseudo-code for populating
     the symbol table that has been presented was for constructing
     tuple types for parameter lists, as needed for the type-check
     example that we then worked on.
</li><li> More generally, how do we construct type representations
     from syntax trees for other kinds of declarations?
</li><li> If we had time, we could stand to do a more concrete example of
     populating the symbol table
</li></ul>
-->

<p>

<!--<img src="c_type_rep.png" width=1200>-->



</p><h3> Semantic Analysis for Structs and Classes </h3>

What work is performed during the semantic analysis phase, to support structs and classes?

<ul>
<li> Build struct/class-level symbol tables
<li> In the implementation of <code>x.y</code> (and <code>x-&gt;y</code>
     in languages that have it),
     lookup <code>y</code> within <code>x</code>'s type's symbol table,
     using privacy rules.

<li> If you did classes: within class member functions, three-level symbol lookup
     (local first, then class, then global).
<li> If you did inheritance, that would be a whole fun topic. Multiple inheritance even more so!
<li> ...what are the other issues for semantic analysis of objects in
     our language, as you understand it?
</li></ul>



<h3> How to TypeCheck Square Brackets </h3>

This is about the grammar production whose right-hand side is:
<pre>postfix_expression LB expression RB
</pre>
or its equivalent in your grammar. In mainstream languages this syntax
may be reserved for an array type, but in a language like Python it might
be for lists, strings, dictionaries, etc.

<ol>
<li> recursively typecheck $1 and $3 ... compute/synthesize their .type fields.
</li><li> What type(s) does $1 have to be?  LIST/ARRAY, or STRING (or DICT/TABLE, if a table type exists)
</li><li> What type(s) does $3 have to be?  INTEGER (or e.g. STRING/ARRAY OF CHAR, for tables with those keys)
</li><li> What is the result type we assign to $$?  Lookup the element type from $1, possibly Any
</li></ol>

Pseudo-code fragment.  Goal is to find errors and determine n's type.
<pre>int typecheck_squarebrackets(struct tree *n)
{
   struct tree *n1 = n-&gt;child[0];
   struct tree *n3 = n-&gt;child[2];
   /*
    * Typecheck children. This is a mutual recursion.
    */
   if (typecheck(n1) == TYPE_ERROR ||
       typecheck(n3) == TYPE_ERROR) {
      n-&gt;type = TYPE_ERROR;
      return TYPE_ERROR;
      }

   /*
    * Given the children's types, see whether n1[n3] is legal.
    * For PunY, you need to allow for Any at various points.
    */
   switch (n1-&gt;type-&gt;basetype) {
   case STRING:
      /* ... insert string typecheck code here */
      /* check if n3's type is integer */
      if (n3-&gt;type-&gt;basetype != BT_INTEGER) {
          bad_type("list must be subscripted with integers", n3);
	  return TYPE_ERROR;
          }
      /* a subscript of a string is still a string, right? */
      n-&gt;type = n1-&gt;type;
      break;
   case LIST:
      /* check if n3's type is integer */
      if (n3-&gt;type-&gt;basetype != BT_INTEGER) {
          bad_type("list must be subscripted with integers", n3);
	  return TYPE_ERROR;
          }
      /* assign n's type to be n1's element type */
      n-&gt;type = n1-&gt;type-&gt;u.l.elemtype;
      break;
   case DICT:
      /* check if n3's type is n1's index type */
      if (n3-&gt;type-&gt;basetype != n1-&gt;type-&gt;u.t.indextype-&gt;basetype) {
          bad_type("table must be subscripted with its declared index type", n3);
	  return TYPE_ERROR;
         }
      /* assign n's type to be n1's element type */
      n-&gt;type = n1-&gt;type-&gt;u.t.elemtype;
      break;
   default:
      bad_type("list or table expected in [] operation", n1);
      /* what does n's type field hold, then */
      n-&gt;type = /* ?? */
      return TYPE_ERROR;
      }
</pre>

<br>
<br>
<br>
<br>
<br>
Did we get something like:

<pre>      if (n3-&gt;type-&gt;basetype != INTEGER) {
         bad_type("index must be integer in [] operation", n3);
         }
      n-&gt;type = n1-&gt;type-&gt;elemtype;
</pre>
and
<pre>      if (n3-&gt;type-&gt;basetype != n1-&gt;type-&gt;indextype) {
         bad_type("index type must be compatible in [] operation", n3);
         }
      n-&gt;type = n1-&gt;type-&gt;elemtype;
</pre>





<h3> What other type checking examples should we be doing? </h3>

So far in lecture we have seen possibly-too-handwavy examples of
<ul>
<li> Operators like x + y
</li><li> Parameters for a function call f(x,y) where arguments must be checked
</li><li> Subscript operator x[y], dot operator x.y
</li></ul>

What else would help you wrap your brains around type checking?

<!--
<h3> Old Mailbag </h3>

<dl>
<dt> When putting together my grammar for Homework 2, I didn't implement any
postfix expressions. Instead my grammar rules for a list access looks
something like this:

<pre>
ArrayAccess: IDENTIFIER '[' Expression ']' ;
</pre>

i.e. I only allow brackets after an identifier, so something like
<code>function_that_returns_list()[1]</code> is invalid.
Will I need to implement postfix expressions, so that expressions
like that one are valid?
<dd> While in real languages such expressions are supported, in g0
tests will only get as complicated as those that come
up in CS120. I don't think function returns are subsequently
subscripted, so f()[i] is out, and we have ruled out L[i][j] even
though CS120 does that much. The main postscript expressions that
might be chained together involve the dot operator, so x.y.z or maybe
L[i].x[j] for example.

</dl>
-->


<h3> Mailbag </h3>

<dl>
<dt> I have homework due in other classes. Can we have an extension?
<dd> The bad news is: we don't have room in the semester for much extension.
     The good news is: by this point, the late fees are very low.

<dt>I'm still working on hw4 since I can't get my assignment 4 working clean
enough for hw5. What should
I do? I do not wanna fail this class and its not like I haven't been putting
lots of effort into it.
</dt>

<dd> You are graded relative to your peers, and many of your peers are also
far behind. If you have been putting in appropriate effort, and you are
getting instructor help when you get stuck, you should be able to make
progress on your HW. If you stay in, and give it your best shot, odds are
good that relative to your peers, you will be OK.

<dt> When int and double mix, C-based languages promote
      <code>int</code> to <code>double</code>.
     Do we ever have to demote from  <code>double</code> to <code>int</code>?
<dd> What should happen if the program contains:
<pre>
   i : int
   r : float
   r = 27.0
   i = 3.1415 * r * r # implicit demotion to int
   i = int(3.1415 * r * r) # explicit demotion to int
</pre>
<ul>
<li> Is all this legal Python? yes.
<li> Does CSE 107 use implicit demotion? (not sure)
<li> Does it use int()? Yes.
  </ul>

<!--
<pre>
   int i;
   double r;
   r = 27.0;
   i = 3.1415 * r * r; // error, no autodemotion
   i = (int) (3.1415 * r * r); // error, no typecasting
</pre>
-->


<!--
<dt> Regarding pointers, are we only supporting char *? Or are we supporting
all pointer types, like int*, double*? I also wasn't sure if we were
supporting char * as a return type for functions, like char *func().

<dd> How much of pointers are used in CSE 113?  Almost all C programs
use pointer types like <code>FILE *</code>...
-->
<!--
When professor Soule explicitly introduces
pointer types he uses int *ptr, and ptr = &x; but these are in
artificial toy fragments. The program example of chapter 7, however,
declares a 2D array of pointers to objects (i.e. class instances),
and uses a pointer to object to swap elements within the 2D array.
Later on he explicitly uses object pointer to implement linked lists.
-->
<!--
<blockquote>
Your official charge is to support pointers, except you do not have
to support pointer arithmetic (p + i). Unofficially it seems that
you could get away without supporting pointers to types other than
char and struct instances, but I am not sure that will save you much.
</blockquote>
-->
</dl>



</p><p>
<font size="1"> <a name="29">lecture #29</a> began here</font>
</p><p>

<h3> "Drop day" commentary </h3>

<ul>
<li> If you need advice on whether to withdraw, I am happy to meet or zoom
<li> Personally, I would guess that: if you do not have syntax trees that
  you can trust yet, it would be better to take the class again. But it is
  your call
<li> If you have mostly-reasonable trees and are struggling e.g. with symbol
  tables, the class is still pass-able but you will need to persist, and get
  help where needed, maybe more help than you have asked for up to now.
</ul>

<h3> Thoughts on HW </h3>

<ul>
<li> Class Specs say the zip should not unpack in a subdirectory
<ul>
  <li> if you did not comply, my script might try to move
    your files up a directory so I can build them
  <li> if you named your directory the same as the name of
    the required compiler executable name, "make" will fail for me
</ul>
<li> Class Specs say the zip should not include generated files
  <ul>
    <li>This includes executables, .o or .class, lex.yy.c or Yylex.java, *.tab.c or Parser.java...
    <li> I expect my script to be able to build your compiler from scratch,
      and submitting these files prevents that
  </ul>
<li> Some submissions appear not to have been tested on login.cs.nmt.edu.
<ul>
<li>     If you do not build and run there you might not get many points.
<li> For example, if you build your .zip on MACOS and leave everything in and
  the .zip includes a bunch of MACOS "data fork" subdirectories, that makes
  extra clutter that might or might not pose extra build troubles on Linux.
  I mean, what could possibly go wrong during my testing/grading? Lots.
  As another example, some students leave their entire .git repo in their
  submission. Please do not.
</ul>
</ul>

<!--
<h3> Class Member Variables </h3>

<ul>
<li> In CSE 423 we often don't do classes, or only have one class
  (for user code) and all
  members of that class are public static.
<li> public static provides a "global" scope for J0 Level 1
<li> In a previous class discussion I said OK I'd change all the tests to
     require <code>public static</code> everywhere.
<li> As originally delivered to you,
     j0gram.y allows non-static variables (not a J0 Level 1 thing)
     and does not provide for public static class member variables.
<li> Need to add a production rule to j0gram.y, something like
  <pre>
FieldDecl: PUBLIC STATIC Type VarDecls ';' ;
  </pre>
<li> No point penalty or late fee, but yeah, please go ahead and implement
  this and resubmit HW4 with it. For HW#3 I will comp you points lost due
  to this.
</ul>
-->

<!--
<h3> Tests from Lab #9 </h3>

<!--
I am told we have some 80 lexical tests, 30 syntax  tests, and 72 semantic
tests in a repo at
<A href="https://git.cs.nmt.edu/hashfastr/c113c-test-programs/-/tree/master">
  https://git.cs.nmt.edu/hashfastr/c113c-test-programs/-/tree/master</A>-->
<p>
  Questions:
  <ul>
<li>  How did we do on coverage in each of these three categories?
<li>  Are we lumping disparate items into tests such that failing one,
  I would not know if another was working or not?
<li> Is there anything else that would help you test your compilers, prior
  to code generation tests?
</ul>
-->

<h3>Another Typecheck Example</h3>

Consider the following small program.

<table border>
<tbody><tr><th> C </th><!--<th> Go </th>--><th>Java</th></tr>
<tr><td>
<pre>void write(int);
int fib(int);
void main()
{
   int i;
   i = 0;
   while (i &lt; 5) {
      write(fib(i));
      i += 1;
      }
}
int fib(int n)
{
  if (n &lt; 3) { return 1; }
  return fib(n-2) + fib(n-1);
}



</pre>
  </td>
<!--
  <td>
<pre>package main
import "fmt"
func fib(n int) int {
  if n &lt; 3 { return 1 }
  return fib(n-2) + fib(n-1)
}
func main() {
   var i int
   for i &lt; 7 {
      fmt.Println(fib(i))
      i += 1
      }
}
</pre>
</td>
-->
<td>
<pre>public class fibber {

  
  public static void main()
  {
     int i;
     i = 0;
     while (i &lt; 5) {
        write(fib(i));
        i += 1;
        }
  }
  public static int fib(int n)
  {
    if (n &lt; 3) { return 1; }
    return fib(n-2) + fib(n-1);
  }
  public static void write(int i) {
    System.out.println(i);
  }
}
</pre>
</td>
</tr></tbody></table>

<p>

See below for a syntax tree

<ul>
<li> given the syntax tree, compute the types of all
     symbols and expressions.
</li><li> You have exactly one hammer to use: tree traversal
<pre>   void treewalker(struct tree *n) {
      /* pass inherited attribs into children */
      /* visit children */
      /* make use of synthesized attribs in children */
   }
</pre>
You can have as many passes, calling as many different
traversal functions, as you want.
</li><li> Do you know how to build/populate the symbol tables for this?
     Practice simulate/visualize that code on the tree for this program.
</li><li> Do you know how to type check it?
     Practice simulate/visualize that code on the tree for this program.
</li></ul>


<h3>From Type Checking on to Code Generation</h3>

<ul>
<li> We could still decide to do additional examples of type checking.
</li><li> It is fair game for you to ask more questions as you work on it.
</li><li> Main reason to compute all this type information was: we need it
     for code generation.  And we need it because different types are
     different sizes and call for different machine instructions.
</li><li> Fancy words for adding information to the syntax tree (and symbol tables,
     which are mainly used so you can look up things in the syntax tree):
     decoration, annotation... basically, it is a fundamental task of computing
     to turn <em>data</em> into <em>information</em> by analyzing it
     and adding value.
</li></ul>


<!--
<h3> Old Mailbag </h3>
<dl> 
<dt> When creating an array, Go allows for the following:
<pre>   var x []int 
</pre>

What should the array size be when this happens? Is this supposed to be an
all-knowing infinite array or an empty array?

</dt><dd> I think we discussed this in class last time -- this syntax is in Go
but not in VGo.

</dd></dl>
-->

<h3> Type Checking Fibonacci Example, Cont'd </h3>

As a reminder, our code looked like this:
<p>
<pre>void write(int);
int fib(int);
void main()
{
   int i;
   i = 0;
   while (i &lt; 5) {
      write(fib(i));
      i += 1;
      }
}
int fib(int n)
{
  if (n &lt; 3) { return 1; }
  return fib(n-2) + fib(n-1);
}
</pre>

<p>
The full syntax tree looks like the following. Still barely legible on my
office monitor  
<p>

<img src="fib.png" width=600>

<p>

Now, let's crank the tree traversal for the main typecheck of the
executable code.





<p>
<font size="1"> <a name="30">lecture #30</a> began here</font>
</p><p>

<h3>End-of-semester considerations</h3>

<ul>
  <li> The <A href="https://www.nmt.edu/registrar/Finals%20202330%20-%20V6.pdf">NMT final exam schedule</A> says our designated
    final exam period is Monday May 8, 6-9pm, in Cramer 107
  <li> Final grades for graduating seniors (most of you) are due May 10 5pm
  <li> If we give a final (current plan) it has to be gradable in two
       business days.
  <li> Your final projects have to be completed early enough that I can
    finish grading them BEFORE May 8.  So: final project (i.e. HW#6) is
    due May 3 5pm, end of instruction.
</ul>



<h3><A href="hw6.html">HW#6</A></h3>


<h3> Mailbag </h3>

<dl>
<!--
<dt> What up with arrays, anyhow?
<dd> J0 has one-dimensional Java-style arrays.  In order to keep things
  simple, you do not have to do array initializers where the program says
  things like
  <code>int [] a = {2, 3, 5, 7}</code>.
  You only have to do uninitialized arrays
  where the program says
  <pre>int [] a;
    a = new int[100];
  </pre>
-->

<dt>
I have been having a bug with stuff from HW4 for a decent while... I am
pretty much at the point that I'm thinking I should start over with my code
entirely from scratch and try to rebuild it. But if I do this I really have
no hope of finishing HW5 which I am assuming will carry on to HW6.  I
recently found an error with some of the stuff I wrote in HW3 which was
causing problems with my HW4... I am
wondering if there is anyways to have stuff that we are currently working on
now graded separately. Otherwise I either will have to rewrite my entire code
again being late on everything. I would rather not do this as I did it in
HW3 when my prior code was not working. But otherwise all of my homeworks
moving forward is not going to run properly because of errors in prior
homework

<dd>

Yup,  all along, the later homeworks depend upon earlier
ones, and this poses a challenge.  My general view is that you should not
try and go on to a later homework if an earlier one has not been completed
to a passing level. If an earlier homework was not at a passing level, you
should fix and resubmit, and you are encouraged to seek help if that is
needed.

</dl>


<h3>Run-time Environments </h3>

<dl>
<dt>How does a compiler (or a linker) compute the addresses for the various
instructions and references to data that appear in the program source code?
</dt><dd>To generate code for it, the compiler has to "lay out" the data as it will
be used at runtime, deciding how big things are, and where they will go.
</dd></dl>

<ul>
<li> Relationship between source code names and data objects during execution
</li><li> Procedure activations
</li><li> Memory management and layout
</li><li> Library functions
</li></ul>





<h4> Scopes and Bindings </h4>

<ul>
<li> Variables may be declared explicitly or implicitly in some languages

</li><li> Scope rules for each language determine how to go from names to
     declarations.
</li><li> Each use of a variable name must be associated with a declaration.
</li></ul>

This last item is generally done via a symbol table. In most compiled
languages it happens at compile time (in contrast, for example ,with LISP).

<h4> Environment and State </h4>

Environment maps source code names onto storage addresses (at compile time),
while state maps storage addresses into values (at runtime).  Environment
relies on binding rules and is used in code generation; state operations
are loads/stores into memory, as well as allocations and deallocations.
Environment is concerned with scope rules, state is concerned with things
like the lifetimes of variables.
<p>


<!--
<h3> Thoughts on the Predefined Classes </h3>

Tables 1.4 and 1.5 of the 120++ manual present Dr. Soule's reference
on built-in classes such as string, ifstream, and ofstream.

One way to implement these would be to write actual source code for (the
     tiny subset of) these classes that we need, and feed it into your
     compiler as if it were an #include.  Another way would be to just
     execute code that performs the corresponding symbol table inserts and
     type constructors.

<pre>
class ifstream {
   public:
      ignore();
   }
class ofstream {
   }
</pre>
-->

<!--
<h3> Semantics Things Checked </h3>

<dl>
<dt> extern
<dd> this word does not appear in 120++
<dt> static
<dd> this word does not appear in 120++
<dt> default constructor
<dd> this is used (without discussion) in an example in 120++
     Your semantic rule would be: if no constructor is present,
     insert a default constructor into the symbol table for a class.
<dt> delete
<dd> this is used in a trivial way on a simple pointer variable.
     Your typecheck rule would be: its operand must be a pointer.
</dl>
-->


</p><h3> Runtime Memory Regions </h3>

Operating systems vary in terms of how the organize program memory
for runtime execution, but a typical scheme looks like this:

<table border="">
<tbody><tr><th>code
</th></tr><tr><th>static data
</th></tr><tr><th>stack (grows down)
</th></tr><tr><td>heap (may grow up, from bottom of address space)
</td></tr></tbody></table>

The code section may be read-only, and shared among multiple instances
of a program.  Dynamic loading may introduce multiple code regions, which
may not be contiguous, and some of them may be shared by different programs.
The static data area may consist of two sections, one for "initialized data",
and one section for uninitialized (i.e. all zero's at the beginning).
Some OS'es place the heap at the very end of the address space, with a big
hole so either the stack or the heap may grow arbitrarily large.  Other OS'es
fix the stack size and place the heap above the stack and grow it down.





<h4> Questions to ask about a language, before writing its code generator</h4>

<dl>
  <dt> May procedures be recursive?
  <dd>All but toy languages require this and it entails a stack region
<dt> What happens to locals when a procedure returns?
<dd>Lazy deallocation would be exceedingly rare
<dt> May a procedure refer to non-local, non-global names?
<dd> nested procedures?  dynamic scoping? implicit object/struct field names?
<dt> How are parameters passed?
<dd>Many styles possible. Different
     declarations for each? Rules hardwired by type?
  <dt> May functions be passed as parameters?
  <dd> Not too awful. Function pointers are popular with
     both the functional programming and operating systems communities!
    <dt> May procedures be return values?
      <dd> Adds complexity for non-local names
<dt> May storage be allocated dynamically (like, on the heap)
<dd> All modern languages require this,
     but some languages do it with syntax (new) others with library (malloc))
  <dt> Is storage deallocated explicitly
    <dd> Do we have a garbage collector?  Does that affect code generation?
</dl>






  

<h3> "Modern" Runtime Systems </h3>

Modern languages' runtime systems have extra properties compared with
that of a traditional language like C. Here are a few examples.
<p>

</p><dl>
<dt> A "self" or "this" in non-static method calls.
</dt><dd> Possibly implemented via a dedicated register, or an implicit,
     extra parameter.  Either way, OO slightly alters the activation record.

</dd><dt> Garbage collection.
</dt><dd> Automatic (heap) storage management is one of the most important features
     that makes programming easier.
The Basic problem in garbage collection is: given a piece of memory, are there
any pointers to it?  (And if so, where exactly are all of them please).
Approaches:

<ul>
<li> reference counting
</li><li> traversal of known pointers (marking)
	<ul>
	<li> copying (2 heaps approach)
	</li><li> compacting (mark and sweep)
	</li><li> generational
	</li></ul>
</li><li> conservative collection
</li></ul>

Note that there is a fine 
<a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.439.1202&rep=rep1&type=pdf">
paper</a> presenting a "unified theory of garbage collection"

</dd><dt> Reflection.
</dt><dd> Objects can describe themselves, via a set of member functions.
     This plays a central role in Visual GUI builders, IDE's,
     component architectures and other uses.

</dd><dt> Just-in-time compilation.
</dt><dd> A virtual machine ("byte code") execution model...can be augmented
     by a compiler built-in to the VM that converts VM instructions
     to native code <em>for frequently executed methods or code blocks</em>.

</dd><dt> Security model.
</dt><dd>  Modern languages may attempt to guarantee certain
     security properties, or prevent certain kinds of attacks.
</dd></dl>

For what its worth, goal-directed programs in languages such as Unicon have
an activation tree each instant, due to suspended activations that may be
resumed for additional results.  The lifetime view is a sort of
multidimensional tree, with three types of nodes.

<p>

<p>
<font size="1"> <a name="31">lecture #31</a> began here</font>
</p><p>

<h3> Mailbag </h3>

<dl>
<dt> Do we really have to implement a dot operator? What is it again?
<dd> Summary of dot (.) operator used in CSE 107:
<ul>
<li> file.write(s), file.close(), file.read(), file.readline()
<li> math.sqrt(r), math.asin(r), math.acos(r), math.atan(r), math.gcd(i)
<li> random.choice(L)
<li> list.append(x), list.remove(x), list.pop()
<li> str.split(), str.split(s), str.join(s), str.format(i), str.format(i,j),
     str.replace(s2, s3), str.remove(s)?, str.isdigit()
<li> dict.keys()
<li> module.function(...) for functions in imported user defined modules;
  handled same as in-module functions except looked up in module's symbol table
<li> module.glob for global variables within module 
<li> Aspirational-not-required: turtle.speed(r), turtle.Turtle(), turtle.done(),
  turtle.forward(i), turtle.right(r), turtle.left(r), turtle.clone(),
  plt.subplot, plt.bar()
</ul>
<dt> So, really, how do I handle classes (structs)?

<dd> Well... to answer this question:
  <ol>
    <li> In PunY, we are only supporting a tiny # of 107-required class types.
         File objects returned by open(). What else?
    <li> there should be a basetype (integer code) for <code>class</code>
        (or <code>struct</code>)
         in your type representation.
    <li> In PunY all variables of a declared class type start with a
      null value.
      <!--  Instances get created via <code>new</code> which is just
      a calloc(). J0 does not do constructors, which is kind of too bad. :-)-->
    <li> the same class/structure name/label cannot be declared twice.
         Insert the <em>classname</em> as a global symbol table entry
         when a class is declared.
    <li> each unique class type should be able to tell you its fields'
         and methods' names and types, in order
    <li> each unique class type should be able to lookup a field/method
         by name and tell you its type. i.e. classes define a local scope

    <li> For PunY, variables declared to be of a class type can be assigned
         from any value of that type, and not any other class type.
    <li> The same exact-match type check semantics are applied e.g. to
      passing a class instance as a parameter, it is like an assignment
    <li> Do PunY objects need to support any other operators besides
         assignment and being passed as a parameter?  Method calls.
    <li> For languages with structs only:
      <ul><li> check your language. In many/most
      languages struct values cannot be assigned to other named struct
      types,
         even if they are "equivalent" in size and shape
    <li> while you cannot declare a struct variable for an undeclared struct
      type, you can declare a pointer to an unknown struct type.
    <li> if we were doing typedefs we would have extra complications like
      distinguishing a variable of a struct type from a typedef name
      for a struct type.
	</ul>
  </ol>
</dl>

<!--
<h3>On Adding PUBLIC STATIC to member variable declarations</h3>

<ul>
<li> As-delivered, j0gram.y had 50 shift/reduce and 5 reduce/reduce conflicts.
<li> You were instructed to fix the reduce/reduce conflicts, but you
  didn't have points riding on fixing the shift/reduce conflicts, they would
  only cost you points if they caused a test case to fail.
<li> As mentioned last class, adding the one line
  <pre>FieldDecl: PUBLIC STATIC Type VarDecls ';' ;</pre>
  adds one shift/reduce AND a warning that would cost you a point:
  <pre>j0gram.y:22.19-22: warning: rule useless in parser due to conflicts [-Wother]
 MethodReturnVal : Type | VOID ;
                   ^^^^</pre>
<li> If you "factor out" the common prefix of a MethodHeader and a FieldDecl,
  you eliminate the warning and the extra shift/reduce:
  <pre>
DeclHeader: PUBLIC STATIC Type;
</pre>
  Q: where do you use this non-terminal in order to fix the trouble? What else do
  you have to change?
</ul>
-->

<h4>Activation Records</h4>

Activation records organize the stack, one record per method/function call.

<p>

  <table border>
    <tr><th>&vellip;<th>&vellip;<br>earlier<br>activation<br>record<br>&vellip;
    <tr><th>&vellip;<th>&vellip;<br>earlier<br>activation<br>record<br>&vellip;
<tr><th>
<table >
<tbody><tr><td></td><td>return value
</td></tr><tr><td></td><td>parameter
</td></tr><tr><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&vellip;
</td></tr><tr><td></td><td>parameter
</td></tr><tr><td></td><td>previous frame pointer (FP)
</td></tr><tr><td></td><td>saved registers
</td></tr><tr><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&vellip;
</td></tr><tr><td>%rbp &#8594;</td><td>saved PC
</td></tr><tr><td></td><td>local
</td></tr><tr><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&vellip;&nbsp;&nbsp;&nbsp;&nbsp;
</td></tr><tr><td></td><td>local
</td></tr><tr><td></td><td>temporaries
</td></tr><tr><td>%rsp &#8594;</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&vellip;
</td></tr></tbody></table>
  <th>
current<br>activation<br>record
<tr>
  <th> "top" of stack<br>
    &vellip;<br>
       grows down by subtracting from %rsp<th>
       calls create new<br>activation<br>records here
</table>

</p><p>

At any given instant, the live activation records form a chain and
follow a stack (push/pop) discipline for allocation/deallocation.
Since each activation record contains a pointer to the previous one,
it is really pretty much a linked list we are talking about, with a
base pointer register holding the pointer to the top of the stack.
</p><p>

Over the lifetime of the program, all these activation records,
if saved, would form a gigantic tree.  If you remember all
prior execution up to a current point, you have a big tree in which
its rightmost edge are live activation records, and the non-rightmost
tree nodes are an execution history of prior calls. (Program Monitoring
and Visualization could allow us to depict and inspect this history tree.)

</p><p>

<!--<h3> Reference Implementation Files </h3>

Here are some files containing example code you may use in your compiler
project.  Note that understanding and using someone else's code may require
just as much or more work than writing it yourself, and that no warranty
is expressed or implied: you are responsible for your compiler working,
even if it uses code from these files and it turns out they have a bug!

<ul>
<li> <A href="hw4/main.c">main.c</A>
<li> <A href="hw4/tree.h">tree.h</A>
<li> <A href="hw4/type.h">type.h</A>
<li> <A href="hw4/sym.h">sym.h</A>
<li> <A href="hw4/sym.c">sym.c</A>
<li> <A href="hw4/semantic.c">semantic.c</A>
</ul>-->


<!--
<h3> Reduction in Typecheck Work </h3>

<dl>
<dt> 120++ does not use pointer arithmetic
<dd> so no pointer + integer.
<dt> 120++ does not mention any type promotion
<dd> so no char + integer or integer + double.
</dl>


<h3> On Type-checking of &lt;&lt; </h3>

Consider

<pre>
   cout &lt;&lt;"Player"&lt;&lt;current_player&lt;&lt;endl;
</pre>

We deduce:
<ul>
<li> &lt;&lt; requires a stream on its left side
<li> &lt;&lt; accepts string, char *, int, or double on its right side
       (but not: ... what?)
<li> &lt;&lt; is left-associative
<li> &lt;&lt; produces a value of type ifstream as its result
</ul>
-->




</p><h3> Variable Allocation and Access Issues</h3>

Given a variable name, how do we compute its address?
<dl>
<dt> globals
</dt><dd> easy, symbol table lookup... once we have figured out how to
     allocate addresses in a process that does not exist yet.
</dd><dt> locals
</dt><dd> easy, symbol table gives offset in (current) activation record
</dd><dt> objects
</dt><dd> Is it "easy"? If no virtual semantics*, symbol table gives offset in
     object, activation record has
     pointer to current object in a standard location. (<em>This is the
     reason C++ does not use virtual semantics by default</em>.)
     <br>
     For virtual semantics, generate code to look up offset
     in a table at runtime, based on the current object's type/class.
</dd><dt> locals in some enclosing block/method/procedure
</dt><dd> ugh.  Pascal, Ada, and friends offer their own unique kind of pain.
     Q: does the current block support recursion?  Example: for procedures
     the answer would be yes; for nested { { } } blocks in C the answer
     would be no.
<ul>
<li> if no recursion, just count back some number of frame pointers based
     on source code nesting
</li><li> if recursion, you need an extra pointer field in activation record
     to keep track of the "static link", follow static link back some
     # of times to find a name defined in an enclosing scope
</li></ul></dd></dl>

<h3> *What are "Virtual" Semantics? </h3>

C++ is (just about) the only major object-oriented language
that has to compete with C in the performance arena. For this
reason, it chose early on to be different than every other
OO language. By default, if you are working on a class Foo
object, you can find Foo's member variables and call Foo's
methods by compile-time-determinable memory offsets and
addresses.  So a class is basically no worse than a struct to
generate code for.
<p>

If you say the keyword "virtual" in C++, or if you use just
about any other OOP language, subclassing and interfacing
semantics mean that the address referred to by o.x or o.m()
has to be calculated at runtime by looking up o's actual
class, using runtime type information.





</p><h3> Sizing up your Regions and Activation Records </h3>

Add a size field to every symbol table entry. Many types are not required
for your project but we might want to discuss them anyhow.<br>

<ul>
<li> The size of chars is 1. We could make them use an alignment of 8,
     but then arrays of char would be all...wrong.<br>
</li><li> The size of integers is 8 (for x86_64; varies by CPU).<br>
</li><li> The size of reals is... 8 (for x86_64 doubles; varies by CPU).<br>
</li><li> The size of strings is... 8? (varies by CPU and language)
</li><li> The size of arrays is (sizeof (elementype)) * the number of elements.
      In static languages.
   The size of arrays/lists in dynamic languages might be more complicated.
</li><li> what about sizes of structs/objects?  They are the size of the sum of
     their members... after adding in padding to meet alignment requirements.
</li></ul>
<p>

You do this sizing up once for each scope.  The size of each scope is the
sum of the sizes of symbols in its symbol table.



<a name="codegen">
</a></p><h3><a name="codegen"> Intermediate Code Generation </a></h3><a name="codegen">
</a>

Goal: list of machine-independent instructions for each procedure/method
in the program.  Basic data layout of all variables.
<p>

Can be formulated as syntax-directed translation
</p><ul>
<li> add new semantic attributes where necessary.
     For expression E we might have
<dl>
<dt> <code>E.addr</code>
</dt><dd> the location that at run-time will hold the value of E.
    Sometimes called .place or .location.
</dd><dt> <code>E.icode</code>
</dt><dd> the sequence of intermediate code statements evaluating E.
</dd></dl>
</li></ul>
     How does the compiler talk at compile-time about addresses that
     will exist at runtime?
<ul>
<li>  Option (A): leave everything as names for now.  "declare" the names
     in intermediate code, specifying which memory region they live in, and
     how many bytes big they are. assume an assembler will convert names to
     addresses during final code generation.
</li><li> Option (B): designate only four names for the four memory regions:
     code, global/static, stack, and heap. Specify all addresses as offsets
     in one of those regions. For first two, offsets are relative to a base
     pointer that is the start of the two region. For the latter two, offsets
     are relative to a register (current activation record/base pointer, and
     current "this/self" object pointer).
</li></ul>


<h3> Helper Functions for Intermediate Code Generation </h3>

<ul>
<li> new helper functions, e.g.
<dl>
<dt><code>genlocal([n])</code>
</dt><dd> returns a new one-word temporary variable each time it is called.
    Optionally, it could take a parameter <code>n</code> to specify a size
    in #words, or #bytes. Let's say it
     is the number of 8-byte words.  Default is
     one word (8 bytes), always out of the local region, on the stack.
</dd><dt><code>genlabel()</code>
</dt><dd> returns a new label each time it is called.  A label is a name for
     a code region address, but for practical purposes genlabel() could
     just return a unique integer i by incrementing a counter each time,
     or string "L"||i (e.g. "L29") each time it is called.
</dd></dl>
</li><li> actions that generate intermediate code formulated as semantic rules
</li></ul>

These helper functions might really be best described
as returning "addresses". Intermediate code addresses
are described down below.

<h3>Semantic Rules for Intermediate Code Generation</h3>

Code for evaluating traditional expressions can be synthesized
via bottom-up traversal.  If the location where an expression's
computed result can be read is called <code>addr</code> and the
sequence of intermediate code instructions that compute that
value is called <code>icode</code>, you can postulate the
following semantic rules. This is a simplifying abstraction of
what would be needed for an entire modern programming language
expression grammar, and your non-terminal names might be different.
Operator ||| is a list concatenation.

<p>

<p>
<font size="1"> <a name="32">lecture #32</a> began here</font>
</p><p>

<table border="">
<tbody><tr><th>Production</th><th>Semantic Rules</th></tr>

<tr>
<td>Assignment : IDENT '=' AddExpr  </td><td>
<pre>Assignment.addr = IDENT.addr
Assignment.icode = AddExpr.icode |||
                   gen(ASN, IDENT.addr, AddExpr.addr)</pre>
</td></tr><tr>
<td> AddExpr : AddExpr<sub>1</sub> '+' MulExpr </td><td>
<pre>AddExpr.addr = genlocal()
AddExpr.icode = AddExpr<sub>1</sub>.icode ||| MulExpr.icode |||
                gen(ADD,AddExpr.addr,AddExpr<sub>1</sub>.addr,MulExpr.addr)</pre>
</td></tr><tr>
<td>AddExpr : AddExpr<sub>1</sub> '-' MulExpr </td><td>
<pre>AddExpr.addr = genlocal()
AddExpr.icode = AddExpr<sub>1</sub>.icode ||| MulExpr.icode |||
                gen(SUB,AddExpr.addr,AddExpr<sub>1</sub>.addr,MulExpr.addr)</pre>
</td></tr><tr>
<td>MulExpr : MulExpr<sub>1</sub> '*' UnaryExpr </td><td>
<pre>MulExpr.addr = genlocal()
MulExpr.icode = MulExpr<sub>1</sub>.icode ||| UnaryExpr.icode |||
                gen(MUL,MulExpr.addr,MulExpr<sub>1</sub>.addr,UnaryExpr.addr)</pre>
</td></tr><tr>
<td>MulExpr : MulExpr<sub>1</sub> '/' UnaryExpr </td><td>
<pre>MulExpr.addr = genlocal()
MulExpr.icode = MulExpr<sub>1</sub>.icode ||| UnaryExpr.icode |||
                gen(DIV,MulExpr.addr,MulExpr<sub>1</sub>.addr,UnaryExpr.addr)</pre>
</td></tr><tr>
<td>UnaryExpr : '-' UnaryExpr<sub>1</sub> </td><td>
<pre>UnaryExpr.addr = genlocal()
UnaryExpr.icode = UnaryExpr<sub>1</sub>.icode |||
                  gen(NEG,UnaryExpr.addr,UnaryExpr<sub>1</sub>.addr)</pre>
</td></tr><tr>
<td>UnaryExpr : '(' AddExpr ')' </td><td>
<pre>UnaryExpr.addr = AddExpr.addr
UnaryExpr.icode = AddExpr.icode</pre>
</td></tr><tr>
<td>UnaryExpr : IDENT </td><td>
<pre>UnaryExpr.addr = IDENT.addr
UnaryExpr.icode = emptylist()</pre>
</td></tr></tbody></table>


  <h3> Mailbag </h3>

  <dl>
    <dt>  I ended up making a production rule that says
      <pre>DeclHeader: PUBLIC STATIC VOID { ... } ; </pre>
      but I am not sure what to put in the ... part, it is the only rule
      in my grammar where the rightside is entirely terminals.  Is that
      even legal? If it is legal, would I add all three to the stack?
      <dd> It is totally legal and normal to have a tree node with three
	children who all happen to be leaves. Since these leaves are all
	<em>reserved words</em>, a parent node that contained a production
	rule number that encoded the fact that it was built from these
	three tokens might be able to omit/prune all three children; the
	only reason to consider leaving the children in is if their line#,
	filename, column# etc. might be helpful in producing error messages
	with their exact locations. If that was not needed and you deleted
	all three children, the parent node sort of becomes a "leaf" whose
	production rule is semantically equivalent to having a token that
	means: PUBLICSTATICVOID.  Ha ha, what a dumb terminal name I made.
	Anyhow, if in any doubt, just put the terminals/children in the tree
	where you will have them IF you need them later on.
  </dl>


<a name="tac">
</a></p><h4><a name="tac"> Three-Address Code </a></h4><a name="tac">
</a>

Basic idea: break down source language expressions into simple pieces that:
<ul>
<li> translate easily into real machine code
</li><li> form a linearized representation of a syntax tree
</li><li> allow us to check our own work to this point
</li><li> allow machine independent code optimizations to be performed
</li><li> increase the portability of the compiler
</li></ul>

You can literally just make up this intermediate code file format. It
should be human readable and resemble assembler code.

<p>

<b>Instructions:</b> with the exception of immediate mode, operands are addresses and
instructions implicitly dereference values in memory located at those addresses.
Words are understood to be a 64-bit size unit. Offsets are in bytes (nwords * 8).

</p><p>

<table>
<tbody><tr><th>opcode/mnemonic</th><th>C equivalent</th><th> description
</th></tr><tr><td><code>ADD,SUB,MUL,DIV</code></td><th>x = y <em>op</em> z</th><td> store result of binary operation on y and z to x
</td></tr><tr><td><code>NEG</code></td><th>x = -y </th><td> store result of unary operation on y to x
</td></tr><tr><td><code>ASN</code></td><th>x = y </th><td> store y to x
</td></tr><tr><td><code>ADDR</code></td><th>x = &amp;y </th><td> store address of y to x (*)
</td></tr><tr><td><code>LCON</code></td><th>x = *y </th><td> store contents pointed to by y to x (*)
</td></tr><tr><td><code>SCON </code></td><th>*x = y </th><td> store y to location pointed to by x (*)
</td></tr><tr><td><code>GOTO</code></td><th>goto L </th><td> unconditional jump to L
</td></tr><tr><td><code>BLT,BLE,BGT,BGE</code></td><th>if (x <em>rop</em> y) goto L </th><td> test relation and conditional jump to L
</td></tr><tr><td><code>BIF</code></td><th>if (x) goto L </th><td> conditional jump to L if x==0
</td></tr><tr><td><code>BIFN</code></td><th>if (!x) goto L </th><td> conditional jump to L if x!=0
</td></tr><tr><td><code>PARM</code></td><th>param x </th><td> store x as a parameter
</td></tr><tr><td><code>CALL</code></td><th>call p,n,x </th><td> call procedure p with n words of parameters, store result in x
</td></tr><tr><td><code>RET</code></td><th>return x </th><td> return from procedure, use x as the result
</td></tr></tbody></table>
</p><p>
<p>
(*) Not all languages will use all TAC instructions.
<p>

<b>Three-Address Code Declarations (Pseudo instructions):</b>

</p><p>

<table>
<tbody><tr><th>declaration</th><th>description
</th></tr><tr><td><pre>glob x,n &nbsp;&nbsp;&nbsp;</pre></td><td>declare a global named x that has n words of space
</td></tr><tr><td><pre>proc x,n1,n2</pre></td><td>declare a procedure named x with n1 words of parameter space and n2 words of local variable space
</td></tr><tr><td><pre>loc x,n</pre></td><td>use name x to refer to offset n in the local region (the procedure frame);
replaces any prior definiton of x that may exist.
</td></tr><tr><td><pre>lab L<sub>n</sub></pre></td><td>designate that label <code>L<sub>n</sub></code> refers to the next instruction
</td></tr><tr><td><pre>end</pre></td><td>declare the end of the current procedure
</td></tr></tbody></table>

</p><p>


</p>

</p><h3> Old Mailbag </h3>

<dl>
<dt> How do I get started on code generation?
</dt><dd> Start at the leaves, a.k.a. basis cases.
<ul>
<li>     Fill in attributes, possibly one at a time.
</li><li>     For example, assign .addr values for everything.
</li><li>     Allocate all your labels and temporary variables
</li><li>     Assign .true and .false fields in your condition exprs
</li><li>     You can do all this in 1, 2, or 3 or more tree traversals
</li></ul>     
       After you have done these things (you may need to print trees
       that show), you are ready to start allocating .icode

<dt> What do I have to do to get a "D"?
</dt><dd> You are graded relative to your peers.  In previous semesters the
answer to this has been something like: pass the midterm and final, and
convince me that you really did semantic analysis.  If you did poorly on the
midterm, you might want to try and do better on the final, and you might
want to get some three address code working.  Do you really want to settle
for a "D"?  Almost everyone who was "D" material dropped the class already.
</dd>
</dd></dl>


<h3>TAC for Composites/Containers and Object Oriented Code</h3>

<ul>
<li> Arrays and structs hold multiple values.
</li><li> the address of a value is computed as an offset from a base
address for the entire composite object.
</li><li> One can use the existing TAC instructions, by
loading a base address explicitly using ADDR and then performing explicit
arithmetic on it.
</li><li> Or one can add new TAC instructions as needed e.g. for array, struct,
    or map objects.
</li></ul>

<p>
The sketchiness of the following table is pretty good evidence that we are
just making this up as we go along.

</p><p>

<table>
<tbody><tr><th>mnemonic</th><th>equivalent</th><th>description
</th></tr><tr><td><pre>MEMBER</pre></td><th>x = y.z</th><td>lookup field named z within y, store address to x
</td></tr><tr><td><pre>NEW</pre></td><th>x = new Foo,n</th><td>create a new instance of class named x, store
address to x.<br> Constructor is called with n parameters (previously pushed
on the stack).
</td></tr><tr><td><pre>class</pre></td><th>class x,n1,n2</th><td>pseudoinstruction to declare a class named x with n1 bytes of class variables and n2 bytes of class method pointers
</td></tr><tr><td><pre>field</pre></td><th>field x,n</th><td>pseudoinstruction to declare a field named x at offset n in the class frame
</td></tr></tbody></table>

</p><p>

Note: no new instructions are introduced for a member function call.  In a
non-virtual OO language, a member function call <code>o.m(x)</code> might be
translated as <code>Foo__m(o,x)</code>, where <code>Foo</code> is
<code>o</code>'s class.  Other translation schemes are possible.


</p><h3> Variable Reference, Dereference, and Assignment Semantics </h3>

Given, say, x having a value of 2, what does the following compute?

<pre>   int y = x + (x = x + 1) + x;
</pre>

OK, what about

<pre>   int y = x + x + (x = x + 1) + x;
</pre>

In order to get the answers right, one has to understand the moment at which
a variable reference is computed versus the moment at which it is dereferenced
to obtain its value, versus the moment at which it is assigned a new value.
<p>

Operator precedence (and parentheses) determine what order the expressions
are evaluated.  But evaluating something as simple as
<em>expr</em>+<em>expr</em> can give surprise results if variables' values
can change between their reference construction and dereferencing operation.



</p><h3> Tree Traversals for Moving Information Around </h3>

Like with semantic analysis, the intermediate code generation game is
largely one of moving information around in the tree.

<ul>
<li> NOT a "blind" traversal that does the same thing at each node.
</li><li> often a switch statement pre- or post- the traversal of children
</li><li> switch cases are the grammar rules used to build each node
</li><li> lots of similar-but-different cases, for similar-but-different
       production rules for the same non-terminal.
</li></ul>

The alternative to writing one huge recursion
consisting of gigantic switch statements is the "swarm" model:
write a suite of mutually-recursive functions that know
how to do work for each different rule or each different type of
non-terminal node for that traversal.

<p>
<font size="1"> <a name="33">lecture #33</a> began here</font>
</p><p>

<h3> Announcements </h3>

<ul>
  <li> No office hours Monday 4/17/23, sorry
  <li> Class 4/17/23 will have no regular lecture and instead will feature an <em><b>extra credit activity</b></em> (+10 midterm points)
  <li> To participate in the activity you will need to attend in person
       and bring a working laptop.
</ul>

<h3> Fake Mailbag </h3>

<dl>
<dt> Can you describe how to get from ucode to executables, and run them?
  <dd> <ol>
<li> write out ucode into a file with a .u extension
<li> Invoke the Unicon linker to translate and link ucode into binary format
   (in Icon and Unicon this is called icode)
<li> in C, the similar translation to assembly and linking steps would occur
  (gcc -S translates to assembler .s files, gcc foo.s converts to binary and
  links with the C library) although the extensions and formats differ.
<li> Invoking Unicon from within your compiler probably is done via a
  function named system(s), where s is a command line such as "unicon foo.u".
  Java and Python have variants of this system() function.  In Python it is
  os.system(); in Java it might be Runtime.getRuntime().exec(s).
</ol>

<dt> Can you describe the transpiler HW#6 option a bit?
<dd>
<ol>
<li>A transpiler translates source code to source code.
<li> For PunY, the output source code would be Unicon .icn files
<li> The transpiler should then invoke the Unicon translator
 (e.g. system("unicon foo.icn") to generate Unicon ucode and binary
  executable VM icode files.
<li> If the source input and output source code languages are similar,
   the transpiler is almost a "preprocessor" or a "pretty printer";
   there are resources on implementing pretty printers that could be studied.
<li> To translate Python to Unicon you can traverse your syntax tree,
  outputting a string of output Unicon for each tree node, with pieces
  filled in by the string output for various children.
<li> Example: the Unicon translator itself traverses the syntax trees via
  a recursive function called yyprint() that mostly prints tokens as
  themselves, but calls special helper functions for tree nodes that
  require non-trivial alterations in the output code, such as classes.
</ol>
</dl>


<h3> Intermediate Code Generation: Traversal Code Example </h3>

The following code sample illustrates a code generation tree traversal.
Note the gigantic switch statement.  A student once asked the question
of whether the link lists might grow longish, and if one is usually appending
instructions on to the end, wouldn't a naive link list do a terrible
O(n<sup>2</sup>) job.  To which the answer was: yes, and it would be good
to use a smarter data structure, such as one which stores both the head
and the tail of each list.

<pre>void codegen(nodeptr t)
{
   int i, j;
   if (t==NULL) return;

   /*
    * this is a post-order traversal, so visit children first
    */
   for(i=0;i&lt;t-&gt;nkids;i++)
      codegen(t-&gt;child[i]);

   /*
    * back from children, consider what we have to do with
    * this node. The main thing we have to do, one way or
    * another, is assign t-&gt;code
    */
   switch (t-&gt;label) {
   case PLUS: {
      t-&gt;icode = concat(t-&gt;child[0]-&gt;icode, t-&gt;child[1]-&gt;icode);
      g = gen(PLUS, t-&gt;address,
              t-&gt;child[0]-&gt;address, t-&gt;child[1]-&gt;address);
      t-&gt;icode = concat(t-&gt;icode, g);
      break;
      }
   /*
    * ... really, a bazillion cases, up to one for each
    * production rule (in the worst case)
    */
   default:
      /* default is: concatenate our children's code */
      t-&gt;icode = NULL;
      for(i=0;i&lt;t-&gt;nkids;i++)
         t-&gt;icode = concat(t-&gt;icode, t-&gt;child[i]-&gt;icode);
   }
}
</pre>




<!--
Decisions made 10/25: int does not autoconvert to bool, && and || are
allowed to require bool arguments.  Strings can be compared with == and !=.
-->



<h3> Intermediate Codegen Example </h3>

<ul>
<li> A lecture or two ago we had a request in class to do an example
     of intermediate code generation.
</li><li> But we aren't ready to do any non-toy example yet, you
have to get through some more lecture material on code generation for
control flow.
</li><li>  But consider the following example.
</li></ul>

<table border>
<tr><th>C<th>Python
<tr><td>
<pre>void write(int);
void main()
{
   int i;
   i = 5;
   i = i * i + 1;
   write(i);
}
</pre>
<td>
<pre>
   i : int
   i = 5
   i = i * i + 1
   print(i)
</pre>
</table>

For the code of the main() function, we want something like

<pre>proc main,0,32
	ASN	loc:0,const:5
	MUL	loc:8,loc:0,loc:0
	ADD	loc:16,loc:8,const:1
	ASN	loc:0,loc:16
	PARAM	loc:0
	CALL	write,1,loc:24
	RETURN
</pre>

How how do we get there?
<p>
  After lexical and syntax analysis,
  the syntax tree is
<p>
<img src="codegen_example.c.png">
<p>

The prerequisites for intermediate codegen also include semantic analysis
(symbol tables and typechecking), and we need to simulate
that, or present it as already accomplished, in order for
the actual codegen tree traversal to make sense. In particular, for codegen
we need .type and .addr, which for variables come from the symbol table.



<!--
<h3> Run Time Type Information </h3>

Some languages would need the type information around at runtime; for
example, dynamic object-oriented languages.  Its almost the case that one
just writes the type information, or symbol table information that includes
type information, into the generated code in this case, but perhaps one
wants to attach it to the actual values held at runtime.

<pre>
struct descrip {
   short type;
   short size;
   union {
      char *string;
      int ival;
      float rval;
      struct descrip *array;
      /* ... for other types */
      } value;
   };
</pre>
-->

<!--<h3> Old Mailbag </h3>

<dl>
<dt> the following is legal in Go. 
<pre>var x int
var y float64
x, y = 5, 10.4
</pre>

Are they allowed to have different types in the
declaration at once such as this having both int and float64?

</dt><dd> I think we've said that "multiple assignment" was not in our
language. The only
possible waffle I've done was about reading input, because the most
fundamental functions for reading input in Go require multiple assignment
syntax.

</dd></dl>

<h3> Reading input in VGo </h3>

Based on current information about the alternatives, I think we
want to support fmt.Scanln().  That means that there is exactly
one kind of pointer we should allow in VGo.

<p>
Options were:

</p><ol>
<li> Use the blank identifier and introduce a package bufio with a NewReader
that returns a predefined type *Reader and a package os with Stdin.
Support a very limited multiple
assignment in order to accomodate ReadString(), which returns both a string
and a failure.
<pre>var reader *bufio.Reader
reader = bufio.NewReader(os.Stdin)
text, _ = reader.ReadString('\n')
</pre>
Note that if I had this class to do over again, I might just tell us to support
multiple assignment, since it is about the same logic (type tuples) as what
you have to do for parameter passing, anyhow.

</li><li> Use a pointer:
<pre>fmt.Scanln(&amp;text)
</pre>

</li><li> ... your better option here?
</li></ol>


While we are at it, how do you compare strings in Go?

<pre>if strings.Compare("exit", text) == 0 {
   ...
   }
</pre>
-->

<h3> Compute the Offset of Each Variable </h3>

<dl>
<dt> Add an address field to every symbol table entry.
</dt><dd> The address contains a region plus an offset in that region.
</dd><dt> No two variables may occupy the same memory at the same time.
</dt><dd> At the intermediate code level, do not bother to re-use memory.
     In optimization and then in final code, re-use will be a big thing.
</dd></dl>

<h3> Locals and Parameters are not Contiguous! </h3>

For each function you need either to manage two separate regions
for locals and for parameters, or else you need to track where
in that region the split between locals and parameters will be.
This may become more "interesting" if parameters are passed in registers.



<h3> Basic Blocks </h3>

A basic block is a sequence of 1+ instructions in which
there are no jumps into or out of the middle.  In the most extreme
case, every instruction is a basic block.  Start from that perspective
and then lump adjacent instructions together if nothing can come between
them.<p>

What are the basic blocks in the following 3-address code?
("read" is a 3-address code to read in an integer.)

</p><pre>	read x
	t1 = x &gt; 0
	if t1 == 0 goto L1
	fact = 1
	label L2
	t2 = fact * x
	fact = t2
	t3 = x - 1
	x = t3
	t4 = x == 0
	if t4 == 0 goto L2
	t5 = addr const:0
	param t5		; "%d\n"
	param fact
	call p,2
	label L1
	halt
</pre>


<h4> Discussion of Basic Blocks </h4>

<dl>
<dt> Basic blocks are often used in order to talk about
     specific types of optimizations.
</dt><dd> For example, there are optimizations that are only safe to do
     within a basic block, such as "instruction reordering for superscalar
     pipeline filling".
</dd><dt> So, why introduce basic blocks here?
</dt><dd> our next topic is intermediate code for control flow, which includes
     gotos and labels, so maybe we ought to start thinking in terms of
     basic blocks and flow graphs, not just linked lists of instructions.
</dd><dt> view every basic block as a hamburger
</dt><dd> it will be a lot easier to eat if you
     sandwich it inside a pair of labels:
<pre>	label START_OF_BLOCK_7031
	<em>...code for this basic block...</em>
	label END_OF_BLOCK_7031
</pre>
</dd><dt> the label sandwich lets you:
</dt><dd> <ul>
     <li> target any basic block as a control flow destination
     </li><li> skip over any basic block
     </li></ul>
      For example, for an if-then statement, you may need to jump to
      the beginning of the statement in the then-part...or you may need
      to jump over it, the choice depending on the outcome of a boolean.
</dd></dl>

Yeah, these lecture notes repeat themselves about the label sandwich, almost
immediately. That must be on purpose.


<h4> C Operators </h4>

In case you were fuzzy on the operators you need to support:

<table border=""><tbody><tr><th> Essential </th><th> Non-essential
</th></tr><tr><td> = += -= </td><td> *= /= %= &lt;&lt;= &gt;&gt;= &amp;= ^= |=
</td></tr><tr><td> + - * / % </td><td> &gt;&gt; &lt;&lt; ++ -- ^
</td></tr><tr><td> &amp;&amp; || ! </td><td> &amp; | ~
</td></tr><tr><td> &lt; &lt;= &gt; &gt;= == != </td><td> ternary x ? y : z
</td></tr><tr><td> expr[expr] x.y </td><td> &amp;x x-&gt;y *x
      </td>
    </tr>
    <!--<tr><td> x:=:y; d x; y d x; #x expr[i:j]
    </td></tr>-->
</tbody></table>

<!--Plus concatenation, which is invisible, but not unimportant.-->


</p>

</p><h3>Old Mailbag</h3>

<dl>
<!--<dt> How do I typecheck Go's <code>make(x)</code> function?
</dt><dd> Good catch: this is not a normal function, is it?  If I say
<pre>m = make(map[string]Vertex)
</pre>
I am constructing a map, and the argument is not a regular value at all --
it is a type. I suggest you treat make as a special case. You can verify
that the type is a map type. You can make the return type of make() be
whatever type was passed in as its argument.  To generate
code for it, we need a strategy.
</dd>
<dt> What string operations do we have to support?
</dt><dd> Strings are a built-in immutable type with subscript and len(s) built-in
     function.  Although I would really like to strings.Compare() and a few
     other items from the package strings...nope you do not have to do them.

</dd>
-->
<dt> Are we supporting comparisons of doubles with ==, !=, &lt;=, and &gt;=?
</dt><dd> Yes.

</dd><dt> Is it possible/legal to have variables of type void?
</dt><dd> No.
</dd>
<dt> Do we have to support NULL?  To what types of variable is it legal
     to assign a NULL?
<dd> CSE 113 probably does have explicit uses of NULL, which is
     a name for 0 that is introduced by what, &lt;stdio.h&gt;?
  Options:
  <ol>
    <li> ignore and hope I don't use it in tests
    <li> implement a C preprocessor, or a specialty preprocessor
    <li> handle it in the lexical analyzer, return it as a 0
    <li> insert it into the symbol table as some kind of global constant
    <li> ???
    </ol>
<!--
<dt> To what types of variable is it legal to assign 'nil'? 
</dt><dd> Reference types: list, tables and class instances can be nil.
     But you almost never have to say 'nil' in Go because variables
     all start with the value nil automatically.
</dd>
-->

<!--
<dt> When we are inputting multiple files for the compiler, should we be
resetting the global table or allowing for redeclarations of global
variables to carry over to the other files?  I noticed that this was the
first assignment in the specification that we should be treating all the
files as one with a very large name space and wanted to get clarification.

</dt><dd> I previously said in class that we would skip multi-file translation
for HW#3 and beyond, back before we understood that Go would
require a full separate pass to populate the symbol table.

If I had it to do over again, I would say: handle multiple files, and allow
redeclarations of packages, and leave the package main global symbol table
around across all specified files.  Not sure I want to change anything to be
harder at this point, only want to change things to be easier, so at the
moment as things stand, you do not have to handle multiple files.

</dd><dt> I can easily fix some of my HW#3 problems. Can I turn in HW#3 to try
     and grind a couple more points out of you?
</dt><dd> BBlearn will let you resubmit.
     If you lost catastrophic points, it is definitely worth resubmitting.
     If you only missed a few, I probably will assess a late fee that makes
     the resubmit mostly moot. Fix issues anyhow so you don't lose points
     on HW#4-6.
</dd>
-->
<dt> Do we need separate intermediate code instructions for floating point
     and for integer operations?
</dt><dd> Good question.  What do you think?
</dd>
</dl>

<h4>Intermediate Code for Control Flow </h4>

Code for control flow (if-then, switches, and loops) consists of
code to test conditions, and the use of goto instructions and
labels to route execution to the correct code.  Each chunk of code
that is executed together (no jumps into or out of it) is called
a <em>basic block</em>.  The basic blocks are nodes in a control flow graph,
where goto instructions, as well as falling through from one basic block
to another, are edges connecting basic blocks.
<p>

Depending on your source language's semantic rules for things like
"short-circuit" evaluation for boolean operators, the operators
like || and &amp;&amp; might be similar to + and * (non-short-circuit) or
they might be more like if-then code.
</p><p>

A general technique for implementing control flow code:
</p><ul>
<li> add new attributes to tree nodes to hold labels that denote the
possible targets of jumps.
</li><li>  The labels in question are sort of
analogous to FIRST and FOLLOW
</li><li>for any given list of instructions
corresponding to a given tree node,
add a .first attribute to the tree to hold the label for the beginning
of the list, and a <code>.follow</code> attribute to hold the label for the next
instruction that comes after the list of instructions.
</li><li>The .first attribute can be easily synthesized.
</li><li> The <code>.follow</code> attribute must be
inherited from a sibling.
</li></ul>


<p>
<font size="1"> <a name="34">lecture #34</a> began here</font>
</p>
<p>


<h3> Mailbag </h3>
<dl>
<dt> I am encountering a very interesting segfault when testing my hw.
     as seen in pic below.<br>
     <img src="valgrind1.png"><br>
 This bug only comes up with a 'char' declaration, otherwise it runs fine
 on an int or String of the same name.
 This 'char' decl for some reason parses fine by yydebug, however when
 populating the sym table, it is interpreted as a ClassDecl (pic2).
 <br>
 <img src="valgrind2.jpeg">
 <br>
 I have looked at my grammar and cannot figure out why this would
 happen or how I can figure out why this is happening. Any tips or
 ideas on what I might be missing here?
  <dd> Wow, thank you for this excellent question, and for the wonderful
    screenshots. The first screenshot tells us we are 12 levels deep in
    recursion at the TOD. But it doesn't give us the line numbers at all
    these levels. Are you compiling with -g on your gcc -c lines?  You should
    be. The second picture leaves us guessing. A wrong internal tree node
    could be the result of building the tree structure/shape wrong, or
    putting the wrong information into the tree. We might start by looking
    at your suspicious .y
    <!--<A href="j0gram-bug.y.html">j0gram-bug.y</A>--> file,
    but when you seek help by e-mail or appointment, I will probably
    need to see
    your flex file and/or the code that prints the symbol tables, in order
    to find this bug.
</dl>




<h3> If-Then and If-Then-Else </h3>

The labels have to actually be allocated and attached to instructions
at appropriate nodes in the tree corresponding to grammar production
rules that govern control flow.  An instruction in the middle of a
basic block need neither a first nor a follow.

<p>

<table border="">
<tbody><tr><th>Production</th><th>Semantic Rules
</th></tr><tr><td>IfThenStmt :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
     if '(' Expr ')' Stmt</td><td>Expr.onTrue = Stmt.first<br>
	Expr.onFalse = IfThenStmt.follow<br>
	Stmt.follow = IfThenStmt.follow<br>
      IfThenStmt.icode = (Expr.icode != null) ? Expr.icode<br>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                       : gen(BIF, Expr.onFalse, Expr.addr, con:0) <br>
      IfThenStmt.icode |||:= gen(LABEL, Expr.onTrue) ||| Stmt.icode
</td></tr><tr><td>IfThenElseStmt :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
     if '(' Expr ')' Stmt<sub>1</sub> else Stmt<sub>2</sub>
</td><td>Expr.onTrue = Stmt<sub>1</sub>.first<br>
    Expr.onFalse = Stmt<sub>2</sub>.first<br>
	Stmt<sub>1</sub>.follow = IfThenElseStmt.follow;<br>
	Stmt<sub>2</sub>.follow = IfThenElseStmt.follow;<br>
      IfThenElseStmt.icode = (Expr.icode != null) ? Expr.icode<br>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                       : gen(BIF, Expr.onFalse, Expr.addr, con:0)<br>
	IfThenElseStmt.icode |||:= gen(LABEL, Expr.onTrue) ||| Stmt<sub>1</sub>.icode |||<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            gen(GOTO, IfThenElseStmt.follow) ||| gen(LABEL, Expr.onFalse) ||| Stmt<sub>2</sub>.icode
</td></tr></tbody></table>


<!--
<h4> BASIC </h4>

As a student reported in class, Color BASIC supports statements in
the bodies of THEN and ELSE as an alternative to a line number to GOTO.
Indeed, it supports colon-separated lists of statements.<p>

This means the discussion in class about generating labels for the
starts and ends of then-parts and else-parts applies to BASIC, not
just C.<p>

BASIC also supports boolean AND, OR and NOT operators, and computes them
as integer (0 = FALSE, -1 = TRUE) but they are not short-circuit so the
handling of them is identical to (and simpler than) arithmetic operators
such as + and -.  Since we have not considered them up to now, and they
do not introduce interesting new challenges but instead are just handled
the same as required operators, Booleans are OPTIONAL EXTRA CREDIT for
your homework #4 and 5.  Don't bother with them unless everything else
in your assignment is finished.<p>
-->

</p><p>

</p>

<p>


<h3> Generating Code for Conditions </h3>

The big picture on code generation for control structures such
as if's and while's requires an understanding of how to generate code for
the boolean expressions that control these constructs.
<ul>
<li> Consider the inherited attributes such as E.true and E.false.
</li><li> These are the destination instruction labels that say where to
      go if the condition is true, or false, respectively.
</li><li> The parent statement creates or inherits (from its parent
     or sibling) these destination goto labels
</li><li> They have to get passed down into boolean subexpressions
</li><li> Options for inherited attributes:
<ul>
<li> Allocate them ahead of time and pass them down in
     an extra tree-traversal before code generation, <b>OR</b>
</li><li> Go back into E.icode afterwards and fill them in after the
     information becomes known! For
     that you will have to remember/store/track spots where such labels
     are missing. This implies more attributes and/or auxiliary structures.
</li></ul>
</li></ul>

<h4> Alternative Models of Control Flow </h4>

Different languages have different semantics for booleans.
<ul>
<li> Pascal and similar languages treat them similar to arithmetic operators.
<ul>
<li> allocate a temporary variable to store E.addr at each tree node
     where a new boolean value is computed.
</li><li> compute a true or a false result into an E.addr.
</li><li> The .icode of the statement using the result inserts, after the E.icode, a
     <code>gen(BNIF, E.addr, E.false)</code> to skip over a then-part
     for an if with no else, or <br>
     <code>gen(BIF, E.addr, E.true) ||| gen(GOTO, E.false)</code>
     for an if with an else.
</li></ul>
</li><li> C (and C++, and many others) specify "short-circuit"
evaluation in which operands are not evaluated once the answer to
the boolean result is known.
<ul>
<li> <b>add extra attributes</b> to keep track of code locations that are
     targets of jumps. The attributes store link lists of those instructions
     that are <em>targets to backpatch</em> once a destination label is known.
     Boolean expressions results evaluate to jump instructions and program
     counter values (where you get to in the code implies what the boolean
     expression results were).
</li><li> at each level you have a .true target and a .false target.
</li><li> naive version may have many unnecessary goto instructions and
      extra labels. This is OK in CSE 423. Optimizer can simplify.
</li></ul>
</li><li> Some languages have <em>both</em>
     short circuit and non-short-circuit boolean operators!
     (Can you name a language that has both?)
</li><li> Icon and Unicon define the machine
      instruction semantics to implicitly route
     control from expression failure to the appropriate location!  In
     order to do this one might
     <ul>
     <li> mark boundaries of code via "mark" and "unmark" sandwiches
<li> these define "statement" boundaries as well as "conditional expr"
boundaries. Arguably they might correlate to basic blocks.
<li> within each mark-unmark, failure triggers an implicit goto
     </li><li> system maintains a stack of these marked "expression frames"
     </li></ul>
</li></ul>
<p>

<h3> Ucode Control Flow Example </h3>
  
The following example illustrates how ucode does control flow.
<ul>
  <li>labels are fairly conventional
  <li>"failure" is used for testing conditionals
  <li>rather different than conventional machines.
  <li>"mark" and "unmark" around basic blocks
</ul>
By the way, <A href="http://unicon.org/book/ib.pdf">the Implementation
Compendium</A> explains a lot more than you need to know; see Chapter 9
(Expression Evaluation) for example.

<pre>
  if x < 10 then write("small")
</pre>

generates the following ucode:

<pre>
	mark	L1	# if anything fails go to L1
	mark0		# push a "zero failure IPC" expression frame
	pnull		# push slot for a result
	var	0	# push x
	int	0	# push 10, the const in slot 0
	numlt		# numeric less than
	unmark		# bound the condition; no backtracking
	var	1	# push write
	str	1	# push "small", string constant in slot 1
	invoke	1	# call write with 1 param
	unmark		# bound the expression; no backtracking
lab L1
</pre>

mark-unmark defines a "bounded-expression". Inside, failure results in
a goto.  mark0-unmark defines a nested bounded-expression; inside, failure
results in going where the enclosing expression says to go.

<p>

Compare that with the following if-then-else. Failure in the "if" condition
takes you to L2. Both then-part and else-part end with L3, which unmarks
the "mark L1" for the whole expression.

<pre>
	mark	L1	# if anything fails go to L1
	mark	L2	# if anything fails go to L2
	pnull		# push slot for a result
	var	0	# push x
	int	0	# push 10, the const in slot 0
	numlt		# numeric less than
	unmark		# bound the condition; no backtracking
	var	1	# push write
	str	1	# push "small", string constant in slot 1
	invoke	1	# call write with 1 param
	goto	L3	# skip over else-part
lab L2
	var	1	# push write
	str	2	# push string constant in slot 2
	invoke	1	# call write with 1 param
lab L3
	unmark		# bound the expression; no backtracking
lab L1
</pre>


<h3> Grade Jitters? </h3>

<dl>
<dd> Canvas is certainly not a viable measuring stick for your grade.
     Your measuring sticks
     are your midterm grade, graded HWs, whether you are making regular
     progress, and whether you are seeking help.
<dt> If you are struggling in this class, that is normal and to a certain
     degree, healthy.
<dd> The goal is for <em>everyone</em> to get xp and levels out of the course
     proportional to what you put in. Even the smartest persons in the class.
<dd> Get as far as you can by end of semester.
</dl>


<h3> Old Mailbag </h3>

<dl>
<dt> 
For the current HW we are doing intermediate code
generation. I sorta understand that we are supposed to get label points
added at key places in our tree as semantic properties for the next
step. What I do not understand is what I will be doing in more detail.
What should this be looking like.

<dd> Tree traversals that compute more attributes.
     A lot of small do-able pieces of work that will be combined.
     Steps to intermediate code generation include:
<ul>
<li> Before you generate any code, implement and test the building blocks:
<ul>
<li> Define structs for address (region and offset) and for three-address
     intermediate code instructions.
<li> Build a linked list data type for lists of three-address instructions.
<li> Write a gen() function to create a linked list of length one, containing
     a single 3-address instruction
<li> Write a copycode(L) function to copy a linked list.
<li> Write a concatenate function concat(L1, L2) that builds
     a new linked list that consists of a copy of L1 followed by L2.
<li> Write a printcode(L) function that prints a list of code readably.
<li> Build a counter and a genlabel() function for generating labels
<li> Extend your symbol tables so that they track sizes of variables
     inserted into them, and can report how many bytes the whole table
     will need.
</li></ul>
</li><li> straight line code
<ul>
<li> Assign a .addr for all treenodes that represent anything with a value
</li><li> Allocate temporary variables for all operators/calls.
</li><li> Probably need to extend your tree printer so you can see/debug these.
</li><li> Generate linked lists of intermediate code instructions for straight
     line expressions and statements, with no control flow.
</li><li>     Generate header/ender pseudoinstructions for procedure main().
</li></ul>
</li><li> control flow
<ul>
<li> Allocate LABEL #'s to all treenodes that can be targets of goto
     instructions
</li><li> Push LABEL #'s around to where they are needed, through inherited
     and/or synthesized attributes via one or more tree traversals
</li><li> Need to extend your tree printer so you can see/debug these.
</li><li> Generate linked lists of intermediate code for ifs and loops.
</li><li> Generate linked lists of intermediate code for call (no params) and void return
</li><li> Generate linked lists of intermediate code for return values, and parameters.
</ul>
</ul>



<dt> Traditionally, % only works on integer arguments.
Do I need to ensure that, or do I need to worry
about modulus for other types?

</dt><dd> % requires integer arguments.  You need to type check it.

</dd>
<!--<dt>For structs <!--class <em>definitions</em>-->, how do we size them?
</dt><dd>The size of the <em>instances</em> will be the sum of
the sizes of the member variables (rounding up each variable
to the next 8 byte (machine word) boundary), allocated out of the heap.
The type (struct|class) itself occupies no space.  Variables that hold
references to instances are sized as pointers
(8 bytes) in the global or local regions.
</dd>-->
<dt> Do I need to give classes a region/offset before I create an instance?
My thought is to give them a size, but only assign a region/offset to an
instance of the class.  Does this sound right?

</dt><dd> Sure: size yes, location no. In a language like C, you can 
    assign instances' region:offset when a variable of a type is inserted
    into a symbol table for a global or local region.  In a language like
    Java, Python, or Unicon, all instances
    are created from the heap at runtime; at compile time you only give
    the region/offset of the object reference; the address of the actual
    object in the heap is not known until runtime.

</dd>
<!--
<dt> Does the size of a method include the size of the private
members that are declared inside the class but used inside the function?

</dt><dd> VGo is not doing methods.  But if we were...
private members are allocated/sized in the instances, not the functions.
The member functions that use
class variables must do so using byte offsets relative to the beginning of an
object reference, and these byte offsets are consistent, for a given instance,
and do not vary depending on which function is called.

</dd>
-->
<dt>
How do I do float constants?
</dt>
<dd>
Most CPUs do not have float immediate instructions.  We need an actual
constant region; we need that for string constants too. Depending on your
target code, you might create a region
for each constant type, perhaps R_FLOAT and R_STRING, with byte offsets
starting at word
boundaries. With other targets such as Unicon ucode, you probably should
just do one combined region, perhaps R_RODATA.
</dd></dl>



</p><h4> Boolean Expression Example</h4>

<pre>a&lt;b || c&lt;d &amp;&amp; e&lt;f
</pre>

Compare three intermediate code solutions given below.
<ul>
<li> The left uses the intermediate code presented earlier.
</li><li> The middle uses some new three address instructions. Is it cheating?
</li><li> Both left and middle end with E.addr in t<sub>5</sub> which must
     then be tested/used in some conditional branch to do control flow.
</li><li> The right side uses short-circuits as per C/C++
</li></ul>
<p>

<table border="">
<tbody><tr><th> conditional branches </th><th> relop instructions </th><th> short circuit
</th></tr><tr><td>
<pre>100:	if a&lt;b goto 103
	t<sub>1</sub> = 0
	goto 104
103:	t<sub>1</sub> = 1
104:	if c&lt;d goto 107
	t<sub>2</sub> = 0
	goto 108
107:	t<sub>2</sub> = 1
108:	if e&lt;f goto 111
	t<sub>3</sub> = 0
	goto 112
111:	t<sub>3</sub> = 1
112:	t<sub>4</sub> = t<sub>2</sub> AND t<sub>3</sub>
	t<sub>5</sub> = t<sub>1</sub> OR t<sub>4</sub>
</pre>
</td><td>
<pre>t<sub>1</sub> := a LT b
t<sub>2</sub> := c LT d
t<sub>3</sub> := e LT f
t<sub>4</sub> := t<sub>2</sub> AND t<sub>3</sub>
t<sub>5</sub> := t<sub>1</sub> OR t<sub>4</sub>
</pre>
</td><td>
<pre>    if a&lt;b goto E.true
    if c&lt;d goto L1
    goto E.false
L1: if e&lt;f goto E.true
    goto E.false
</pre>
</td></tr></tbody></table>

</p><p>
Short circuit semantics is short, fast, and can be used to play parlor tricks.

</p>


</p><p>
<font size="1"> <a name="35">lecture #35</a> began here</font>
</p><p>

<h3> Announcements </h3>

<ul>
<li> Final grades for graduating seniors are due (from me to NMT) at
  noon May 10 with no extensions possible.  If you are not
  graduating and want a grade extension, let me know.
<!--
<li> I will post a final exam (take-home exam) on Canvas after class on
     May 4. It will be due Monday May 9, 11:59pm.
<li> <A href="hw7.html">HW#7</A> will be due Sunday May 8, 11:59pm.  Given
     the shortness of time remaining, I will be extremely pragmatic about
     what final code I can expect.
-->
</ul>
  

<p>
Q: do we know enough now to write the code generation rules for booleans?
</p><p>

<table border="">
<tbody><tr>
<th>Production</th><th> Semantic Rules
</th></tr><tr>
<td> AndExpr :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        AndExpr<sub>1</sub> &amp;&amp; EqExpr
</td><td>
<pre> EqExpr.first = genlabel();
 AndExpr<sub>1</sub>.onTrue = EqExpr.first;
 AndExpr<sub>1</sub>.onFalse = AndExpr.onFalse;
 EqExpr.onTrue = AndExpr.onTrue;
 EqExpr.onFalse = AndExpr.onFalse;
 AndExpr.icode = AndExpr<sub>1</sub>.icode ||| gen(LABEL, EqExpr.first) ||| EqExpr.icode;
</pre>
</td></tr><tr>
<td> OrExpr :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
       OrExpr<sub>1</sub> || AndExpr
</td><td>
<pre> AndExpr.first = genlabel();
 OrExpr<sub>1</sub>.onTrue = OrExpr.onTrue;
 OrExpr<sub>1</sub>.onFalse = AndExpr.first;
 AndExpr.onTrue = OrExpr.onTrue;
 AndExpr.onFalse = OrExpr.onFalse;
 OrExpr.icode = OrExpr<sub>1</sub>.icode ||| gen(LABEL, AndExpr.first) ||| AndExpr.icode;
</pre>
</td></tr><tr>
<td> UnaryExpr : ! UnaryExpr<sub>1</sub>
</td><td> 
<pre>UnaryExpr<sub>1</sub>.onTrue = UnaryExpr.onFalse
UnaryExpr<sub>1</sub>.onFalse = UnaryExpr.onTrue
UnaryExpr.icode = UnaryExpr1.icode
</pre>
</td></tr>
</tbody></table>

</p><p>

Hints: parent fill's out childrens' inherited attributes...



<h3> Intermediate Code for Relational Operators </h3>

<ul>
<li> intermediate code can have either
     relational operators in conditional branch statements, or
     relationals as standalone instructions that compute a
     boolean result.
</li><li> operands to relationals must be valid (numeric?) type.
</li><li> inherited attributes get used here, not pushed down further
     to the operands
</li><li> You could analyze
     whether to generate gotos to E.true/E.false or instead to
     generate values that compute a boolean result. Maybe surrounding
     code only sets your E.true/E.false to non-NULL if result
     should be expressed as gotos?
</li><li> You might instead compute a result AND generate gotos. The gotos
     might get optimized out if they are not needed.
</li></ul>

<p>

<table border="">
<tbody><tr><th>C syntax</th><th>gotos</th><th> bool value </th><th> both ?
</th></tr><tr><td>E-&gt; E<sub>1</sub> &lt; E<sub>2</sub>
</td><td>
E.icode = E<sub>1</sub>.icode || E<sub>2</sub>.icode ||<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(BLT, E<sub>1</sub>.addr, E<sub>2</sub>.addr, E.true) || <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(GOTO, E.false)
</td><td>
E.addr = genlocal() <br>
E.icode = E<sub>1</sub>.icode || E<sub>2</sub>.icode ||<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(LT, E.addr, E<sub>1</sub>.addr, E<sub>2</sub>.addr)
</td><td>
E.addr = genlocal() <br>
E.icode = E<sub>1</sub>.icode || E<sub>2</sub>.icode ||<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(LT, E.addr, E<sub>1</sub>.addr, E<sub>2</sub>.addr) || <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(BIF, E.addr, E.true) || <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           gen(GOTO, E.false)

</td></tr></tbody></table>

</p><h3> Intermediate Code for Loops </h3>

<h4> While Loops </h4>

A while loop has semantic attributes and rules for intermediate code that
are very similar to an if-statement. There is almost only one difference,
the goto back to the beginning. Is there anything else missing or wrong here?

</p><p>
Finishing touches: what attributes and/or labels does this plan
need in order to support <code>break</code> and <code>continue</code>
statements?

</p><p>

</p>

<h3> Ucode While Loop Example </h3>

The Unicon code
<pre>
  while i < 10 do { write("small"); i+:= 1 }
</pre>

Turns into the following.

<pre>
	mark	L2	# if anything fails go to L2 (whole loop expr)
lab L3
	mark0		# push a "zero failure IPC" expression frame
	pnull		# push slot for a result
	var	0	# push x
	int	1	# push 10, the const in slot 1
	numlt		# numeric less than
	unmark		# bound the condition; no backtracking
	mark	L3	# if anything fails go to L3
	mark	L6	# if anything fails go to L6
	var	1	# push write
	str	2	# push string constant in slot 2
	invoke	1	# call write with 1 param
	unmark		# bound the write expression; no backtracking
lab L6
	pnull		# push slot for a result
	var	0	# push i
	dup		# push i
	int	0	# push 1, the const in slot 0
	plus		# add
	asgn		# store top of stack into var above it on stack
lab L4			# not used ?!
	unmark		# bound the increment expr; no backtracking
	goto	L3	# explicit goto top of loop
lab L5			# not used ?!
	unmark
lab L2
</pre>





<h4> For Loops </h4>

For-loops can be trivially transformed into while loops, so they pose just
about no new code generation issues.  Notice that only some expressions
need .true/.false: the ones used as conditionals.

<p>

<table border="">
<tbody><tr><th>Production</th><th>Semantic Rules
</th></tr><tr><td>WhileStmt : while '(' Expr ')' Stmt</td><td>Expr.onTrue = genlabel();<br>
					Expr.first = genlabel();<br>
					Expr.false = WhileStmt.follow;<br>
					Stmt.follow = Expr.first;<br>
					WhileStmt.icode = gen(LABEL, Expr.first) |||<br>&nbsp;&nbsp;&nbsp;Expr.icode ||| gen(LABEL, Expr.true) |||<br>
					&nbsp;&nbsp;&nbsp;Stmt.icode |||
					gen(GOTO, Expr.first)
  </td></tr>
<tr><td>ForStmt : for( ForInit; Expr; ForUpdate ) <br>
        &nbsp;&nbsp;&nbsp; Stmt
    <br><br>a.k.a.
    <br><br>
ForInit; <br>
while (Expr) { <br>
   &nbsp;&nbsp;&nbsp;
   Stmt <br>
   &nbsp;&nbsp;&nbsp;
   ForUpdate <br>
}
</td><td>		Expr.true = genlabel();<br>
		Expr.first = genlabel();<br>
		Expr.false = S.follow;<br>
		Stmt.follow = ForUpdate.first;<br>
		S.icode = ForInit.icode ||| <br> 
			&nbsp;&nbsp;&nbsp;gen(LABEL, Expr.first) |||<br>
			&nbsp;&nbsp;&nbsp;Expr.icode ||| gen(LABEL, Expr.true) |||<br>
			&nbsp;&nbsp;&nbsp;Stmt.icode ||| <br>
			&nbsp;&nbsp;&nbsp;ForUpdate.icode ||| <br>
			&nbsp;&nbsp;&nbsp;gen(GOTO, Expr.first)
</td></tr></tbody></table>
</p><p>

Again: what attributes and/or labels does this plan
need in order to support <code>break</code> and <code>continue</code>
statements?



<!--
<h4> BASIC FOR Loops </h4>

Is the same true for a BASIC FOR loop?  If not,
So how is a FOR loop different from C while loop?
Well, for one thing, there are two separate statements (FOR and NEXT)
that are matched together only by the variable name that controls the loop.

<p>
Example BASIC FOR-loop:
<pre>
10 FOR I = 1 to 10
20 PRINT I
30 NEXT I
</pre>

One possible 3-address code equivalent for this is:
<pre>
L10:				; line 10
	asn G:24 C:1		; I = 1
L10A:				; "end of line 10" == loop test
	bgr G:24 C:10 L30A	; How did we decide to go to end of 30?
L20:				; line 20
	param G:24		; push I onto stack for print
	call  print,1		; call print
L30:				; line 30
	add G:24 G:24 C:1	; I = I + 1
	goto L10A		; go to end of line 10
L30A:
	...
</pre>

There is an obvious question, which is how do the FOR and the NEXT find
each other?  Minimally, one might be looking at writing tree traversal
code to match up FOR and NEXT statements.
-->
<!--
<p>
<h3> FOR loops, continued </h3>

Last time we considered generating code for simple FOR-loops.
In reality FOR loops are stickier than this; FOR really isn't like
a C-style for- or while-loop.
There can be several NEXT statements corresponding to a given
FOR statement.  A FOR statement cannot determine a destination
to which to branch when the loop is finished; it never fails.
If you execute the following lines, BASIC prints a "2":
<pre>
10 FOR I = 2 TO 1
20 PRINT I
30 NEXT I
</pre>

Instead, a NEXT statement must not only do the increment, but also
test the loop's exit condition, and either branch back up to the
top of the loop (if the loop is not finished) or fall through.
In order to communicate between a FOR and any of several NEXT's,
use <em>variables</em>.  As I see it, you need about two variables
to do FOR loops: one variable to store: what code region address
to goto to jump back to do the next iteration of the loop, and
one to store the upper limit of the loop (for STEP versions of FOR
you need a third variable to hold the increment).  With these two
variables, the simple FOR loop looks more like:
<p>
<pre>
L10:				; line 10
	asn G:24 C:1		; I = 1
	asn G:28 L10A
	asn G:32 C:10
	asn G:36 C:1
L10A:				; "end of line 10" == place for NEXT to go
L20:				; line 20
	param G:24		; push I onto stack for print
	call  print,1		; call print
L30:				; line 30
	add G:24 G:24 G:36	; I = I + 1
	bleq G:24 G:32 G:28	; if i <= 10 goto L10A
L30A:
	...
</pre>


<!--
<h4> Note on BASIC's INPUT statement </h4>

By the way, Color BASIC's INPUT statement
has a convenient, optional, PRINT-like prompt clause.  Instead of
<pre>
10 PRINT "Enter your Mastercard Number: "
20 INPUT M$
</pre>
you can write:
<pre>
10 INPUT "Enter your Mastercard Number: "; M$
</pre>
This is shown in Chapter 11 of the Color BASIC book.
-->


<h3> Code generation for Switch Statements </h3>

Consider the C switch statement
<pre>switch(e) of {
   case v<sub>1</sub>:
      S<sub>1</sub>;
   case v<sub>2</sub>:
      S<sub>2</sub>;
   ...
   case v<sub>n-1</sub>:
      S<sub>n-1</sub>;
   default:
      S<sub>n</sub>;
}
</pre>

The intermediate code for this might look like:

<table><tbody><tr><td>
<pre>	<em>code for e, storing result in temp var t</em>
	goto Test
L<sub>1</sub>:
	<em>code for S<sub>1</sub>
L<sub>2</sub>:
	<em>code for S<sub>2</sub>
	...
L<sub>n-1</sub>:
	<em>code for S<sub>n-1</sub>
L<sub>n</sub>:
	<em>code for S<sub>n</sub>
	goto Next
Test:
	if t=v<sub>1</sub> goto L<sub>1</sub>
	if t=v<sub>2</sub> goto L<sub>2</sub>
	...
	if t=v<sub>n-1</sub> goto L<sub>n-1</sub>
	goto L<sub>n</sub>
Next:
</em></em></em></em></pre><em><em><em>
</em></em></em></td><td>
Note that C "break" statements<br>
are implemented in S<sub>1</sub>-S<sub>n</sub><br>
by "goto Next" instructions.
<br><br><br><br><br><br><br><br><br><br>
</td></tr></tbody></table>


<!--
<h3> Brief Followup on Boolean-Integer Compatibility </h3>

Professor Soule's text <em>almost</em> cleanly separates bools and integers,
but not quite: he uses an int variable to hold a boolean value in one
example, and then uses
<pre>
   if (i) ...
</pre>
and suggests in a homework
exercise a feature that would extend it to
<pre>
if (i &amp;&amp; anotherbooleancondition...) ...
</pre>
-->


<font size="1"> <a name="36">lecture #36</a> began here</font>

<h3> Final Grades and Projects </h3>

<ul>
<li> Final project due May 3
<li> Resubmission and regrading capabilities for HW6 will be reduced/limited
<li> In many years I have invited compilers students to demo their work for
  me during finals week in order to ensure appropriate credit is given,
  but that seems not possible this year due to scheduling deadlines.  So:
<ul>
<li> You should thoroughly test that your work unpacks, builds and runs
      and passes your tests prior to submission
<li> I will give them a quick/preliminary test and try to identify
     flagrant issues/omissions by May 5. If I accept any resubmits, they will
     be limited to trivial fixes necessary to see/grade your work, turned
     in by May 6
<li> You can include tests, and a "make test" command that demonstrates as
     much as you got working: semantic analysis, code generation, execution...
</ul>
<li> Some of you have asked to see your pre-final grades at this point.
  I worked a lot on grading this last weekend and will work on it more this
  week to try and give you a better picture.
</ul>



<h3> Name Mangling </h3>

<ul>
<li> names in PunY source code get mapped onto names in target code.
<li> global names may conflict with runtime library names
<li> example: main() in PunY vs. main() in Unicon
</ul>

<table border><tr><th>Python<th>Unicon (broken)<th>Unicon (mangled)
<tr><td>
<pre>
x = 5
def main():
   print("x ", x)
   print("y ", y)
y = 12
main()
</pre>
<td>
<pre>
global x, y
procedure main()
  write("x ", x)
  write("y ", y)
end
procedure main()
  x := 5
  y := 12
  main()
end
</pre>
<td>
<pre>
global puny_x, puny_y
procedure puny_main()
  write("x ", puny_x)
  write("y ", puny_y)
end
procedure main()
  puny_x := 5
  puny_y := 12
  puny_main()
end
</pre>
</table>

So, prefix all globals with a prefix "_" or "puny_" or whatever.


<h3> Some Obvious Differences Between Python and Unicon </h3>

These might be relevant as you try to generate code

In Unicon:
<ul>
<li> global declarations are always outside function/procedure bodies.
<li> local declarations are always at the top of functions, before
     the executable code begins
<li> indices/subscripts are 1-based, not 0-based. Affects
<li> no executable code can be outside the procedures
<li> there are no tuples, nor iterators
<li> Assignment is :=
<li> Indentation is not in the grammar.
     Curly braces bound statement sequences { }
<li> Unicon has no boolean type!
<li> 3 &lt; x &gt; 12 works

</ul>

<h3> Some Obvious Similarities Between Python and Unicon </h3>

<ul>
<li> Python strings resemble Unicon strings.
<li> Python dictionaries resemble Unicon tables.
<li> Python lists resemble Unicon lists
</ul>


<h3> Intermediate Code Generation Examples </h3>

Consider the following small program.  It would be fair game as input
to your compiler project.  In order to show blow-by-blow what the code
generation process looks like, we need to construct the syntax tree and
do the semantic analysis steps.
<p>

<table><tbody><tr><th>C</th><th>Go<th>Python
</th></tr><tr><td>
<pre>void print(int i);
void main()
{
   int i;
   i = 0;
   while (i &lt; 20)
      i = i * i + 1;
   print(i);
}
</pre>
</td><td>
<pre>package main
import "fmt"
func main() {
  var i int
  i = 0
  for i &lt; 20 {
    i = i * i + 1
    }
  fmt.Println(i)
}
</pre>
</td>
<td>
<pre>
def main():
  i : int
  i = 0
  while i < 10:
    i = i * i + 1
  print(i)
</pre>
</tr></tbody></table>
</p><p>

</p><p>

<img src="codegen.png" width="900" height="600">

</p><p>

We proceeded with a discussion of how to build the .icode fields.
One thing that got said was: .icode fields get built via a post-order
traversal (synthetised attribute) but .true, .false etc. are inherited
and may require a previous pass through the tree, or a pre-order
traversal.  If you are trying to do both in one pass it might look like
the following.

</p><p>

</p><h3>Old Mailbag </h3>

<dl>
<dt> Are you calling functions like they are variables???
</dt><dd> No of course not. And you aren't supposed to be allowing that either.
</dd><dt> Is there any chance I can resubmit for extra points from hw4?
</dt><dd> Yeah, sure.
</dd>
<--
<dt> Looking at Test case 5 you are trying to Println a float value but we
are not allowed to overload. So, should Println accept float or a string to
avoid overloading?
<dd> So, we danced around the question of how to print numbers before.
     Go seems to accept fmt.Println(i) for i being numberic, but
     I am trying to avoid making you implement type casts/conversions,
     and trying to avoid making you implement function overloading.
-->
</dl>

<!--
<h3> itoa(i) and ftoa(f) in VGo </h3>

<table border="">
<tbody><tr><th>itoa(i int) string </th><th> ftoa(f float64) string
</th></tr><tr><td>
<pre>func itoa(i int) string {
if i == 0 { return "0"}
if i == 1 { return "1"}
if i == 2 { return "2"}
if i == 3 { return "3"}
if i == 4 { return "4"}
if i == 5 { return "5"}
if i == 6 { return "6"}
if i == 7 { return "7"}
if i == 8 { return "8"}
if i == 9 { return "9"}
...
}
</pre>
</td><td>
<pre>func ftoa(f float64) string {
??
}
</pre>
</td></tr></tbody></table>
-->



<h3> A Code Generation Function </h3>

<pre>void codegen(struct tree *t)
{
   // pre-order stuff, e.g. label generation
   switch (t-&gt;prodrule) {
         ...
      case ITERATION_STMT: // inherited attributes for while loop
         // push an inherited attribute to child before visiting them
         t-&gt;child[2]-&gt;true = genlabel();
         break;
	 ...
      }
   // visit children
   for(i=0; i &lt; t-&gt;nkids; i++) codegen(t-&gt;child[0]);

   // post-order stuff, e.g. code generation
   switch (t-&gt;prodrule) {
         ...
      case CONDEXPR_2: // synthesized attribs for CondExpr: Expr &lt; Expr
         t-&gt;code = concat(
	        t-&gt;child[0]-&gt;code,
	        t-&gt;child[2]-&gt;code,
		gen(BLT, t-&gt;child[0]-&gt;place, t-&gt;child[2]-&gt;place, t-&gt;true),
		gen(GOTO, t-&gt;false)
		);
	 break;
      case ITERATION_STMT: // synthesized attributes for while loop
	 t-&gt;code = concat(
                    gen(LABEL, t-&gt;child[2]-&gt;first),
		    t-&gt;child[2]-&gt;code,
                    gen(LABEL, t-&gt;child[2]-&gt;true),
   		    t-&gt;child[4]-&gt;code,
		    gen(GOTO, t-&gt;child[2]-&gt;first));
	 break;
}
</pre>


<!--
<h3> Grammar Tweak: Casting and Implicit Type Conversion </h3>

<ul>
<li> you have been told that professor Soule's code examples do not include
      type casts, or at least, no implicit conversions.
<li> Maybe that's not quite true/correct.
<li> It is true that Soule's book uses implicit type conversion from int to
     double, <em>at least for the constant 0</em>.  He compares a double to
     0 (bad idea), and returns a 0 from a function that returns type double.
<li> Professor Soule's book also mentions implicit and explicit type
     conversion, including an example of the new-style cast syntax, int(d)
     for some double value.
<li> I had previously removed some of Sigala's grammar rules related to the
     new-style cast syntax due to reduce-reduce conflicts.
<li> I revised the reference 120gram.y to include new-style cast syntax for
     the scalar numeric built-in types.
<li> However, you are not required to do anything more with casts than is
     already stated in the 120++ Manual.
</ul>
-->


<!--
Here is an example BASIC program to compile:
<pre>
10	i = 0
20	IF i &gt;= 20 THEN 50
30	i = i * i + 1
40	GOTO 20
50	PRINT i
</pre>

This program corresponds to the following syntax tree, which a
successful homework #5 would build.  Note that it has a height of
approximately 10, and a maximum arity of approximately 4.  Also: your
exact tree might have more nodes, or slightly fewer; as long as the
information and general shape is there, such variations are not a problem.
<p>
<img src="syntree.jpg">
<em> A syntax tree, with attributes obtained from lexical and semantic
analysis, needs to be shown here.</em>
-->



The code for the boolean conditional expression controlling the while
loop is a list of length 1, containing the instruction t0 = i &lt; 20,
or more formally

<table>
<tbody><tr><th> gotos </th><th> bool value
</th></tr><tr><td>

<table border="">
<tbody><tr><th>opcode</th><th>dest</th><th>src1</th><th>src2</th></tr>
<tr><td>BLT</td><td>i</td><td>20</td><td>E.true</td></tr>
<tr><td>GOTO</td><td>E.false</td><td></td><td></td></tr>
</tbody></table>

</td><td>

<table border="">
<tbody><tr><th>opcode</th><th>dest</th><th>src1</th><th>src2</th></tr>
<tr><td>LT</td><td>t0</td><td>i</td><td>20</td></tr>
</tbody></table>
</td></tr></tbody></table>
<p>

The actual C representation of addresses dest, src1, and src2 is a

<table border=""><tbody><tr><td>region<br><hr>offset</td></tr></tbody></table> pair, so the
picture of this intermediate code instruction really looks something like this:

</p><p>

<table>
<tbody><tr><th>gotos</th><th>bool value
</th></tr><tr>
<td>
<table border="">
<tbody><tr><th>opcode</th><th>dest</th><th>src1</th><th>src2</th></tr>
<tr><td>BLT</td><td>local<br><hr>i.offset</td><td>const<br><hr>20</td><td>code<br><hr>(E.true's label#)</td></tr>
</tbody></table>

</td><td>
<table border="">
<tbody><tr><th>opcode</th><th>dest</th><th>src1</th><th>src2</th></tr>
<tr><td>LT</td><td>local<br><hr>t0.offset</td><td>local<br><hr>i.offset</td><td>const<br><hr>20</td></tr>
</tbody></table>
</td></tr></tbody></table>

</p><p>

Regions are expressed with a simple integer encoding like:
global=1, local=2, const=3.
Note that address values in all regions are offsets from the start of the
region, except for region "const", which
stores the actual value of a single integer as its offset.

</p><p>

<table border="">
<tbody><tr><th>opcode</th><th>dest</th><th>src1</th><th>src2</th></tr>
<tr><td>MUL</td><td>local<br><hr>t1.offset</td><td>local<br><hr>i.offset</td><td>local<br><hr>i.offset</td></tr>
</tbody></table>

</p><p>
The rest of class was spent elaborating on the linked list of instructions
for the preceding example.


</p><h3> <code>.first</code> and <code>.follow</code> for StmtList </h3>

<ul>
<li> As mentioned previously, attributes
     <code>.first</code> and <code>.follow</code>
     are an alternative to the "label sandwich" model of code generation
</li><li> <code>.first</code> holds a label denoting the first instruction to execute when
     control reaches a given subtree within a function body.
</li><li> <code>.first</code> is a synthesized attribute. Note that unlike
     FIRST(a), there is a unique and deterministic label. But worry-warts
     might want to ask if a given subtree can have epsilon code.
</li><li> <code>.follow</code> holds a label denoting the instruction that comes after
     a given subtree within a function body.
</li><li> <code>.follow</code> would be an inherited attribute, obtained from
     some ancestor's sibling.
</li></ul>

<p>

Suppose you have grammar rules

</p><pre>FuncBody : '{' StatementList '}' ;
StatementList : StatementList Statement ;
StatementList :  ;
</pre>

What kind of <code>.first</code> and <code>.follow</code> values can we
develop and pass in to children from these rules?

<br>
<br>
<br>
<br>

<table border="">
<tbody><tr><th> Syntax </th><th> Attribute Manipulations
</th></tr><tr><td><pre>FuncBody : '{' StatementList '}'</pre>
    </td><td><pre>StatementList.follow = genlabel();
FuncBody.icode = StatementList.icode ||
                 gen(LABEL,StatementList.follow) ||
		 gen(RETURN)</pre>
</td></tr><tr><td><pre>StatementList<sub>1</sub>: StatementList<sub>2</sub> Statement</pre>
    </td><td><pre>StatementList<sub>2</sub>.follow = Statement.first;
Statement.follow = StatementList<sub>1</sub>.follow
StatementList<sub>1</sub>.icode = StatementList<sub>2</sub>.icode || Statement.icode</pre>
</td></tr><tr><td><pre>StatementList : ;</pre>
    </td><td><pre>/* no need for a StatementList.follow */
StatementList.first = genlabel()
StatementList.icode = gen(LABEL, StatementList.first) || gen(NOOP)</pre>
</td></tr></tbody></table>

<!-- Using this same representation, the next instruction found by bottom-up
traversal of the tree is -->



<h3>More Code Generation Examples</h3>

You should implement your code generation one operator at a time,
simplest expressions first.

<p>

Zero operators.</p><p>

</p><pre>if (x) S
</pre>
translates into

<pre>if x != 0 goto L1
goto L2
label L1
...code for S
label L2
</pre>


or if you are being fancy

<pre>if x == 0 goto L1
...code for S
label L1
</pre>
I may do this without comment in later examples, to keep them short.
<p>

One relational operator.</p><p>

</p><pre>if (a &lt; b) S
</pre>
translates into

<pre>if a &gt;= b goto L1
...code for S
label L1
</pre>

One boolean operator.<p>

</p><pre>if (a &lt; b  &amp;&amp;  c &gt; d) S
</pre>
translates into

<pre>if (a &lt; b)
   if (c &gt; d)
      ...code for S
</pre>
which if we expand it

<pre>if a &gt;= b goto L1
if c &lt;= d goto L2
...code for S
label L2
label L1
</pre>

by mechanical means, we may wind up with lots of labels for the same
target (instruction), this is OK.<p>



Beware the following. A lazy code generator doing short-circuits might be
tempted to say that


</p><pre>if (a &lt; b  ||  c &gt; d) S
</pre>
translates into

<pre>if (a &lt; b) ...code for S
if (c &gt; d) ...code for S
</pre>
but its unacceptable to duplicate the code for S!  It might be huge!
Generate labels for boolean-true=yes-we-do-this-thing, not just for
boolean-false=we-skip-this-thing.

<pre>if a &lt; b goto L1
if c &gt; d goto L2
goto L3
label L2
label L1
...code for S
label L3
</pre>

<p>
<!--
<dl>
<dt> Does VGo support this statement : gg=Vertex{15,199}?
</dt><dd> Good question. The VGo references says no map literals,
     but indicates by example that object literals are supported.
     It also states that the named field initializer syntax
     Vertex{Y: 1} is not supported.

</dd><dt> The VGo reference does not have any sizes for types. What are these
     sizes or where can I find this information?
</dt><dd> Sizes have been discussed in lectures and some information are in
     lecture notes.  VGo also defers to Go on all matters unspecified in
     the VGo reference, so you could use Go documentation for sizes.
     Here is what I remember off-hand
<table border="">
<tbody><tr><th>type</th><th>size (bytes)
</th></tr><tr><td>bool</td><td> 1
</td></tr><tr><td>rune</td><td> 4
</td></tr><tr><td>int </td><td> 8
</td></tr><tr><td>float64 </td><td> 8

</td></tr><tr><th>Reference Types </th><th> variable is size 8 pointer, thing pointed at is:
</th></tr><tr><td>array[n] </td><td> n * elementsize, round up to a multiple of 8
</td></tr><tr><td>struct  </td><td> sum of field sizes, pad field sizes if needed
                     to a multiple of whatever field size comes next.
</td></tr><tr><td>func    </td><td> assembler will take care of code sizes of functions
</td></tr></tbody></table>

OK, now what have I left out?
</dd>
</dl>
-->


<h3> Object-Oriented Changes to Above Examples </h3>

The previous examples were assuming a C-like language semantics.
For an object-oriented language, the generated code for these examples
is more interesting.  For example, the semantics of
<pre>if (x) S
</pre>
if x is an object, may be defaulted to be equivalent to
<pre>if (x != NULL) S
</pre>
or more generally, the different types may have (hardwired, or overrideable)
conversion rules to convert them to booleans for use in tests, such as
<pre>tempvar := x.as_boolean()
if (tempvar) S
</pre>

</p><p>

</p><h3> Old Mailbag </h3>

<dl>
<dt> Do we need to specify the RET instruction at the end of a function
 or does the END instruction imply that the function returns?
</dt><dd> I think of END in three-address code as a non-instruction
     (pseudo instruction) that marks the end of a procedure. So
     you should have a RET in front of it.  But really, you are
     allowed to define END's semantics to also do a RET; you could
     call it REND.

</dd><dt> If we have nothing to return, can we just say RET with no parameter or
must the parameter x always be there, i.e. RET x?

</dt><dd> I would accept a RET with no operand. You are allowed to define
new opcodes in intermediate code. Native assemblers often have several
variants of a given instruction -- same mnemonic, different opcodes for a
related family of instructions.  But in that case our final codegen
would have to have a way to tell which version of RET is in use. Either
a way of marking unused addresses, or a separate opcode such as RET0.

</dd><dt> Can you give me an example of when to use the GLOBAL and LOCAL
declaration instructions?

</dt><dd> These are pseudo-instructions, not instructions.
Globals are listed as required; at the minimum, if your program has any
global variables you must have at least one GLOBAL declaration to give the
size of (the sum of) the global variables. You can do one big GLOBAL and
reference variables as offsets, or you can declare many GLOBAL regions,
effectively defining one named region for each variable and therefore
rendering the offsets moot.

<p>
A LOCAL pseudo-instruction is listed as optional and advisory; think of
it as debugging symbol information, or as an assist to the reader of your
generated assembler source.

</p></dd>
<!--
<dt> What sort of type checking is needed for a constructor?
     (in C++/Java it would be <code>new</code>)?
</dt><dd> VGo is a special subset of Go. There is always a default constructor
     with all zeroes, and a non-default constructor with all fields' values
     specified in order, which should be typechecked like a function call.

     If you were implementing <code>new</code>, its
     operand can be almost any type (what would be illegal there?).
     More generally in other languages,
     a constructor has to have # and types of parameters checked.
     Its return type is a reference to its operand type, and that type
     is type-checked against its enclosing expression, usually an assignment.
</dd>-->
</dl>


<h4> Code Generation for Arrays  </h4>

Consider first the subscript operator for C-like arrays. Then
consider how it ought to work in your compiler.
<p>

So far, we have only said, if we passed an array as a parameter we'd have to
pass its address.  3-address instructions have an "implicit dereferencing
semantics" which say all addresses' values are fetched / stored by default.
So when you say t1 := x + y, t1 gets values at addresses x and y, not the
addresses.  Once we recognize arrays are basically a pointer type, we need
3-address instructions to deal with pointers.  </p><p>

now, what about arrays?  reading an array value: x = a[i].  Draw the
picture.  Consider the machine uses byte-addressing, not word-addressing.
Unless you are an array of char, you need to multiply the subscript index
by the size of each array element...

</p><pre>t0 := addr a
t1 := i * 8
t2 := plus t0 t1
t3 := deref t2
x  := t3
</pre>

What about writing an array value?

<p>

There are similar object-oriented adaptation issues for arrays: a[i]
might not be a simple array reference, it might be a call to
a method, as in
</p><pre>x := a.index(i)
</pre>
or it might be implemented like:
<pre>x := a field i
</pre>

The main issue to keep straight in both the C-like example and the
object-oriented discussion is: know when an instruction constructs an
address and stores an address in a memory location. When you want to
read or write to the address pointed to by the constructed address,
you may need to do an extra level of pointer-following. Three address
instructions have "implicit" pointer-following since all addresses are
followed when reading or writing memory, but if what is in the address
is another address, you have to be careful to keep that straight.

<p>




</p><h3> Supplemental Comments on Code Generation for Arrays </h3>

In order to generalize from our example last lecture,
the 3-address instructions for
<pre>expr [ expr ]
</pre>
ideally should generate code that computes an address that can
subsequently be read from or written to. One can certainly write
a three address instruction to compute such an address.
With arrays this is pointer arithmetic.
<p>


With tables, the main wrinkle is: what to do
if the key is not in the table?  The behavior might be different
for reading a value or writing a value:

<table border="">
<tbody><tr>
<th> syntax </th><th> behavior
</th></tr><tr>
<td> t[x] := y </td><td> if key is not in table, insert it
</td></tr><tr>
<td> y := t[x] </td><td> if key is not in table, one of:
<ul>
<li> produce a default value
</li><li> raise an exception
</li><li> ??
</li></ul>
</td></tr></tbody></table>
</p><p>

</p>

<p>
<font size="1"> <a name="37">lecture #37</a> began here</font>
</p><p>

<!--
<img src="partybusiness.jpg">
<p>
  <img src="bbq23.png" width=600>
<p>
<ul>
  <li> party tomorrow 5-7pm, Sedillo Park
  <li> favorite hamburger toppings requests?
  <li> what would an ideal NMT CSE party have by way of food and drink and activites?
  <li> a bunch of you-all are going to receive awards!
       So, please come if you can.
</ul>
-->

<p>
  <h3> No Lab Today </h3>


  Which is to say, you have no deliverable turnin this week. I will spend
  the second hour today on whatever topic(s) you have for me,
  or I will just make up topics relatd to the PunY runtime system.
  
  
<p>


<A href="#finalcode">Warp to Final Code Gen</A>


<h3> Code Generation for Maps (Dictionaries, Tables) </h3>

Consider the map type for a moment. Example presented from the point
of view of Go, but Python dictionaries and Unicon tables are similar.
One can generate code for maps either by extending the three-address
instruction set with new instructions, or by generating function calls.
How might you implement

<dl>
<dt> map construction: make(map[string]int)
</dt><dd> Needs to allocate one hash table (array of buckets) from the heap.
For compiler, keys were always string. For VGo, keys can be string or int;
maybe two different opcodes/functions, or an argument that specifies this.
For other languages keys might be arbitrary type, adding complexity.

<table border="">
<tbody><tr><th>Via 3-address Instructions </th><th>Via function call
</th></tr><tr><td>
<pre>MAPCREATE  dest
</pre>
</td><td>
<pre>CALL	mapcreate,?,?
</pre>
</td></tr></tbody></table>

</dd><dt> insert: x[s] = s2
</dt><dd> Needs to compute an address into which to store s2.

<table border="">
<tbody><tr><th> Via 3-address Instructions </th><th> Via Function call
</th></tr><tr><td>
<pre>MAPINSERT  map,key,val
</pre>

</td><td>
<pre>PARAM	map
PARAM	key
CALL    mapinsert,?,val
</pre>

</td></tr></tbody></table>





</dd><dt> lookup: s = x[s2]
</dt><dd>
<table border="">
<tbody><tr><th> Via 3-address Instructions </th><th> Via Function call
</th></tr><tr><td>
<pre>MAPLOOKUP   tmp,map,key
ASN	    s, tmp
</pre>
</td><td>
<pre>PARAM   map
PARAM   key
CALL    maplookup,,tmp
ASN     s, tmp
</pre>
</td></tr></tbody></table>
</dd></dl>

<!--
The remainder of class was spent working out the details of assembling the
code generation for the entire while loop from our example before: <p>

<img src="intermed.jpg">
-->
<p>


</p><h3> Debugging Miscellany </h3>

Prior experience suggests if you are having trouble debugging, check:

<dl>
<dt> makefile .h dependencies!
</dt><dd> if you do not list makefile dependencies for important .h files,
     you may get coredumps!
</dd><dt> traversing multiple times by accident?
</dt><dd> at least in my version, I found it easy to accidentally re-traverse
     portions of the tree. this usually had a bad effect.
</dd><dt> bad grammar?
</dt><dd> our sample grammar was adapted from good sources, but don't assume its
     impossible that it could have a flaw or that you might have messed it up.
</dd><dt> bad tree?
</dt><dd> its entirely possible to build a tree and forget one of your children
<!--
<dd> cocogram.y was adapted from an old BASIC grammar and from the available
     books on color computer BASIC.  But, it is certain that it still
     has bugs (missing pieces).  Our goal is not to do the whole of Color
     BASIC, but if there is a bug in the reasonable subset we've defined,
     fix it.
-->
</dd></dl>

<h3> A few observations from Dr. D</h3>

I went shopping for more intermediate code examples, and while I didn't find
anything as complete as I wanted, I did find updated notes from the same
Jedi Master who trained me, check it:
<p>
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/IntermediateCodeGeneration.pdf">Dr. Debray's Intermediate Code Generation notes</a>.


</p><p>

You can consider these a recommended supplemental reading material, and we
can scan through them to look and see if they add any wrinkles to our prior
discussion.


</p><h3> A Bit of Skeletal Assistance with Three Address Code </h3>

<ul>
<li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/tac.h">tac.h</a>
</li><li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/tac.c">tac.c</a>
</li><li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/codegen.c">codegen.c</a>
</li></ul>




<h3> Example of Generating <code>.first</code> and <code>.follow</code> Attributes </h3>

What nodes need these?
<ul>
<li> probably only the statement level nodes.
</li><li> they give way to <code>.true</code> and <code>.false</code>
     within (conditional) expressions
</li><li> maybe only certain statements, like loops, and
     statements that have a preceding statement that
     can jump to them instead of just falling through
</li><li> ok to just blindly brute force these, as many as you want
</li><li> but it would be good to not write them if they aren't used
</li></ul>
<p>

Call <code>gen_firsts(root)</code> followed by <code>gen_follows(root)</code> before generating code.
</p><p>

<table border="">
<tbody><tr><th><code>.first</code></th><th><code>.follow</code>
</th></tr><tr><td>
What?
<ul>
<li> synthesized attribute
</li><li> a label (#) to precede all executable instructions for a given chunk of
     code
</li></ul>
Why?
<ul>
<li> loops may go back to their <code>.first</code>.
</li><li> preceding statements' <code>.follow</code> may be inherited from your <code>.first</code>
</li></ul>


Sample code:
<pre>void gen_firsts(nodeptr n)
{
   if (n == NULL) return;
   for(i=0; i<n->nkids; i++)
      gen_firsts(n-&gt;kids[i]);

   switch (n-&gt;prodrule) {
   case LABELED_STATEMENT:
      n-&gt;first = /* ... just use the explicit label */
      break;
   case EXPRESSION_STATEMENT:
   case COMPOUND_STATEMENT:
   case SELECTION_STATEMENT:
   case ITERATION_STATEMENT:
   case JUMP_STATEMENT:
   case DECLARATION_STATEMENT:
   case TRY_BLOCK:
      n-&gt;first = genlabel();
      break;
   default:
   }
}
</n-></pre>

</td><td>
Why?
<ul>
<li> if we skip a then-part or do a then-part and have to skip an else-part
</li><li> if we have to break out of a loop
</li></ul>


What?
<ul>
<li> inherited attribute
</li><li> a label to go to whatever comes after the executable instructions for
     a given chunk of code.
</li><li> Could try to dodge, by blindly generating labels at the end of each
     statement ("label sandwich" approach). 
</li></ul>

<pre>void gen_follows(nodeptr n)
{
   if (n == NULL) return;

   switch (n-&lt;prodrule) {
   case STATEMENT_SEQ + 2: /* statement_seq : statement_seq statement */
        n-&gt;child[0]-&gt;follow = n-&gt;child[1]-&gt;first;
	n-&gt;child[1]-&gt;follow = n-&gt;follow;
   	break;
   case COMPOUND_STATEMENT + 1: /* compstmt : '{' statement_seq_opt '}' */
        if (n-&gt;child[1] != NULL)
           n-&gt;child[1]-&gt;follow = n-&gt;follow;
   	break;
   case FUNCTION_DEFINITION + 1: /* funcdef : declarator ctor_init_opt body */
        n-&gt;child[2]-&gt;follow = genlabel();
        /* .icode must have this label and a return at the end! */
   	break;
   /* ... other cases? ... */
   default:
   }

   for(i=0; i&lt;n-&gt;nkids; i++)
      gen_follows(n-&gt;kids[i]);
}
</pre>
</td></tr></tbody></table>


</p><h3> Labels for <code>break</code> and <code>continue</code> Statements </h3>

<ul>
<li> As shown above, label generation of <code>.first</code> and <code>.follow</code> isn't difficult
</li><li> <em>propagating</em> that information <em>way down</em>
     into the subtrees where it is needed, across many nodes where it
     is not needed, and not messing up on nested loops, can be a challenge.
</li><li> Option #1: add inherited attributes .loopfirst and
     .loopfollow to the treenodes. Use them to pass a loop's
     <code>.first</code> and <code>.follow</code>
     down into the "break" and "continue" statements that
     need them: 
</li><li> Option #2: write a specialized tree traversal whose first parameter is the
     tree (node) we are traversing, and whose second and third parameters
     are pointers to the label (struct address) of the nearest enclosing
     loop.  It would be called as <code>do_break(root, NULL, NULL);</code>
</li><li> Option #3: implement parent pointers within all the nodes of your
     tree, and walk up the parents until you find a loop node.
</li></ul>
<p>

Sample code for Option #2 is given below. Implied by the BREAK case is
the notion that the .addr field for this node type will hold the label
that is the target of its GOTO. How would you generalize it to
handle other loop types, and the <code>continue</code> statement?
There may be LOTS of different production rules for which
you do something interesting, so you may add a lot of cases to this
switch statement.

</p><pre>void do_break(nodeptr n, address *loopfirst, address *loopfollow)
{
   switch (n-&gt;prodrule) {
   case BREAK:
      if (loopfollow != NULL)
	 n-&gt;place = *loopfollow;
      else semanticerror("break with no enclosing loop", n);
      break;
   case WHILE_LOOP:
      loopfirst = &amp;(n-&gt;first);
      loopfollow = &amp;(n-&gt;follow);
      break;
      ...
      }

   for(i=0; i&lt;n-&gt;nkids; i++)
      do_break(nodeptr n, loopfirst, loopfollow);
}
</pre>


<a name="tacordie">
<h3> TAC or die trying </h3>
</a>

We need a simple example, in which you see

<ul>
<li> Systematic traversal to populate explicit symbol table
</li><li> Systematic traversal to assign .addr (populate implicit symbols)
</li><li> Systematic traversal to assign <code>.first</code>/<code>.follow</code>/.true/.false
</li><li> Finally, build linked list of TAC instructions (.icode)
</li></ul>

It is easy to spend too much class time on
front-end stuff before getting to a too-short and still under-explored
TAC code generation phase. Our Goal:
<ul>
<li> manage a slightly larger ("interesting") example
</li><li> with syntax and semantic analysis already done
</li><li> for which we can go more blow by blow through the intermediate code
generation.
</li></ul>

The perfect example would include a few statements, expressions,
control flow constructs, and function calls.  Here is an such an
example. Notes for this exercise:

<ul>
<li> We will look at a C example.  Compare this with the
     corresponding VGo example.  Qualitatively, what is the difference?
</li><li> We will just generate the body for function main().
     See if you can generate TAC code for the other functions,
     and ask questions.
</li><li>  we are again trying hard to use a syntax tree, not a
      parse tree, i.e. generally, no internal nodes with only one child.
</li><li>  We omit from the tree, tokens that are simply punctuation
      and reserved words needed for syntax.
</li><li>  Also as stated previously, in real life you
      might not want to remove <em>every</em> unary tree node, some of them
      have associated semantics or code to be generated, or may help
      provide needed context in your tree traversal.
</li></ul>


<table>
<tbody><tr><th>C version </th><th> pseudo-VGo version
</th></tr><tr><td>
<pre>void printf(char *, int);
int fib(int i);
int readline(char a[]);
int atoi(char a[]);
int main() {
   char s[64];
   int i;
   while (readline(s)!=0 &amp;&amp; s[0]!='\004') {
      i = atoi(s);
      if (i &lt;= 0) break;
      printf("%d\n", fib(i));
      }
}
</pre>
</td><td>
<!-- g0 version
<pre>
int fib(int i){
   if (n <= 1) { return 1 }
   else { return fib(n-1) + fib(n-2) }
}
int ctoi(string s){
   if (s == "0") {return 0}
   else if (s == "1") {return 1}
   else if (s == "2") {return 2}
   else if (s == "3") {return 3}
   else if (s == "4") {return 4}
   else if (s == "5") {return 5}
   else if (s == "6") {return 6}
   else if (s == "7") {return 7}
   else if (s == "8") {return 8}
   else if (s == "9") {return 9}
}
int atoi(string s){
   int i
   i = 0
   while (#s > 0) {
      string c = s[1]
      i = i * 10 + ctoi(c)
      s = s[2:0]
      }
   return i
}
string itoa(int i){
   string s
   int div, rem
   if (i == 0) { return "0" }
   else if (i == 1) { return "1" }
   else if (i == 2) { return "2" }
   else if (i == 3) { return "3" }
   else if (i == 4) { return "4" }
   else if (i == 5) { return "5" }
   else if (i == 6) { return "6" }
   else if (i == 7) { return "7" }
   else if (i == 8) { return "8" }
   else if (i == 9) { return "9" }
   else if (i < 0) { return "-" itoa(-i) }
   else {
     div = i / 10
     rem = i % 10
     return itoa(div) itoa(rem)
   }
}
int main() {
   string s
   int i
   while ((s = read()) != EOF) {
      i = atoi(s)
      if (i <= 0) { break }
      write(itoa(fib(i)))
      }
}
</pre>
-->
<pre>func fib(int i) int {
   if n &lt;= 1 { return 1 }
   else { return fib(n-1) + fib(n-2) }
}
func ctoi(string s) int {
   if s == "0" {return 0}
   else if s == "1" {return 1}
   else if s == "2" {return 2}
   else if s == "3" {return 3}
   else if s == "4" {return 4}
   else if s == "5" {return 5}
   else if s == "6" {return 6}
   else if s == "7" {return 7}
   else if s == "8" {return 8}
   else if s == "9" {return 9}
}
func atoi(string s) int {
  var i int
  for ... /* while (#s &gt; 0) */ {
     //?? string c = s[1]
     //?? i = i * 10 + ctoi(c)
     //?? s = s[2:0]
      }
   return i
}
func itoa(i int) string {
   var s string
   var div, rem int
   if i == 0 { return "0" }
   else if i == 1 { return "1" }
   else if i == 2 { return "2" }
   else if i == 3 { return "3" }
   else if i == 4 { return "4" }
   else if i == 5 { return "5" }
   else if i == 6 { return "6" }
   else if i == 7 { return "7" }
   else if i == 8 { return "8" }
   else if i == 9 { return "9" }
   else if i &lt; 0 { return "-" + itoa(-i) }
   else {
     div = i / 10
     rem = i % 10
     return itoa(div) + itoa(rem)
   }
}
func main() {
  var s string
  var i int
  for ... {
      i = atoi(s)
      if i &lt;= 0 { break }
      fmt.Println(itoa(fib(i)))
      }
}
</pre>

</td></tr></tbody></table>

<p>

</p><pre>string ftoa(double d)
{
   if (d == 0.0) {
      return "0.0"
   }
   else if (d &lt; 0.0) {
      return "-real"
      }
   else {
     return "real"
   }
}
</pre>


<!--
<pre>
package {
    public class fibber {
	public function fib(n : int): int {
	   if (n <= 1) return 1
	   else return fib(n-1) + fib(n-2)
	}
	public function fibber() {
            var s: String
	    var i: int
            while (s = read()) {
	       i = int(s)
	       if (i <= 0) break
	       trace(fib(i))
	       }
	}
    }
}
</pre>
-->


<p>


</p><p>



<img src="tac-example.png">
</p><p>

Using <a href="https://www.cs.nmt.edu/~jeffery/courses/423/cgram.y">cgram.y</a> nonterminal names, let's focus on
code generation for the main procedure.



</p><h3> TAC-or-die: the First-level </h3>

<em>Potentially, this is a separate pass after labels have been generated.</em>
<p>

<table <tr=""><tbody><tr><td>
<img src="tac-example.png" width="500" height="768">
</td><td>

The first tree node that TAC code hits in its bottom up traversal is
IDENT<sub>readline</sub> (no .icode), followed by IDENT<sub>s</sub> (no .icode).
Above the IDENT<sub>s</sub>, argument_expression_list is one of those
non-terminals-with-only-one-child that matters and needs to be in the tree:
each time it churns out an actual parameter,
TAC code generates a PARAM instruction to copy the value of the parameter
into the parameter region. PARAM indicates an 8-byte (word) parameter;
you might also want to define PARAM4, PARAM2, PARAM1 (etc.) instructions.
Q: why is the ADDR instruction here?
<p>
</p><pre>	ADDR   loc:72,loc:0
	PARAM  loc:72
</pre>
<p>

The postfix_expr is a function call, whose TAC codegen rule should say:
allocate a temporary variable t<sub>0</sub> (or as we called it: LOC:80)
for the return value, and generate a CALL instruction

</p><pre>	CALL readline,1,loc:80
</pre>

The next leaf (ICON<sub>0</sub>) has no .icode, which brings code generation
up to the <code>!=</code> operator. Here the code depends on
the .true (L5) and .false (L2) labels.  The TAC code generated is

<pre>	BNE loc:80,const:0,lab:5
	GOTO lab:2
</pre>

After that, the postfix traversal works over to IDENT<sub>s</sub> (no .icode),
ICON<sub>0</sub> (no .icode), and up to the postfix expression for the subscript
operator for <code>s[0]</code>.  It needs to generate .icode that will place
into a temporary variable (its .addr, loc:88) what s[0] is.<p>

The basic expression for a[i] is baseaddr + index * sizeof(element).
sizeof(element) is 1 in this case, so we can
just add baseaddr + index.  And index is 0 in this case, so an optimizer
would make it all go away.  But we aren't optimizing by default, we are
trying to solve the general case.  Calling temp = genlocal() we get a new
location (loc:96) to store index * sizeof(element)
</p><pre>	MUL	loc:96,const:0,const:1
</pre>
We want to then add that to the base address, but
<pre>	ADD	loc:104,loc:0,loc:96
</pre>
would add the (word) <em>contents</em> of s[0-7].  Instead, we need
<pre>	ADDR	loc:104,loc:0
	ADD	loc:104,loc:104,loc:96
</pre>

After all this, loc:104 contains...the address we want to use.

<pre>	DEREF1	loc:112,loc:104
</pre>
fetches (into word at loc:112) the <em>value</em> of s[0].
<p>
A label L5 needs to be prefixed into the front of this:
</p><pre>	LABEL	lab:5
</pre>

</td></tr></tbody></table>

</p><p>
Note: an alternative to ADDR would be to define opcodes for reading and
writing arrays.  For example
</p><pre>	SUBSC1   <em>dest</em>,<em>base</em>,<em>index</em>
</pre>
might be defined to read from base[index] and store the result in dest.
Similar opcodes for ASNSUB1, SUBSC8, and ASNSUB8 could be added that
assign to base[index], and to perform these operations for 8-byte elements.
Even if you do this, you may need the more general ADDR instruction for
arrays of arbitrary sized elements.

<p>
CCON<sub>^D</sub> has no .icode, but the <code>!=</code> operator has
to generate code to jump to its .true (L4) or .false (L2) as in the previous
case.  Question: do we need to have a separate TAC instruction for
char compares, or sign-extend these operands, or what?  I vote: separate
opcode for byte operations.  BNEC is a "branch if not-equal characters"
instruction.

</p><pre>	BNEC loc:112,const:4,lab:4
	GOTO lab:2
</pre>

The code for the entire local_and_expr is concatenated from its children:
<pre>	ADDR   loc:72,loc:0
	PARAM  loc:72
	CALL   readline,1,loc:80
	BNE    loc:80,const:0,lab:5
	GOTO   lab:2
	LABEL  lab:5
	MUL    loc:96,const:0,const:1
	ADDR   loc:104,loc:0
	ADD    loc:104,loc:104,loc:96
	DEREF  loc:112,loc:104
	BNEC   loc:112,const:4,lab:4
	GOTO   lab:2
</pre>


Tree traversal then moves over into the body of the while loop: its statements.
<p>

IDENT<sub>i</sub> has no .icode.  The code for <code>atoi(s)</code> looks
almost identical to that for readline(s). The assignment to i tacks on
one more instruction:
</p><pre>	ADDR   loc:120,loc:0
	PARAM  loc:120
	CALL   atoi,1,loc:128
	ASN    loc:64,loc:128
</pre>

For the second statement in the while loop, the IF statement, there is
the usual conditional-followed-by-unconditional branch, the interesting
part is where they go.  The E.true should do the then-part (the break
statement) for which we generate a <code>.first</code> of lab:6.  The E.false should
go for whatever instruction follows the if-statement, for which lab:3
has been designated.

<pre>	BLE    loc:64,const:0,lab:6
	GOTO   lab:3
</pre>

The then-part is a break statement. All then-parts will need to have a
label for their <code>.first</code> instruction, which in this case is a trivial GOTO,
but where does it go?

<pre>	LABEL  lab:6
	GOTO   ??
</pre>

The <code>break</code> is a major non-local goto that even
the parent node (the if-statement) cannot know the target for, without
obtaining it from about 7 tree-nodes higher!  The iteration_statement's
<code>.follow</code> (lab:2) is the target for <code>break</code> (its
<code>.first</code> would be the target for <code>continue</code>).

<h3> Dr. J has Doubts About 64-bit Ints </h3>

<ul>
<li> Last lecture I pointed out that I had edited the example we are
     working right now, to account for ints being 64-bit instead of 32-bit.
</li><li> It is reasonable to ask whether this is a Bad Idea.
</li><li> Pros: if (almost) everything is 64-bits, does that keep things simpler?
</li><li> Cons: if our ints are not the same size as g++ ints, how will that
     affect us?
</li></ul>

<h3> Back to the TAC-or-die example </h3>

So by one of options #1-3, we find the nearest enclosing iteration_statement's
<code>.follow</code> field says LAB:2. Note that since we have here a label target that
is itself a GOTO, an optimizer would chase back to the branch instructions
that go to label 6, and have them go to label 2, allowing us to remove this
instruction.  By the way, if there were an else statement, the
code generation for the then-part would include another GOTO (to skip over
the else-part) that we'd hopefully remove in optimization.

<pre>	LABEL  lab:6
	GOTO   lab:2
</pre>

Having completed the then part, it is time to assemble the entire
if-statement:

<pre>	BLE    loc:64,const:0,lab:6
	GOTO   lab:3
	LABEL  lab:6
	GOTO   lab:2
	LABEL  lab:3
</pre>

The next statement is a printf statement. We need to push the parameters
onto the stack and execute a call instruction.  The code will be: code
to evaluate the parameters (which are non-empty this time), code to push
parameters (in the correct order, from their .addr values),
then the call.  <em>Question: does it matter whether the evaluations
all occur before the PARAM instructions, or could they (should they) be
interleaved?</em>  Answer: in C++ evaluations must all occur before the
PARAM instructions, all PARAM instructions for a call come after the
code for evaluating those arguments, IN REVERSE ORDER, and right
before the CALL instruction.
<p>

The code for parameter 1 is empty; its string address will be
pushed onto the stack when we get to that part.
Here is the code for parameter 2,
storing the return value in a new temporary variable.

</p><pre>	PARAM  loc:64
	CALL   fib,1,loc:136
</pre>

The code for the outer call is then

<pre>	PARAM  loc:64
	CALL   fib,1,loc:136
	PARAM  loc:136
	PARAM  sconst:0
	CALL   printf,2,loc:144
</pre>

Given this, whole while-loop's code can finally be assembled.  The while
prepends a label and appends a GOTO back to the while loop's <code>.first</code> field.
The whole function's body is just this while loop, with a procedure
header and a return statement at the end:

<pre>proc main,0,128
	LABEL  lab:1
	ADDR   loc:72,loc:0
	PARAM  loc:72
	CALL   readline,1,loc:80
	BNE    loc:80,const:0,lab:5
	GOTO   lab:2
	LABEL  lab:5
	MUL    loc:96,const:0,const:1
	ADDR   loc:104,loc:0
	ADD    loc:104,loc:104,loc:96
	DEREF  loc:112,loc:104
	BNEC   loc:112,const:4,lab:4
	GOTO   lab:2
	ADDR   loc:120,loc:0
	PARAM  loc:120
	CALL   atoi,1,loc:128
	ASN    loc:64,loc:128
	BLE    loc:64,const:0,lab:6
	GOTO   lab:3
	LABEL  lab:6
	GOTO   lab:2
	LABEL  lab:3
	PARAM  loc:64
	CALL   fib,1,loc:136
	PARAM  loc:136
	PARAM  sconst:0
	CALL   printf,2,loc:144
	GOTO   lab:1
	LABEL  lab:2
	RETURN
</pre>




<h3>Intermediate Code Generation for Structs, Classes and OO </h3>

<ul>
<li> CodeGen for structs/classes depends a lot on the language semantics.
</li><li> Lecture notes with ideas relevant to Java, ActionScript, or Unicon
may not do things identically to what a C++ subset needs.
</li><li> For a new language, we are needing to invent some stuff.
</li><li> Maybe some new 3 address opcodes/instructions, for example.
</li><li> Next section was for a C++ subset. For each bit, ask how is our
     target language different?
</li><li> More general OO considerations deferred to later
</li></ul>
<p>

Consider the following simplest possible OO class example program:

</p><pre>class pet {
     int happy
      pet() { happy = 50 }
      void play() {
        write("Woof!\n")
	happy += 5
	}
}
int main()
{
    pet pet1
    pet1.play()
    return 0
}
</pre>

What are the code generation issues?
<br><br><br><br><br><br><br><br><br><br><br><br>

Did we get:
<ul>
<li> allocation
</li><li> initialization via constructor
</li><li> method calling
</li><li> member variable referencing
</li></ul>

For what its worth, one VGo test case is basically a hand-translation of
this into VGo using a struct.

<h3> Object Allocation </h3>

<dl>
<dt> memory allocation of an object is similar to other types.
</dt><dd> it can be in the global, local (stack-relative) or heap area
</dd><dt> the # of bytes (size) of the object must be computed from the class.
</dt><dd> each symbol table should track the size of its members
</dd><dt> for a global or local object, add its byte-count size requirement
     to its containing symbol table / region.
</dt><dd> effectively, no separate code generation for allocation
</dd><dt> translate a "new" expression into a malloc() call...
</dt><dd> plus for all types of object creation, a constructor
     function call has to happen.
</dd></dl>

<h3> Initialization via Constructor </h3>

<ul>
<li> A major difference between objects and, say, integers, is that
     objects have constructors.
</li><li> Constructor, like all other member functions, takes a 0th parameter
     that is a pointer to the object instance.  Could be implemented as
     a register variable, similar to %ebp procedure frame pointer.
</li><li> For a local, the object variable declaration translates into a
     constructor function call that happens at that point in the code body.
     Just catenate .icode into the linked list.
</li><li> For a "new" object, the constructor function call happens right after
     the (successful) call to allocate the object.
</li><li> For a global, how do we generate code for its constructor call?
     When does it execute? ... Good news, everyone!  120++ almost
     does not support globals at all, and only has integer globals.
</li></ul>

<h3> Method Invocation </h3>

Now let's discuss how to generate code for <p>

<code>o.f(arg1,...,argN)</code>

</p><ul>
<li> In C++ it's just a method invocation.

</li><li>
When o's class C is known at compile time and methods are non-virtual,
You can generate <code>C__f(&amp;o, arg1, ..., argN)</code>.

</li><li> Note the flip side of this: when you generate code for the member
function body, you do the same name mangling, and add the same extra
one-word "this" parameter to the symbol table.

</li></ul>

<h3> Member variable references </h3>

<dl>
<dt> inside a member function, i.e. access member variable x.
</dt><dd> Handle like with arrays, by allocating a new temporary variable
     in which to calculate the address of this-&gt;x.  Take the address
     in the "this" variable and add in x's offset as given in the
     symbol table for this's class.
</dd><dt> outside an object, o.x.
</dt><dd> Handle as above, using o's address instead of this's.
     You would also check o's class to make sure x is public.
</dd></dl>


<h3> Code Generation for Dynamic OO Languages </h3>

<ul>
<li>
In a "really" OO language, for o.f(...) you'd do semantic analysis to know
whether f is a method of o's class, or a member variable that happens
to hold a function pointer
</li><li> What if f is a method that C inherits from some superclass S?

</li><li> What if o's class not known at compiled time and/or methods
are virtual. You have to calculate at runtime which method f to use for o.
What are your options???

</li></ul>

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
Your brilliant suggestions should have included: insert function pointers
for all methods into the instance.<p>

Now let's consider a simple real-world-ish
example.  Class TextField, a small, simple GUI widget. A typical
GUI application might have many textfields on each of many dialogs; many
instances of this class will be needed. </p><p>

The source code for TextField
is only 767 lines long, with 17 member variables and 47 member functions.
But it is a subclass of class Component, which is a subclass of three other
classes...by the time inheritance is resolved, we have 44 member variables,
and 149 member functions.  If we include function pointers for all methods
in the instance, 77% of instance variable slots will be these function
pointers, and these 77% of the slots will be identical/copied for all
instances of that class.
</p><p>

The logical thing to do is to share a single copy of the function pointers,
either in a "class object" that is an instance of a meta-class, or more
minimally, in a struct or array of function pointers that might be
called (by some) a <em>methods vector</em>.



</p><h3> Methods Vectors </h3>

Suppose you have class A with methods f(), g(), and h(), and class B
with methods e(), f(), and g().  Suppose further that you have code
that calls method f(), that is designed to work either either A or B.
This might happen due to polymorphism, interfaces, subclassing, virtual
methods, etc.  The kicker will be that in order to generate code for
o.f(), a runtime lookup will be performed to obtain
the function/method pointer associated with symbol f.

Instead a separate structure (the "methods vector") is allocated and
shared by all the instances of a given class.  In this case, o.f()
becomes o.__methods__.f(o)


<p>


</p><h3> Old Mailbag </h3>

<dl>
<dt> What if my program has three functions, each with a local variable to
     declare?
</dt><dd> Each function's "local region" is allocated uniquely each time they
     are called. Each of your functions' local regions starts at offset 0
     so all three local variables might say LOC:0 for local region offset
     zero.  And yet, they never refer to the same memory, because they are
     always offsets relative to some base pointer register on the stack.

</dd><dt> When do I allocate my labels?  When do I use them?
</dt><dd> You allocate them in one or more tree traversals prior to starting
     the main traversal that generates the linked lists of 3-address code.
     Most labels are allocated very close to where they are used.
     You use labels by generating pseudo-instructions in the linked list AND
     by filling in the target addresses used by goto instructions with LAB:#N
     for label number N.

</dd>

<dt> I am confused about how to access class members via the "this"
pointer.  I am unsure how to do the offsets from the "this" pointer in
three address code without creating a new symbol table for class instances.
</dt><dd> An object instance is like its own little memory region.
The <code>this</code> pointer is a parameter; offsets relative to
what it points at are done via pointer arithmetic. Each class
should indeed have a symbol table for its member variables' offsets.

</dd><dt> Do you have an example that uses each of the pseudo instructions
     (global, proc, local, label, and end), so we
     know how these should be formatted?
</dt><dd> No.  The pseudo instructions should have opcodes and three address
fields; their presence in the linked list of three address codes is the
same as an instruction. Their format when you print them out is not very
important since this is just intermediate code. But:
instructions are on a single line that begins with a tab character, and
pseudo instructions are on a single line that does not begin with a tab
character.

</dd><dt> We have const that can hold an int/(int)char/boolean, a string region
for holding a string offset, but what should we do about double const
values?

</dt><dd> Real number constants have to be allocated space similar to other types.
They could either be allocated out of a separate "real number constant
region", or the constants of different types could all be allocated out of
the same region, with different offsets and sizes as needed. Note that
not all integer constants fit in instructions, so potentially
some of them may have to be allocated as static data also.

</dd>

<dt> Do the linked lists of code really just get concatenated in order
     until the entire program is one big linked list?
     Does main() have to be at the beginning in generated code?
</dt><dd>
     Not really, and not really.  It is recommended that you build one
     big linked list for the generated code, but I am a pragmatist; do
     what makes sense to you to generate all the code.  In real native
     OS'es, the code at the beginning of the executable is not main, it
     is some weird startup boostrapper that sets up environment and
     command line arguments and then calls main(). So no, main() does not
     have to be at the top, unless maybe you are building an image
     for an embedded system that doesn't have an OS or something like that.

</dd><dt> How do I represent function names in addresses in 3 address code?
</dt><dd> One option is to totally dodge, and generate code for one function
      at a time, at a place where you know the function name. If you
     choose instead to build one big linked list,
     function "names" get boiled down to code region addresses. So far
     we have one kind of address in the code region: labels.
     You could literally generate label #'s for these things, but function
     names are more human-friendly.  Unless you turn function names into
     labels, you should create a new region (call it PROCNAME).  You could make the "offset" field in
     your 3 addresses a union
<pre>     struct addr {
      int region; // if PROCNAME, use u.s instead of u.i
      union {
         int offset;
	 char *s;
         } u;
      }
</pre>
     You could, instead, make an array of string funcnames in your compiler
     and have your region PROCNAME provide offsets that are subscripts into
     this array of funcnames.

</dd><dt> I am having a hard time understanding how everything will be put
together in the end, will it be one linked list once all the instructions
are concatenated? How should we handle assigning locations to functions like
Println? Once we see import "fmt" should we go to that symbol table and
assign locations to those functions then?

</dt><dd>Library functions like Println require that we store enough information
to call them, but not that we store information to generate code for them.
fmt should have an associated symbol table entry for Println which should
know that Println takes a string argument.  Code for a call to fmt.Println
should mangle that name out to something like fmt__Println.

</dd><dt> can we just define a function without parameters as call, so
<code>main</code> is equivalent to <code>main()</code> if not followed
by parentheses?
</dt><dd> Do not confuse type (reference to) FUNCTION with
the function's return type, which is the result of a call (postfix parentheses
operator).
</dd></dl>



<h3> Where we are at </h3>

Schedule-wise, it says it is time to move lectures on into the area of
final code generation.  We have a new wrinkle there this year, and need
to allow some time for it.  But, intermediate code generators are not
due yet, and questions about that are still totally fair game.

<p>
</p><h3>One More Intermediate Code Example, with Feeling </h3>

I glossed over the "TAC or die trying" example in the last lecture;
it felt redundant for me since we did an earlier example that
was similar. However, one or more of you have requested another
intermediate code generation example.
<p>

Yeah, we'll do one alright; this week.  But it will take a bit more
preparation, so: not today.  This weekend I spent a fair bit digging into
another code generation topic, namely LLVM, and we will also be talking
about that.
</p><p>



<p>
</p><h3>Mailbag </h3>

<dl>
<dt> Remind me again: What is the MINIMUM I have to do to pass this class
<dd>

That depends on exam results, but generally students need either good exam
results and at least get through type checking, or less good exam results
and at least some/partial intermediate code to "pass". This semester folks
are behind where we are some other semesters, and that may help you, since
you are graded relative to your peers. A grade extension might be an option.
I am pretty darn OK with grade extension if you have been working at it but
need more progress.
You should check whether it would prevent you from walking in commencement,
but they seem to have relaxed NMT's traditional hard-core commencement-walking
rules lately.

<dt> I have been working 12 days a week, 7 hours per day on this homework and
  it just isn't fair.
<dd> Some of you are probably working more efficiently than others
  ("work smarter"), but the goal was not to teach you what the death
  marches in industry are going to be like. The goal is to cause you
  to increase your skill level in programming and/or software engineering.

  <dt> Where is my HW#5 feedback?
  <dd> You made it to a HW#5 submission?  Congratulations!
    I spent quality time this weekend on regrades of HW#2-4 and did the
    groundwork for grading HW#5.  I will get right on that.

<dt>
I'm having trouble figuring out what TAC I need to generate for a function
definition.  For example, given the function 
<pre>int foo(int x){
   ...somecode
}</pre>

I'm having trouble understanding what code needs to be generated at this
level.  I understand that there needs to be (at least) 1 label, at the very
start (to be able to call the function).

</dt><dd><font color="red">In final code, the procedure entry point
will indeed include a label. In three address code, a function header
should result in a PROC pseudo-instruction for which you create a link
list element, just like everything else.
</font>

</dd><dt>

I'm having trouble understanding what code I would create for the int
return, or to define the space available for parameters.

</dt><dd>
<font color="red">
The "return type" at the top of a function generates no code, but it may
affect what you generate when you hit a "return" statement in the function
body.
<p>
The proc pseudoinstruction includes a declaration of how many
(words of parameters) it requires/assumes has been passed in to a function,
from which space required may be calculated. In most native code the caller
allocates this space; the called function
just decides the amount of
local/temp variable space on the stack that the procedure requires.
So the pseudoinstructions in intermediate code that you use is
something like:
<pre>proc foo,1,<em>nbytes_localspace</em>
</pre>
<p>
This question gets more interesting if you have the ability to return
multi-word values such as a struct, for which a register will not suffice!
What do you think a compiler should do in that case?
</font>

</dd><dt>

If I understand the return properly, I don't actually generate code at this
(the procedure header return type) node for the return.  It gets generated
at the <code>return</code> statement in the body.

</dt><dd>

<font color="red">Yes. There and at the end of any function
that falls off the end.  In final code the return statement will put a
return value in %eax and then jump
down to the end of the function to use its proper function-return assembler
instruction(s).
</font>

</dd><dt>

I guess the .addr of a parameter <code>int x</code> is what is really
getting me.
Do I really
need to worry about it too much in TAC, because it is just 'local 0' (or
whatever number gets generated)?

</dt><dd>

<font color="red">I recommend you consider it (in TAC) to be region
PARAM offset 0.  That could be handled almost identically to locals in final
code, unless you use the fact that parameters are passed in registers...
</font>

</dd><dt>

Then I really end up worrying about it during final code since local 0 might
actually be something like %rbp -1 or wherever the location on the stack
parameters end up being located.

</dt><dd>

<font color="red">If you make a separate region for parameters, by saying
a variable is is PARAM region offset 0, the TAC code for
parameters is distinct from locals. Parameters can be found to be at
a different location relative to the %rbp (positive instead of negative offsets)
or passed in registers.</font>

</dd></dl>



<a name="finalcode">
</a></p><h3><a name="finalcode"> Final Code Generation </a></h3><a name="finalcode">
</a>

<ul>
<li> Goal: execute the program we have been translating, somehow.
</li><li> Note: in real life we would execute a major optimization phase
on the intermediate code, before generating final code.
</li></ul>

Alternatives for Final Code:
<dl>
<dt> interpret the source code
</dt><dd> we could build an interpreter instead of a compiler, in which the
     source code was kept in string or token form, and re-parsed, possibly
     repeatedly, during execution. Some early BASIC's and operating system
     shell scripting languages do this, but it is Really Slow.
</dd><dt> interpret the parse tree
</dt><dd> we could write an interpreter that executes the program
     by walking around on the tree doing traversals of various subtrees.
     This is still slow, but successfully used by many "scripting languages".
</dd><dt> interpret the 3-address code
</dt><dd> we could interpret the link-list or a more compact binary representation
     of the intermediate code
</dd><dt> translate into VM instructions
</dt><dd> popular virtual machines such as JVM or .Net allow execution from an
     instruction set that is often higher level than hardware, may be
     independent of the underlying hardware, and may be oriented toward
     supporting the specific language features of the source language.
     For example, there are various BASIC virtual machines out there.
</dd><dt> translate into "native" instructions
</dt><dd> "native" generally means hardware instructions.
</dd></dl>

For practical purposes, we will consider only two of these options
<ol>
<li> translate into VM assembler for the LLVM IR, or
</li><li> translate into native x86_64 <&lt;-- "simplest", today's lab
</li></ol>


<h3> Introduction to <a href="https://llvm.org/docs/LangRef.html">LLVM</a></h3>

LLVM, low-level virtual machine, is a compiler back-end developed by Apple.
Compared with Java VM it is arguably lower level, and it provides a human
readable assembler format that the Java folks have avoided. For a
compiler writer, it provides a way to translate to a machine independent
3-address instruction set and still obtain a highly optimized native
executable on various platforms.  LLVM intermediate representation looks
like this:

<pre>@.str = private constant [12 x i8] c"Hello llvm!\00", align 1 ;
 
define i32 @main() ssp {
entry:
  %retval = alloca i32
  %0 = alloca i32
  %"alloca point" = bitcast i32 0 to i32
  %1 = call i32 @puts(i8* getelementptr inbounds ([12 x i8]* @.str, i64 0, i64 0))
  store i32 0, i32* %0, align 4
  %2 = load i32* %0, align 4
  store i32 %2, i32* %retval, align 4
  br label %return
return:
  %retval1 = load i32* %retval
  ret i32 %retval1
}
 
declare i32 @puts(i8*)
</pre>

Human-readable LLVM IR is translated from a <code>.ll</code> extension into
a binary version with the extension <code>.bc</code>. .bc files can be
translated into native assembler code by llc, and then assembled and linked.
For example, if the above file were in a file named hello.ll, the following
sequence would produce an executable:

<pre>    llvm-as hello.ll
    llc hello.bc
    as hello.s -o hello.o
    gcc hello.o -o hello
</pre>

To study LLVM further we should take a look at how to translate our various
three-address intermediate instructions into it, and take a look at its
instruction set.  We will explore these topics as time allows.


<h3> Native Code Generation </h3>

In mainstream compilers, final code generation into native code
<ol>
<li> takes a linear sequence of 3-address intermediate
code instructions, and
</li><li> translates each 3-address instruction into one or
more native instructions.
</li></ol>
<p>

The big issues in code generation are:
</p><dl>
<dt> (a) instruction selection, and
</dt><dt> (b) register allocation and assignment.
</dt></dl>

</p>

<h3> # of Registers Clarification </h3>

<ul>
<li> numbers quoted last lecture were for "completely undesignated"
     general purpose registers
</li><li> 32-bit x86 really has eight (8) general purpose registers although
     some are typically used for specific purposes suggested by their name:
     (eax, ecx, edx, ebx, esp, ebp, esi, edi)
</li><li> 64-bit AMD64 (a.k.a. x86-64) has sixteen (16) registers:
rax, rcx, rdx, rbx, rsp, rbp, rsi, rdi, r8, r9, r10, r11, r12, r13, r14, r15
</li><li> DEC VAX had 32 registers
</li><li> ARM (hello, smartphones) has 8, or maybe 13
</li><li> other RISC systems often have 32 or more;
     Sun SPARC has 192 registers accessed
     via a sliding <em>register window</em>
</li></ul>


<h3> Code Generation for High Level Structure Types </h3>

This discussion applies to maps/dictionaries/tables as we as high-level
sequential (list) types that are dynamic, in contrast with arrays.

<ul>
<li> What we have said so far is that you could define new opcodes
     for such operators (raising the language level of your
     intermediate code), or implement them as function calls.
</li><li> Either way, we will (by final code generation) need an
     implementation of this functionality, that your code can
     link in and use.  You could write your own, or ask me to
     provide this as a set of runtime functions in C.
</li></ul>

<p>
Lists:
</p><p>

<table border="">
<tbody><tr><th>operation</th><th> as opcode        </th><th> as function
</th></tr><tr><td> L1 L2   </td><td> LCONCAT t,L1,L2  </td><td> t = lconcat(L1,L2)
</td></tr><tr><td> L1 += L2</td><td> LAPPEND L1,L2    </td><td> lappend(L1,L2)
</td></tr><tr><td> L1 += x </td><td> LPUT    L1,x     </td><td> lput(L1,x)
</td></tr><tr><td> L[i]    </td><td> LINDEX  t,L,i    </td><td> t = lindex(L,i)
</td></tr><tr><td> L[i:j]  </td><td> LSLICE t,L,i,j<br>
                      no good, 4 addrs </td><td> t = lslice(L,i,j)
</td></tr><tr><td> #L      </td><td> LSIZE   t,L      </td><td> t = lsize(L)
</td></tr><tr><td> t = list() </td><td> LIST t,n,m    </td><td> t = list(n,m)
</td></tr></tbody></table>

</p><p>
Tables:
</p><p>

<table border="">
<tbody><tr><th>operation</th><th>as opcode</th><th>as function
</th></tr><tr><td> T[a]    </td><td> TINDEX  t,T,a  </td><td> t = tindex(T,a)
</td></tr><tr><td> T[]=a   </td><td> TDEFAULT T,a   </td><td> tdefault(T,a)
</td></tr><tr><td> T -= a  </td><td> TDELETE T,a    </td><td> tdelete(T,a)
</td></tr><tr><td> #T      </td><td> TSIZE   t,T    </td><td> t = tsize(T)
</td></tr><tr><td> t = table() </td><td> TABLE t,m    </td><td> t = table(m)
</td></tr></tbody></table>



</p><h3> Collecting Information Necessary for Final Code Generation </h3>

<dl>
<dt> Option #A: a top-down approach to learning your native target code.
</dt><dd>
     Study a reference work supplied by the chip manufacturer, such
     as the <a href="https://support.amd.com/TechDocs/24592.pdf">
     AMD64 Architecture Programmer's Manual</a>
      (<a href="http://developer.amd.com/wordpress/media/2012/10/24593_APM_v21.pdf">Vol. 2</a>,
      <a href="https://support.amd.com/TechDocs/24594.pdf">Vol. 3</a>).
</dd><dt> Option #B: a bottom-up (or reverse engineering)
     approach to learning your native target code.
</dt><dd>
     study an existing compiler's native code.  For example, run
     "g++ -S" for various toy programs
     to learn native instructions corresponding to each expression,
     particularly ones equivalent to the various 3-address instructions.
</dd></dl>


<h3> A New Fun Intermediate CodeGen Example </h3>

This example is not burdened with redundant practice at generating code
for arithmetic and assignments and such.

<pre>package main
import "fmt"
func min(a,b,c int) int {
  if a&lt;=b &amp;&amp; a&lt;=c {
     return a
  } else if b&lt;=a &amp;&amp; b&lt;=c {
     return b
  }
  return c
}

func main() {
  fmt.Println(min(3,6,2))
}
</pre>



<h3> Mailbag </h3>
<dl>
<!--
<dt> I am unsure how to best handle array creation in my tree structure.
  I have the rule
  <pre>ArrayCreate: NEW Type '[' INTLIT ']'</pre>
  but I am unsure whether alctree() should be passed $4, INTLIT, as well?
  <dd>

Yes. If the ArrayCreate tree node contains information that tells us we have
used this production rule, the NEW and the square brackets become unnecessary
in the tree, but Type and INTLIT are needed. More generally, terminals are all
needed unless they are reserved words or pure punctuation. The terminal symbols
whose characters may vary in each occurrence need to be in the tree.  We need
to be able to tell what the number was inside the square brackets.
-->

<dt> I do not know what I am looking for with this email. I want help with
something, but it feels like there is so much to do that I do not know where
to even begin [HW6].

<dd>
Well,

<ol>
<li>
  Do HW#5, if you have not yet. You need to know the spots where you
  check for redeclared variables and undeclared variables.
<li> assign addresses (in some languages like Unicon, just index/slot numbers
  within the memory region)
  to all the variables' symbol table entries,
  when they get declared. verify.
  These are the spots where you check for redeclared variables.
<li> Assign labels. You can get some points for straight line code
  if you didn't do control flow, so this is not 100% required to start,
  but <code>if</code> statements and <code>while</code> loops are
  pretty fundamental and important, so do labels.
<li> Assign addresses to all the <em>leaves</em> where variables or constants
  occur in your actual executable statements (function body code),
  including fetching variables' address from symbol table lookups at
  the spots where you check for undeclared variables
<li> Assign addresses at the internal nodes where temporary variables
  are needed, i.e. the production rules for ADD, MUL, and a few others
  like CALL.
<li> Build the linked lists using .addr and labels.
  Try it one operator at a time, simplest ones first.
  Generate code for 2+2.  Generate code for x=3. Generate code for x=2+2.
  Work your way up.
</ol>

<P>

  You can get partial credit if you show work for earlier # steps,
  which you may insert print statements for your own debugging,
  but the bulk of the points rest on getting #6 going at least for simple stuff

<!--<dt> I am doing LLVM for HW#6 and my LLVM is incompatible with the one on
     the grading machine! What do I do?
</dt><dd> You can demo your HW#6 results during finals week on your machine.
     Or you can do your HW6 on the grading machine. Or you can do x86_64.
     I will take and grade anything you give me on HW#6.-->

<!--
<dt>
If we have a variable that is inside of a function that is inside of a
class, would that variable address be part of the LOCAL memory region or
CLASS memory region?

<dd>
Local variables declared inside a function inside a class, are just LOCAL
region variables.  CLASS region is only for variables that are not local to
any function, the memory that is allocated per-instance (a.k.a. per-object),
not per-function-call. CLASS region variables are accessed as offsets from
a "this" pointer instead of from a base pointer register.
-->


<dt>Has this class been a one long <a href="https://en.wikipedia.org/wiki/Kobayashi_Maru">Kobayashi Maru</a> Test?
</dt><dd> Thanks for the pop culture reference! For some of you,
CSE 423 may seem similar to the
Kobayashi Maru in that it may seem unwinnable. It is different than
the Kobayashi Maru in that the goal is not to test your character,
but to make you gain experience points and go up levels
in programming skill, such that you are ready to work professionally.
Any character development that may occur is a side bonus.
</dd>

<!--
<dt>
I saw your in your three address code examples of calling a function that
pass array variables that before PARAM, you always put the array
address into a temporary variable.

like:
<pre>char s[64];
readline(s)

	ADDR   loc:68,loc:0
	PARAM8 loc:68
	CALL   readline,1,loc:68
</pre>

and  printf("%d\n", 10+2);

<pre>     addr	    loc:0,string:0
     parm	    loc:0
     add	    loc:8,im:10,im:2
     parm	    loc:8
     call	    printf,16,loc:16
</pre>

So, before passing the variables to the function, do you have to copy
the variables to the temporary variables? And then PARAM the temporay
variables. Or it is only true for passing array address?

<p>

I know the PARAM will copy the passing arguments into the called function's
activation record's parameter region. So there is no need copy the parameter
variables into temporary variables then PARAM the temporary variables.

<dd>

The three-address instructions use addresses, but they normally operate by
implicitly fetching and storing values pointed to by those addresses.

<p>

The ADDR instruction does not copy the variable into a temporary variable,
it copies the address given, without fetching its contents, into its
destination.  This is needed in order to pass an reference parameter.
In Pascal, by default we would have to allocate (on the stack) an entire
physical copy of the whole array in order to pass it as a parameter. This is
potentially very expensive, which is why C-based languages don't do it.
</p><p>

(Q: if you wanted a physical copy of an array to be passed, do you know
some ways to get one?)
-->
</dl>

<h4>Instruction Selection</h4>

A modern CPU usually has many different sequences of instructions
that it could use to accomplish a given task.  Instruction selection
must choose a particular sequence.
<ul>
<li> how many registers are tied to particular instructions?
</li><li> is a special case instruction available for a particular
     computation?
</li><li> what addressing mode(s) are supported for a given instruction?
</li></ul>

Given a choice among equivalent/alternative sequences, the decision on which
sequence of instructions to use is usually based on estimates or
measurements of which sequence executes the <em>fastest</em>.

<ul>
<li> "fastest" is often approximated by the
number of memory references incurred during execution, including the
memory references for the instructions themselves.
</li><li>  picking the
<em>shortest</em> sequence of instructions is often a good approximation of the
optimal result, since fewer instructions usually translates into fewer
memory references.
</li></ul>

<p>

A good set of examples of instruction selection are to be
found in the <a href="http://www.stanford.edu/class/cs343/resources/superoptimizer.pdf">superoptimizer</a> paper. From that paper:

</p><ul>
<li> a longer instruction sequence may be faster if it avoids gotos
</li><li> sometimes the fastest sequence exploits specific constants in the
     operands and is really, really surprising.
</li></ul>



<h3> Register Allocation and Assignment </h3>

<ul>
<li> reading values in registers is much much faster than accessing main memory.
</li><li>
<em>Register allocation</em> denotes the selection of which variables
will go into registers.
</li><li>
<em>Register assignment</em> is the determination of exactly
which register to place a given variable.
</li><li> goal: minimize the total number of memory accesses required
by the program.
</li></ul>
<p>

</p><h4> The (register allocation) job changes as CPUs change </h4>

<ul>
<li>In the age of dinosaurs, Load-Store architectures featured
only one (accumulator) register.
Register allocation and assignment was moot.
</li><li>In the age of minis and micros, it was usually "easy", e.g.
traditional x86 had 4 registers instead of 1.
</li><li>Recent History features CPU's with 32 or more general purpose
registers.  On such systems,
high quality compiler register allocation and assignment makes a huge
difference in program execution speed.
</li><li> :-( btw, optimal register
allocation and assignment is NP-complete! Compilers must settle for
doing a "good" job.

</li><li>usually the # of variables at many given time exceeds the number
of registers available (the common case)
</li><li> variables may be used (slowly)
     directly from memory IF the instruction set supports
     memory-based operations.
</li><li>
When an instruction set does not support memory-based operations, all
variables must be loaded into a register in order to perform arithmetic
or logic using them.
</li></ul>
<p>

Even if an instruction set does support memory-based operations, most
compilers should load a value into a register while it is
being used, and then spill it back out to main memory when the register
is needed for another purpose.  The task of minimizing memory accesses
becomes the task of minimizing register loads and spills.



<h3> Mailbag </h3>

<dl>
<!--
<dt> On the homework #5 grading, test #4 calls <code>printf</code>. Would you please
    change this to <code>System.out.println</code> before regrading?
<dd> OK. Given the obvious goof, your HW#5 grade should receive the test #4
  points if you issued a semantic error (undefined symbol) for printf, as
  an alternative to the intended semantic error being sought.
<dt> You assigned me a different grade than my partner! Why?
<dd> Most likely a mistake was involved!  Some teams have broken up, and
  some submissions were not labeled with their partner, and sometimes, being
  human, I miss something in one reading that I see in another.

<dt> In j0, don't we have to <code>import System.out.println</code>
    in order to use it?
<dd> The intent was that j0 not have to do any imports at all. Java doesn't
  need an import to use System.out.println so neither should j0.
  Two possible ways to implement the
  predefined/built-in things in lieu of an import: insert them by hand into
  the symbol table, or read them in from some magical file on startup.

<dt> Given the incomplete nature of the j0 spec, I'm still mad at you for not 
     giving us all the test cases in advance.
<dd> I do not generally believe in providing all the test cases in advance.
     I am willing to release the rubric and perhaps half the test cases for
     HW#6, to minimize surprises. Say that at least half the test cases for
  HW#6 will resemble those for HW#5, after corrections since we are no
  longer looking for semantic bugs any more. The rubric:
  <pre>
.zip Compiles w/no warnings:         __/1
Valgrind is clean:                   __/2
Exe named j0 writes .ic files:       __/3
Generates intermediate code/exprs:   __/4
Generates intermediate code/gotos:   __/4
Generates intermediate code/funcs:   __/3
Generates intermediate code/decls:   __/3
  </pre>
-->

<dt>
I'm starting to come across certain 3-address instructions that we haven't
seen examples of yet, mainly the ones for branches and conditionals. Would
we be able to talk about some examples in class possibly? If not, could I
get an example for something like the BLT instruction in an if statement?

<dd>

BLT stands for Branch-if-less-than. It takes two operands compares them and
if src1 is less than src2, it jumps the instruction pointer to the
destination (the 3rd address is a label, i.e. a code region offset). It is
kind of interesting to compare this with X86_64.
<table><tr><th>Intermediate<th>Final
<tr><td><pre>
	BLT loc:16,const:5,lab:32
</pre>
<td><pre>
	cmpq $5,-24(%rbp)
	jg .L32
	... code for a then-part
.L32:
</pre>
</table>
</dl>

<ul>
<li> Three-address code is a bit higher-level than X86_64
<li> no registers in three address code, just a clean conditional branch
<li> X86_64 makes you do an explicit compare instruction
<li> the various X86_64 conditional branch instructions depend on the
     logical combinations of the four flags set by cmp in a
     condition code flag register.
</ul>


<h3> Native Code Generation Examples </h3>

<h4> Reusing a Register </h4>

Consider the statement:
<pre>   a = a+b+c+d+e+f+g+a+c+e;
</pre>
A naive three address code generator would generate a
lot of temporary variables here, one per addition operator, when
in actuality one big number is being added.
How many registers does the expression need?  Some variables
are referenced once, some twice.  GCC (32-bit) generates:
<p>

</p><pre>	movl	b, %eax
	addl	a, %eax
	addl	c, %eax
	addl	d, %eax
	addl	e, %eax
	addl	f, %eax
	addl	g, %eax
	addl	a, %eax
	addl	c, %eax
	addl	e, %eax
	movl	%eax, a
</pre>

<p>
Just for fun, the <A href="abc.u.html">corresponding .u file</A>, with
filen/line/column/synt pseudoinstructions removed, and comments added

<p>
<font size="1"> <a name="38">lecture #38</a> began here</font>
</p><p>
<p>

<p>

Now consider
</p><pre>   a = (a+b)*(c+d)*(e+f)*(g+a)*(c+e);
</pre>
How many registers are needed here?
<pre>	movl	b, %eax
	movl	a, %edx
	addl	%eax, %edx
	movl	d, %eax
	addl	c, %eax
	imull	%eax, %edx
	movl	f, %eax
	addl	e, %eax
	imull	%eax, %edx
	movl	a, %eax
	addl	g, %eax
	imull	%eax, %edx
	movl	e, %eax
	addl	c, %eax
	imull	%edx, %eax
	movl	%eax, a
</pre>

And now this:
<pre>   a = ((a+b)*(c+d))+((e+f)*(g+a))+(c*e);
</pre>
which compiles to
<pre>	movl	b, %eax
	movl	a, %edx
	addl	%eax, %edx
	movl	d, %eax
	addl	c, %eax
	movl	%edx, %ecx
	imull	%eax, %ecx
	movl	f, %eax
	movl	e, %edx
	addl	%eax, %edx
	movl	a, %eax
	addl	g, %eax
	imull	%edx, %eax
	leal	(%eax,%ecx), %edx
	movl	c, %eax
	imull	e, %eax
	leal	(%eax,%edx), %eax
	movl	%eax, a
</pre>


<h3> Brief Comparison of 32-bit and 64-bit x86 code </h3>

What can be gleaned from this side-by-side of 32-bit and 64-bit assembler
for a=a+b+c+d+e+f+g+a+c+e.
Note that the actual variable names are in the assembler because the variables
in question are globals.
<p>

<table border="">
<tbody><tr>
<th> x86 32-bit
</th><th> x86_64
</th></tr><tr>
<td>
<pre>	movl	b, %eax
	addl	a, %eax
	addl	c, %eax
	addl	d, %eax
	addl	e, %eax
	addl	f, %eax
	addl	g, %eax
	addl	a, %eax
	addl	c, %eax
	addl	e, %eax
	movl	%eax, a
</pre>
</td><td>
<pre>	movq	a(%rip), %rdx
	movq	b(%rip), %rax
	addq	%rax, %rdx
	movq	c(%rip), %rax
	addq	%rax, %rdx
	movq	d(%rip), %rax
	addq	%rax, %rdx
	movq	e(%rip), %rax
	addq	%rax, %rdx
	movq	f(%rip), %rax
	addq	%rax, %rdx
	movq	g(%rip), %rax
	addq	%rax, %rdx
	movq	a(%rip), %rax
	addq	%rax, %rdx
	movq	c(%rip), %rax
	addq	%rax, %rdx
	movq	e(%rip), %rax
	leaq	(%rdx,%rax), %rax
	movq	%rax, a(%rip)
</pre>
</td></tr></tbody></table>

</p><p>

Q: Should we be disappointed that the 64-bit code looks a lot longer?
</p><p>
A: Maybe instead we should be <em>fascinated</em>.
</p><ul>
<li> Looks can be deceiving; x86_64 tends to run a lot faster than x86
</li><li> Instruction prefetch on x86_64 is extensive; instructions that use
     register operands are short and many may be prefetched together.
</li><li> Superscalar architectures can execute multiple instructions in parallel
</li><li> The instructions selected here may be specifically maximizing the
     superscalar behavior
</li></ul>


<p>

The globals are declared something like the following.
</p><ul>
<li><code>.comm</code> stands for data in a "common" (a.k.a. global data) section.
</li><li><code>.globl</code> and <code>.type</code> are used for functions, and are really part of
the function header before the function code starts.
</li></ul>

If you allocated your globals as a region, you might have one .comm of 56
bytes named globals (or whatever) and give the addresses of your globals as
numbers such as <code>globals+32</code>.  Names are nicer but having to
treat globals and locals very differently is not.

<p>
</p><pre>	.comm	a,8,8
	.comm	b,8,8
	.comm	c,8,8
	.comm	d,8,8
	.comm	e,8,8
	.comm	f,8,8
	.comm	g,8,8
	.text
.globl main
	.type	main, @function
</pre>


<h3> Brief Comparison of x86-64 globals vs. locals </h3>

How does this difference inform, and affect, what we might want in
our three-address code?
<p>

<table border="">
<tbody><tr>
<th> x86_64 local vars
</th><th> x86_64 globals (as per last example)
</th></tr><tr>
<td>
<pre>	movq	-48(%rbp), %rax
	movq	-56(%rbp), %rdx
	leaq	(%rdx,%rax), %rax
	addq	-40(%rbp), %rax
	addq	-32(%rbp), %rax
	addq	-24(%rbp), %rax
	addq	-16(%rbp), %rax
	addq	-8(%rbp), %rax
	addq	-56(%rbp), %rax
	addq	-40(%rbp), %rax
	addq	-24(%rbp), %rax
	movq	%rax, -56(%rbp)
</pre>
</td><td>
<pre>	movq	a(%rip), %rdx
	movq	b(%rip), %rax
	addq	%rax, %rdx
	movq	c(%rip), %rax
	addq	%rax, %rdx
	movq	d(%rip), %rax
	addq	%rax, %rdx
	movq	e(%rip), %rax
	addq	%rax, %rdx
	movq	f(%rip), %rax
	addq	%rax, %rdx
	movq	g(%rip), %rax
	addq	%rax, %rdx
	movq	a(%rip), %rax
	addq	%rax, %rdx
	movq	c(%rip), %rax
	addq	%rax, %rdx
	movq	e(%rip), %rax
	leaq	(%rdx,%rax), %rax
	movq	%rax, a(%rip)
</pre>
</td></tr></tbody></table>




<!--
<h3>Mailbag</h3>
<dl>

<dt>I am hoping for some clarification on exactly what action is associated
  with array instantiation. The production is:
  <pre>Name '=' NEW Type '[' Literal ']' .. alctree($1, $4, $6)</pre>
I had initially started this as an <code>O_ASN</code>
generation but I'm not sure if that is entirely correct. Primarily I'm not
sure what child node addresses would need to be passed to <code>gen()</code>
for this. Am I approaching this the wrong way?
<dt> Great question. Our lecture notes today maybe talk about <code>new</code>,
  and maybe they will answer better than this. But...
  <p>
<code>new</code> allocates memory from the heap. Most compilers will call an
    underlying function for this.  If the size of int is 8 bytes per array element,
<pre>x = new int [10]</pre>
might get translated into: the code to evaluate the right-hand side, followed by
the <code>O_ASN</code> you were thinking about.
<p>
How do you evaluate the righthandside?  Allocate a temporary variable for the result,
  and generate code to call the heap allocator and store the result in the temp:

<pre>param const:80
call malloc,1,tempvar
asn x,tempvar</pre>

Honestly, there might be one or more things wrong here; can to point out any?

</dl>
-->

<h3>Parameters</h3>

In final code, do parameters look like locals?
<p>

Consider the following example. Note that "long" is used to more closely
resemble our "everything is a 64-bit value" mind-set.

</p><pre>#include &lt;stdio.h&gt;

long f(long,long,long);

int main()
{
   long rv = f(1, 2, 3);
   printf("rv is %ld\n", rv);
}

long f(long a, long b, long c)
{
   long d, e, f, g;
   d = 4; e = 5; f = 6; g = 7;
   a = ((a+b)*(c+d))+(((e+f)*(g+a))/(c*e));
   return a;
}
</pre>

for which the generated code was

<pre>	.file	"paramdemo.c"
	.text
	.section	.rodata
.LC0:
	.string	"rv is %ld\n"
	.text
	.globl	main
	.type	main, @function
main:
.LFB0:
	.cfi_startproc
	pushq	%rbp              <font color=red># save old frame pointer</font>
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp        <font color=red># set new frame pointer</font>
	.cfi_def_cfa_register 6
	subq	$16, %rsp         <font color=red>make 16 bytes (two words) of locals</font>
	movl	$3, %edx          <font color=red>"push" parameters back to front, first 6 in registers</font>
	movl	$2, %esi             <font color=red>note implied sign extension</font>
	movl	$1, %edi
	call	f                 <font color=red>call normal func</font>
	movq	%rax, -8(%rbp)    <font color=red>store return in rv</font>
	movq	-8(%rbp), %rax    <font color=red>LOL</font>
	movq	%rax, %rsi        <font color=red>"push" parameter 2</font>
	leaq	.LC0(%rip), %rdi  <font color=red>"push" parameter 1</font>
	movl	$0, %eax          <font color=red>vararg # float parms</font>
	call	printf@PLT        <font color=red>call shared lib func</font>
	movl	$0, %eax          <font color=red>implicit return value is 0</font>
	leave                     <font color=red>restore frame pointer</font>
	.cfi_def_cfa 7, 8
	ret                       <font color=red>implicit return</font>
	.cfi_endproc              <font color=red>end pseudo-instruction</font>
.LFE0:                            <font color=red>end of function label 0</font>
	.size	main, .-main      <font color=red>end pseudo-instruction</font>
	.globl	f           
	.type	f, @function
f:
.LFB1:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp        <font color=red>frame pointer but no local allocation!?!</font>
	.cfi_def_cfa_register 6
	movq	%rdi, -40(%rbp)   <font color=red>pop param 1 to "a"</font>
	movq	%rsi, -48(%rbp)   <font color=red>pop param 2 to "b"</font>
	movq	%rdx, -56(%rbp)   <font color=red>pop param 3 to "c"</font>
	movq	$4, -32(%rbp)     <font color=red>initialize d</font>
	movq	$5, -24(%rbp)     <font color=red>initialize e</font>
	movq	$6, -16(%rbp)     <font color=red>initialize f</font>
	movq	$7, -8(%rbp)      <font color=red>initialize g</font>
	movq	-40(%rbp), %rdx
	movq	-48(%rbp), %rax
	leaq	(%rdx,%rax), %rcx     <font color=red>a+b</font>
	movq	-56(%rbp), %rdx
	movq	-32(%rbp), %rax
	addq	%rdx, %rax            <font color=red>c+d</font>
	imulq	%rax, %rcx            <font color=red>(a+b)*(c+d)</font>
	movq	-24(%rbp), %rdx
	movq	-16(%rbp), %rax
	leaq	(%rdx,%rax), %rsi     <font color=red>e+f</font>
	movq	-8(%rbp), %rdx
	movq	-40(%rbp), %rax
	addq	%rdx, %rax            <font color=red>g+a</font>
	imulq	%rsi, %rax            <font color=red>(e+f)*(g+a)</font>
	movq	-56(%rbp), %rdx
	movq	%rdx, %rdi
	imulq	-24(%rbp), %rdi       <font color=red>c*e</font>
	cqto
	idivq	%rdi
	addq	%rcx, %rax
	movq	%rax, -40(%rbp)       <font color=red>assign a</font>
	movq	-40(%rbp), %rax       <font color=red>use a as return val</font>
	popq	%rbp
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc
.LFE1:
	.size	f, .-f
	.ident	"GCC: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0"
	.section	.note.GNU-stack,"",@progbits
</pre>

<ul>
<li> The first 6 (perhaps more if there are floats) parameters are passed in
registers, but you can allocate local variable space for them, and copy them
into their local space, after which they can be treated exactly like other
locals. Even when that is kinda dumb.
<li> Differences in code generation for "leaf functions" than for the normal
  general case: no %rsp assignment, simpler frame pointer restore.
  You do not have to (and are not expected to) do these as a special case,
  but determining whether a function is a "leaf" is pretty easy.
</ul>

</p>


</p><h3> Aside on .cfi* assembler directives </h3>

<ul>
<li> Explanation of
     <a href="http://www.logix.cz/michal/devel/gas-cfi/">CFI directives</a>
     (CFI stands for Call Frame Information)
</li><li> Summary: the .cfi* assembler pseudoinstructions are used for
exception handling. You can get rid of them using the gcc flag
-fno-asynchronous-unwind-tables. Code still assembles and runs without them.
</li></ul>



</p><h3> Creating an object via <code>new</code></h3>

Consider the following C++ example of final code for an object
constructor. Executing the reserved word <code>new</code> from 
function <code>main()</code> calls two functions to
create an object in the heap (via <code>new</code>):

<dl>
<dt> _Znwm
</dt><dd>  similar to a <code>malloc()</code>; it takes an integer parameter
(constant 16, the # of bytes to allocate) and returns a pointer
</dd><dt> _ZN1CC1Ev
</dt><dd> a call to a C++ constructor function, with an implicit/added first
parameter for <code>this</code>, the object instance that the member
function is working on.
</dd></dl>

<h3> "new" in final code FYI </h3>

<pre>class C {
  private: long x, y;
  public:  C() { x=3; y=4; }
};

int main()
{
   C *a = new C;
}
</pre>

generates

<pre>	.file	"new.cpp"
	.section	.text._ZN1CC2Ev,"axG",@progbits,_ZN1CC5Ev,comdat
	.align 2
	.weak	_ZN1CC2Ev
	.type	_ZN1CC2Ev, @function
_ZN1CC2Ev:
.LFB1:
	.cfi_startproc
	.cfi_personality 0x3,__gxx_personality_v0
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	movq	%rdi, -8(%rbp)
	movq	-8(%rbp), %rax
	movq	$3, (%rax)
	movq	-8(%rbp), %rax
	movq	$4, 8(%rax)
	leave
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc
.LFE1:
	.size	_ZN1CC2Ev, .-_ZN1CC2Ev
	.weak	_ZN1CC1Ev
	.set	_ZN1CC1Ev,_ZN1CC2Ev
	.text
.globl main
	.type	main, @function
main:
.LFB3:
	.cfi_startproc
	.cfi_personality 0x3,__gxx_personality_v0
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%rbx
	subq	$24, %rsp
	movl	$16, %edi
	.cfi_offset 3, -24
	call	_Znwm
	movq	%rax, %rbx
	movq	%rbx, %rax
	movq	%rax, %rdi
	call	_ZN1CC1Ev
.L5:
	movq	%rbx, -24(%rbp)
	movl	$0, %eax
	addq	$24, %rsp
	popq	%rbx
	leave
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc
.LFE3:
	.size	main, .-main
	.ident	"GCC: (GNU) 4.4.7 20120313 (Red Hat 4.4.7-3)"
	.section	.note.GNU-stack,"",@progbits
</pre>

As you may observe: the final code for a <code>new</code> calls a memory
allocator (nwm) whose return value (%rax) gets copied in as a parameter
(%rdi) to the constructor (N1CC1Ev), with an interesting side trip to %rbx.

<h3> On C/C++ Calling Convention and Order of Passed Parameters </h3>

In compilers, the calling conventions are the set of rules by which parameters
and return values are communicated between caller and callee. The calling
conventions also cover things like whether the caller or the callee has to
save and restore specific registers as part of the process of call/return.

<ul>
<li> a good <a href="https://en.wikipedia.org/wiki/X86_calling_conventions">general discussion</a> is available on Wikipedia
</li><li> Each C compiler makes its own rules. We could do what we want unless we
need to be compatible with another compiler to call their library functions,
in which case we have to follow their calling conventions
</li><li> In C/C++, parameters are passed in reverse order
</li><li> (as we have seen,) in gcc/g++, several parameters are passed in
     registers, but generally get allocated local region space and saved there
     by callee
</li><li> in gcc/g++ the callee explicitly restores stack and old call frame,
     the RET instruction doesn't do that magically, it just manages to
     restore the program counter register back to the caller.
</li><li> In (newer versions of) G++, the parameter section is 16-byte aligned
</li></ul>

<h3> How <code>this</code> looks and is used inside member functions </h3>

<ul>
<li> it is the first parameter, so it is passed in %rdi
</li><li> g++ seems to reserve local memory space and copy/save the registers
     into that local memory space for ALL parameters passed in registers, so
     it does that for <code>this</code>
</li><li> it may make it more likely that you run out of registers to pass all your
     parameters in, and are passing later regular paramters on the stack.
</li><li> references (through <code>this</code>) to member variables are done using
     the "usual" indirect addressing mode, which takes an optional small
     constant as a byte offset when reading/writing using a pointer.  If the
     <code>this</code> pointer is in %rax and our byte offset for a member
     variable is 8, then <code>8(%rax)</code> is the assembler syntax to
     read or write to that variable.
</li></ul>


<h3> About name mangling in C++ vs. your compiler </h3>

<ul>
<li> C++ has to name mangle because it does function overloading.
</li><li> your compiler doesn't have to use the C++ _Znwm, it can call
     <code>malloc()</code> for all I care
</li><li> your compiler almost doesn't have to name mangle at all, what
     is the exception?
</li></ul>

</p>


<h3>More about LEAL</h3>

In a previous example, complicated arithmetic drove (some past version of)
GCC to start "leal'ing".
<ul>
<li>leal (load effective address) is a complex instruction usually used for
pointer arithmetic, i.e. its output is usually a pointer.
</li><li> due to x86 CISC addressing modes, leal can actually add two registers,
multiplying one of those registers by 1, 2, 4, or 8, and then adding
a constant offset in as well.  It is a "more than 3 address instruction".
</li><li> the instruction selection module of gcc knows it can be used for
addition.
</li><li>Unlike "add" instruction, it does not set the condition flag,
</li><li>This property might allow it to execute in parallel with some
other arithmetic operation that <em>does</em> use the condition flag.
So sure enough: it (potentially) improves superscalar execution, and
gcc/g++ are smart enough to use it instead of ADD sometimes.
</li></ul>
<p>

Lastly (for now) consider:
</p><pre>   a = ((a+b)*(c+d))+(((e+f)*(g+a))/(c*e));
</pre>
The division instruction adds new wrinkles.  It operates on an implicit
register accumulator which is twice as many bits as the number you divide
by, meaning 64 bits (two registers) to divide by a 32-bit number.  Note
in this code that 32-bit gcc would rather spill than use %ebx.  %ebx is
reserved by the compiler for some (hopefully good) reason.
%edi and %esi are similarly ignored/not used.
<table border="">
<tbody><tr>
<th> 32-bit </th><th> 64-bit
</th></tr><tr>
<td>
<pre>	movl	b, %eax
	movl	a, %edx
	addl	%eax, %edx
	movl	d, %eax
	addl	c, %eax
	movl	%edx, %ecx
	imull	%eax, %ecx
	movl	f, %eax
	movl	e, %edx
	addl	%eax, %edx
	movl	a, %eax
	addl	g, %eax
	imull	%eax, %edx
	movl	c, %eax
	imull	e, %eax
	movl	%eax, -4(%ebp)
	movl	%edx, %eax
	cltd
	idivl	-4(%ebp)
	movl	%eax, -4(%ebp)
	movl	-4(%ebp), %edx
	leal	(%edx,%ecx), %eax
	movl	%eax, a
</pre>
</td><td>
<pre>	pushq	%rbx
	subq	$88, %rsp
	movq	$1, -72(%rbp)
	movq	$2, -64(%rbp)
	movq	$3, -56(%rbp)
	movq	$4, -48(%rbp)
	movq	$5, -40(%rbp)
	movq	$6, -32(%rbp)
	movq	$7, -24(%rbp)
	movq	-64(%rbp), %rax
	movq	-72(%rbp), %rdx
	leaq	(%rdx,%rax), %rcx
	movq	-48(%rbp), %rax
	movq	-56(%rbp), %rdx
	leaq	(%rdx,%rax), %rax
	imulq	%rax, %rcx
	movq	-32(%rbp), %rax
	movq	-40(%rbp), %rdx
	leaq	(%rdx,%rax), %rbx
	.cfi_offset 3, -24
	movq	-72(%rbp), %rax
	movq	-24(%rbp), %rdx
	leaq	(%rdx,%rax), %rax
	imulq	%rbx, %rax
	movq	-56(%rbp), %rdx
	movq	%rdx, %rbx
	imulq	-40(%rbp), %rbx
	movq	%rbx, -88(%rbp)
	movq	%rax, %rdx
	sarq	$63, %rdx
	idivq	-88(%rbp)
	leaq	(%rcx,%rax), %rax
	movq	%rax, -72(%rbp)
	movl	$.LC0, %eax
	movq	-72(%rbp), %rdx
	movq	%rdx, %rsi
	movq	%rax, %rdi
	movl	$0, %eax
	call	printf
	addq	$88, %rsp
	popq	%rbx
</pre>
</td></tr></tbody></table>

In the 32-bit version, you finally see some register spilling.
In the 64-bit version, there is
<ul>
<li> saving a register so you can use it (%rbx)
</li><li> allocating a whole local region of 88 bytes
</li><li> storing immediate values into main memory
</li><li> addition by leaq'ing registers
</li></ul>


<h3> <code>LEAVE</code> instruction </h3>

In our example of using <code>new</code> we saw a LEAVE instruction before
the function returned.  LEAVE restores the frame pointer
to the caller's value, something like

<pre>movq rsp, rbp ; set top of stack back to where caller had it
popq rbp      ; set base pointer back to saved value at (%rsp)
</pre>

Interestingly, there is a corresponding ENTER instruction, but g++ does not
tend to use it because it is slower than corresponding lower-level operations
like <code>subq $nbytes, %rsp</code>.

<h3> Chapter 10 of this <a href="https://www3.nd.edu/~dthain/compilerbook/">free compiler book</a> from Doug Thain</h3>

For what its worth, professor Thain provides a good introduction to
x86_64 assembler.


</p><h3> Brief Comment on HW Resubmissions </h3>

At various points in this course you have a choice between completing/fixing
a previous homework, or working on the next homework.  But sometimes you
have to complete/fix an old homework for the next one to be implementable.
<!--
In addition to your HW#4/#5, I will accept up to 2 old/late homework
resubmissions from you from now up until the end of dead week.  I will award
full credit for such late submissions. -->
I have been accepting resubmissions this semester, to make corrections,
restoring points up to a "C" grade for a given assignment.
Please test your work prior to each resubmission; I won't be able to
just keep regrading it until it passes.


<h3> More on DIV instruction </h3>

When I looked for more, I found this
<a href="http://www.cs.uaf.edu/2009/fall/cs301/support/x86_64/index.html">
Cheat Sheet</a>, which pointed at the big books
(<a href="https://www.cs.nmt.edu/~jeffery/courses/423/instructionsAM.pdf">A-M</a><a href="https://www.cs.nmt.edu/~jeffery/courses/423/instructionsNZ.pdf">N-Z</a>).

<ul>
<li> The cheat sheet says div divides reg. ax by [src], ratio in ax, remainder in
dx.
</li><li> It also says dx must be 0 to start or you get a SIGFPE.
</li><li>  The big book
says your basic full-size divide instruction divides a big value stored in
a pair of registers (32 bit: EDX:EAX or 64 bit: RDX:RAX), by which point I
am thinking I have to give the general introduction to X86_64 before this
should be remotely understandable.
</li></ul>

<h3> Helper Function for Managing Registers </h3>

Define a <code>getreg()</code> function that returns a location L
to hold the value of x for the assignment <br>  <code>x := y op z</code>

<ol>
<li> if y is in a register R that holds the value of no other names,
AND y is not live after the execution of this instruction, THEN
return register R as your location L
</li><li> ELSE return an empty register for L if there is one
</li><li> ELSE if x has a next use in the block or op is an operator
     that requires a register (e.g. indexing), find an occupied
     register R. Store R into the proper memory location(s), update
     the address descriptor for that location, and return R
</li><li> if x is not used in the block, or no suitable occupied register
can be found in (3), return the memory location of x as L.
</li></ol>


<p>
<font size="1"> <a name="39">lecture #39</a> began here</font>
</p>

<p>
<h3> How to Compute your Pre-Final CSE 423 Grade </h3>

<ol>
<li>
  Each Graded Item (HW, Exam, Sum of Labs) is Normalized in the range
  [0.0,1.0] Against the High Scores
  obtained by a class member for that assignment:
<table border>
<tr><th>Graded Item<th>Max
<tr><td>HW#1       <td> 1
<tr><td>HW#2       <td> 20
<tr><td>HW#3       <td> 19
<tr><td>Midterm    <td> 245
<tr><td>HW#4       <td> 18
<tr><td>HW#5       <td> 18
<tr><td>HW#6       <td> ??
<tr><td>Final      <td> ?
<tr><td>Labs       <td> 30
</table>

<li> Each normalized Graded Item is Multiplied Against a Weight. The weights
  are percentages of the total grade. In the end they will add to 100.
<table border>
<tr><th>Graded Item<th>Weight
<tr><td>HW#1       <td> 2
<tr><td>HW#2       <td> 8
<tr><td>HW#3       <td> 8
<tr><td>Midterm    <td>25
<tr><td>HW#4       <td> 9
<tr><td>HW#5       <td> 9
<tr><td>HW#6       <td> 10
<tr><td>Final      <td>25
<tr><td>Labs       <td> 4
</table>

<li> Weighted scores are Summed. For each gradable item, you got some fraction
     of the total weight that that item was worth.

<li> Sum is divided by total weight and multiplied by 100 to give your overall
     percentage against an "ideal peer".

<li> Jeffery subjectively decides whether the high "A" is, and how far
     to draw the ABCD lines 10% apart,
     12% apart, 15% apart, 20%, etc.  For this semester, suppose the "A" line
     is at 90% of the "ideal peer", the grades are 15% apart.
<table border>
  <tr><th>Overall Percentage<th>Grade
  <tr><td> 90+ <td> A
  <tr><td> 85+ <td> A-
  <tr><td> 80+ <td> B+
  <tr><td> 75+ <td> B
  <tr><td> 70+ <td> B-
  <tr><td> 65+ <td> C+
  <tr><td> 60+ <td> C
  <tr><td> 55+ <td> C-
  <tr><td> 50+ <td> D+
  <tr><td> 45+ <td> D
  <tr><td> 40+ <td> D-
</table>
</ol>

Example: at the moment, 68% of the total weights have been graded.
A student computes a weighted sum of 47, 47/68 = 69%. At the moment,
this student is on the borderline between a C+ and a B-.

<h3>Mailbag</h3>

<dl>
<dt>Can you help with split(), join(), and isdigit()?
  <dd>

<ol>
  <li> split(), from
<A href="http://www.mitchellsoftwareengineering.com/icon/icon.sli.pdf">
    http://www.mitchellsoftwareengineering.com/icon/icon.sli.pdf</A>
(hacked by Dr. J, might still be over-flowery)
<pre>
procedure split(s, delimiters : ' \t', keepall)
  local w, ws := [], addproc := put, nullproc

  otherproc := if \keepall then put else 1

  if delimiters := (any(delimiters, s[1]) & ~dlms) then
    otherproc :=: addproc

  s ? while w := tab(many(delimiters := ~dlms)) do {
    addproc(ws, w)
    otherproc :=: addproc
    }
  return ws
end
</pre>

<li> join(), made up before class
<pre>
procedure join(separator, items[])
  if type(items[1]) == "list" then {
     return join ! (push(items[1], separator))
     }

  if *items = 0 then return ""
  if *items = 1 then return items[1]
  result := items[1]
  every result ||:= separator || items[2 to *items]
  return result
end
</pre>

<li> isdigit(c)
<pre>
procedure isdigit(s)
  return any(&digit, s)
end
</pre>

</ol>
</dl>

<h3> Putting It All Together: A Simple Code Generator </h3>

<ul>
<li> Register allocation will be done only within a basic block.
     All variables that are live at the end of the block are stored
     in memory if not already there.
</li><li> Data structures needed:
<dl>
<dt> Register Descriptor
</dt><dd> Keeps track of what is in each register. Consulted when a new register
is needed. All registers assumed empty at entry to a block.
</dd><dt> Address Descriptors
</dt><dd> Keep track of the location(s) where the current value of a name can be
found at runtime. Locations can be registers, memory addresses, or stack
displacements. (can be kept in the symbol table).
</dd></dl>
</li></ul>
<p>

Example
</p><p>
</p><pre>// make an array (12?) of these:
struct regdescrip {
   char name[12]; // name to use in codegen, e.g. "%rbx"
   int status;    // 0=empty, 1=loaded, 2=dirty, 4=live, ...
   struct address addr;
   };
// upgrade symbol table entry to use these instead of struct address
struct addr_descrip {
   int status;    // 0=empty, 1=in memory, 2=in register, 3=both
   struct reg_descrip *r; // point at an elem in reg array. could use index.
   struct address a;
   };
</pre>

<h3> Code Generation Algorithm </h3>

For each three-address statement of the form <br>
<code>x := y op z</code>:

<ol>
<li> Use <code>getreg()</code> to determine location L where the
     result of the computation <code>y op z</code> should be stored.
</li><li> Use the address descriptor for y to determine y', a current location for
y. If y is currently in a register, use the register as y'. If y is not already
in L, generate the instruction <code>MOV y',L</code> to put a copy of y in L.
</li><li> Generate the instruction <code>OP z',L</code> where z' is a current location for z.
Again, prefer a register location if z is currently in a register.
<p> Update the descriptor of x to indicate that it is in L. If L is a register,
update its descriptor to indicate that it contains x. Remove x from all other
register descriptors.
</p></li><li> If y and/or z have no next uses and are in registers, update the register
descriptors to reflect that they no longer contain y and/or z respectively.
</li></ol>


<h3> Register Allocation </h3>

Need to decide:
<ul>
<li> which values should be kept in registers (register allocation)
</li><li> which register each value should be in (register assignment)
</li></ul>

<h4> Approaches to Register Allocation </h4>

<ol>
<li> Partition the register set into groups that are use for different kinds
of values. E.g. assign base addrs to one group, pointers to the stack to
another, etc. <p>
Advantage: simple<br>
Disadvantage: register use may be inefficient
</p></li><li> Keep frequently used values in registers, across block boundaries. E.g.
assign some fixed number of registers to hold the most active values in each
inner loop.<p>
Advantage: simple to implement<br>
Disadvantage: sensitive to # of registers assigned for loop variables.
</p></li></ol>

</p><h3> Challenge Question we Ended with Last Time </h3>

So, how can you know what are the frequently used variables in a function?

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

<ul>
<li> Count the number of occurrences in source code?  (easy static analysis,
     but bad results)
</li><li> Do math proofs of the frequency relationships between variables
     (hard static analysis)
</li><li> Run the program on representative inputs, and count all uses
     of variables in that function. (dynamic analysis)
</li><li> Make a crude approximation or estimate (easy static analysis)
</li></ul>


<h3> x86_64 Floating Point </h3>

<h4> Float Operations </h4>

There is <a href="http://web.cecs.pdx.edu/~apt/cs322/x86-64.pdf">
a useful set of notes</a> from Andrew Tolmach of Portland State University.
Arithmetic operations on floats
have different opcodes, and results have to be stored in
floating point registers, not integer registers.

<pre>	movsd	-56(%rbp), %xmm0
	movapd	%xmm0, %xmm1
	addsd	-48(%rbp), %xmm1
</pre>

<h4> Float Constants </h4>

Doubles are the same 64-bit size as longs.  They can be loaded into memory
or registers using the normal instructions like movq.  A spectacular x86_64
opcode named movabsq takes an entire floating point constant as an immediate
(bit pattern given as a decimal integer!) and stores it in a register.
(Q: What C code (or library function) would take your double and
produce the equivalent decimal integer string?)

<pre>	movabsq	$4620355447710076109, %rax
	movq	%rax, -8(%rbp)
</pre>



<h3> Simple Machine Model </h3>

This model is probably relevant for selecting between equivalent sequences
of instructions but is presented here as food for thought regarding which
variables deserve to stay in registers.

<dl>
<dt> Instruction Costs
</dt><dd> for an instruction I, cost(I) = 1 + sum(cost(operands(I))) <p>
operand costs:
</p><ul>
<li> if operand is a register, cost = 0
</li><li> if operand is memory, cost = 1
</li></ul>
<br>
</dd><dt> Usage Counts
</dt><dd> In this model, each reference to a variable x accrues a savings of
1 if x is in a register.

<ul>
<li> For each use of x in a block that is <b>not preceded by an assignment</b>
in that block, savings = 1 if x is in a register.
</li><li> If x is live on exit from a block in which it is assigned a value,
and is allocated a register, then we can avoid a store instruction (cost = 2)
at the end of the block. <p>

Total savings for x ~ sum(use(x,B) + 2 * live(x,B) for all blocks B)
</p><p>

This is very approximate, e.g. loop frequencies are ignored.
</p></li></ul>
</dd></dl>
<p>

</p><h4>Cost savings flow graph example</h4>

For the following flow graph, how much savings would be earned by leaving
variables (a-f) in a register across basic blocks?
<p>
<img src="liveness.png">

<table>
<tbody><tr><th> Savings </th><th> B1 </th><th> B2 </th><th> B3 </th><th> B4 </th><th> Total
</th></tr><tr><td>    a	 </td><td> 2	 </td><td> 1	 </td><td> 1	 </td><td> 0	 </td><td> 4
</td></tr><tr><td>    b	 </td><td> 2	 </td><td> 0	 </td><td> 2	 </td><td> 2	 </td><td> 6
</td></tr><tr><td>    c	 </td><td> 1	 </td><td> 0	 </td><td> 1	 </td><td> 1	 </td><td> 3
</td></tr><tr><td>    d	 </td><td> 3	 </td><td> 1	 </td><td> 1	 </td><td> 1	 </td><td> 6
</td></tr><tr><td>    e	 </td><td> 2	 </td><td> 0	 </td><td> 2	 </td><td> 0	 </td><td> 4
</td></tr><tr><td>    f	 </td><td> 1	 </td><td> 2	 </td><td> 1	 </td><td> 0	 </td><td> 4
</td></tr></tbody></table>





</p><h3> x86_64 Discussion </h3>

<ul>
<li> <a href="http://www.cs.cmu.edu/~fp/courses/15213-s07/misc/asm64-handout.pdf">machine level programming</a> as taught at CMU
</li><li> 
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/code.html"> Dr. J's TAC-to-x86_64 templates </a> (not finished yet)
</li><li>
<a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html">Intel Developer Manuals</a>
</li></ul>


<h3> For what its worth on Windows 64 </h3>

Warning: the Mingw64 compiler (and possibly other Windows 64-bit c
compilers) do not use the same memory sizes as Linux x86_64!  Beware.
If you were compatible with gcc on Linux you might not be on Windows
and vice versa.


<h3> Three Kinds of Dependence </h3>

In all three of these examples, a dependence relationship implies that
in the program semantics, the second instruction depends on the first
one in some way.
<p>

</p><ul>
<li>  How are they different?
</li><li>How do these affect, e.g., decisions about which registers are in use?
</li><li>What about concurrency/superscalar CPU's ?
</li></ul>
<p>

<table border="">
<tbody><tr><td>
<pre>a = b + c;
...
d = a + e;
</pre>
</td><td>
<pre>a = b + c;
...
b = d + e;
</pre>
</td><td>
<pre>a = b + c;
...
a = d + e;
</pre>
</td></tr></tbody></table>



<!--
<h3> Register Allocation and Graph Coloring </h3>

<ul>
<li> A <em>vertex coloring</em> is an assignment of labels or colors
     to each vertex of a graph such that no edge connects two identically
     colored vertices. 
<li>
A <em>k-coloring</em> of a graph G is a vertex coloring that is an assignment of one of k possible colors to each vertex of G (i.e., a vertex coloring) such that no two adjacent vertices receive the same color. 
<li>
The classic "high-powered" way to do register allocation is by
k-coloring a special kind of dependence/liveness graph of variables.
To do that, one must do a bunch of analysis to
tell which variables are live at the same time.
</ul>

<h3> Register Allocation by Graph Coloring </h3>

When a register is needed but all registers are in use, a register 
has to be freed by storing its contents in memory ("spilling"). <p>

Graph coloring is a systematic way of register allocation and managing
spills. <p>

Graph coloring uses two passes:

<dl>
<dt> Pass 1</ht>
<dd> Target machine instructions are selected as though there are an
infinite number of symbolic registers.
<dt> Pass 2
<dd> Physical registers assigned to symbolic ones in a manner that minimises
the cost of spills. This is done by constructing a <em> register-interference
graph</em> for each procedure, then k-coloring this graph (k = # of registers).
</dl>

<p>


<h3> Register Interference Graphs </h3>

<ul>
<li> nodes: "symbolic registers"
<li> there is an edge connecting two nodes if one is live when the other is
defined
<li> if there are k assignable registers, then we have to try and k-color
the interference graph.
<li> k-colorability is NP-complete in general, but the following heuristic
is efficient in practice:
<ul>
<li> if a node n has less than k neighbors, remove n and its edges from the
graph to get a new graph G': a k-coloring of G' can easily be extended to a
k-coloring of the original graph.
<li> By repeating this process, we either get the empty graph (in which case
we can work backwards to produce a k-coloring of the original graph), or we
get a graph where each node has &gt;= k neighbors: in this case we need to
spill a node, modify the interference graph, and proceed as before.<p>

General rule for spills: avoid introducing code into inner loops.
</ul>
</ul>

<h3> Register Allocation Coloring Example </h3>

Courtesy of those fine folks at
<A href="http://pages.cs.wisc.edu/~cs701-1/NOTES/5.REGISTER-ALLOCATION.html#coloring">University of Wisconsin</A>.
<p>

Their way of thinking about register interference is to define
<em>live ranges</em> === set of all nodes (in a control flow graph)
between definitions and uses.
Actually, feels more like it works back from uses to their definitions,
and merges all overlaps on any given variable.
<p>

OK, so what live ranges occur in the following graph? <p>

<img src="ralloc.gif"><p>

Each live range is one node in a register interference graph, and edges
(denoting interference) connect nodes whose underlying CFG nodesets overlap.
-->

</p>

<A name="callingconventions">
<h3> Review of x86_64 Calling Conventions </h3>
</A>

64-bit x86 was first done by AMD and licensed afterwards by Intel, so it
is sometimes referred to as AMD64.  Warning: Linux and Windows do things
a lot different!

<ul>
<li> <a href="http://en.wikipedia.org/wiki/Calling_convention">Calling conventions</a> in general
</li></ul>


<h3> Final Code Generation Example </h3>

<ul>
<li> <a href="https://www.cs.nmt.edu/~jeffery/courses/423/finalcg.icn">finalcg.icn</a>, a program that generates
     <a href="https://www.cs.nmt.edu/~jeffery/courses/423/tac.s">native code</a>
</li><li> Assemble output with command line such as <code>as -o demo1.o demo1.s</code>
</li><li> needs streamlining, removal of exception directive code per
earlier discussion.
<!--
<li> compare previous with
     <A href="final-tac.icn">TAC-C</A>, whose output looks like
     <A href="final-tac-out.c">this</A>
-->
</li></ul>

<p>

</p><h3> Lessons From the Final Code Generation Example </h3>

<ul>
<li> TAC-to-native-code not that hard; 110 lines netted about half
     the TAC instruction set in procedure final(); many other opcodes very
     similar.
</li><li> Most complexity centers around calls / returns
</li><li> Although you pass parameters in registers, IF YOU CALL ANYTHING, and
     IF YOU USE YOUR PARAMETERS AFTERWARDS, you will
     have to allocate space on the stack for your incoming parameters,
     and save their values to memory before reusing that register.
</li><li> How hard would it be, for each function body, to determine whether it
     calls anything, or is a "leaf" function that does not?  How common are
     such leaf functions?
</li><li> Interesting special case: does a function ever turn around and call
     another function with the same parameters?  How often?  Under what
     circumstances might a compiler exploit this?
</li></ul>

<h3> Reverse Engineering, gcc -S, and Optimization </h3>

I decided to fill in a missing piece of the
<a href="https://www.cs.nmt.edu/~jeffery/courses/423/code.html">x86_64 final code generation template page</a>
that I am providing you, and chose a real easy one: <code>if !x goto L</code>.
I figured it would be a two-instruction analogue of <code>if x goto L</code>.
So I constructed a simple program to try and produce the desired code.

<pre>#include <stdio.h>
int fac(long y)
{
   long x;
   if (!y) goto L;
   printf("hello");
 L:
   return 1;
}
</stdio.h></pre>

<p>
I was frustrated to find seemingly idiotic code as gcc's default: it was
generating an extra jump and an extra label. Eventually, I tried it with -O
just to see what we would get.

</p><p>

The corresponding gcc -S output is as follows:

</p><p>

<table border="">
<tbody><tr><th>gcc -S</th><th>gcc -O -S
</th></tr><tr><td>
<pre>	.file	"foo.c"
	.section	.rodata
.LC0:
	.string	"hello"
	.text
	.globl	fac
	.type	fac, @function
fac:
.LFB0:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	subq	$16, %rsp
	movq	%rdi, -8(%rbp)
	cmpq	$0, -8(%rbp)
	jne	.L2
	jmp	.L3
.L2:
	movl	$.LC0, %edi
	movl	$0, %eax     # num of float args, for vararg funcs
	call	printf
.L3:
	movl	$1, %eax
	leave
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc
.LFE0:
	.size	fac, .-fac
	.ident	"GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-28)"
	.section	.note.GNU-stack,"",@progbits
</pre>
</td><td>
<pre>	.file	"foo.c"
	.section	.rodata.str1.1,"aMS",@progbits,1
.LC0:
	.string	"hello"
	.text
	.globl	fac
	.type	fac, @function
fac:
.LFB11:
	.cfi_startproc
	testq	%rdi, %rdi
	je	.L4
	subq	$8, %rsp
	.cfi_def_cfa_offset 16
	movl	$.LC0, %edi
	movl	$0, %eax     # num of float args, for vararg funcs
	call	printf
.L2:
	movl	$1, %eax
	addq	$8, %rsp
	.cfi_def_cfa_offset 8
	ret
.L4:
	movl	$1, %eax
	ret
	.cfi_endproc
.LFE11:
	.size	fac, .-fac
	.ident	"GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-28)"
	.section	.note.GNU-stack,"",@progbits
</pre>
</td></tr></tbody></table>


</p><h3> Flow Graphs </h3>

In preparation for lectures discussing code optimization, a more detailed
discussion of flow graphs is needed.

<ul>
<li>  A flow graph is a graph in which vertexes are basic blocks
</li><li> There is a distinguished <em>initial</em> node, the basic block
whose leader is the first instruction.
</li><li> There is a directed edge from block B<sub>1</sub> to B<sub>2</sub> if:
<ol>
<li> There is a conditional or unconditional jump from the last statement
     of B<sub>1</sub> to the first statement of B<sub>2</sub>
</li><li> B<sub>2</sub> immediately follows B<sub>1</sub> in the order of the
     program, and B<sub>1</sub> does not end in an unconditional jump.
</li></ol>
</li></ul>

<h3> Flow Graph Example </h3>

<pre>if (x + y &lt;= 10 &amp;&amp; x - y &gt;= 0) x = x + 1;
</pre>

Construct the flow graph from the basic blocks

<p>

<table border="">
<tbody><tr><td><pre>
t<sub>1</sub> := x + y
if t<sub>1</sub> &gt; 10 goto L1

</pre>
</td></tr><tr><td><pre>
t<sub>2</sub> := x - y
if t<sub>2</sub> &lt; 0 goto L1

</pre>
</td></tr><tr><td><pre>
t<sub>3</sub> := x + 1
x := t<sub>3</sub>

</pre>
</td></tr><tr><td><pre>
L1:

</pre>
</td></tr></tbody></table>

</p><h3> Next-Use Information </h3>

<dl>
<dt> use of a name
</dt><dd> consider two statements
<pre>I1: x := ... /* assigns to x */
...
I2: ... := ... x ... /* has x as an operand */
</pre>
such that control <em>can</em> flow from I1 to I2 along some path that has no
intervening assignments to x.  Then, I2 <em>uses</em> the value of x
computed at I1. I2 may use several assignments to x via different paths.

</dd><dt> live variables
</dt><dd> a variable x is <em>live</em> at a point in a flow graph if the
value of x at that point is <em>used</em> at a later point.

</dd></dl>

<h3> Computing Next-Use Information (within a block only)</h3>

<ul>
<li> assume we know which names are live on exit from the block
 (needs dataflow analysis; else assume all nontemporary variables
  are live on exit)
</li><li> scan backwards from the end of the basic block. For each statement
<pre> i:  x := y <em>op</em> z
</pre>
do:
<ol>
<li> attach to stmt. i the current information (from symbol table) about
next use and liveness of x, y, and z
</li><li> in the symbol table, set x to "not live", "no next use"
</li><li> in the symbol table, set y and z to "live", set next use of y,z to i
</li><li> treatment of <code>x := y</code> or <code>x := op y</code> is similar
</li></ol>
Note: order of (2) and (3) matters, x may be on RHS as well
</li></ul>


</p><h3>Old Mailbag</h3>

<dl>

<dt>Could we cover assembly stack allocation/management?
</dt><dd>
Sure. I've pointed you at a lot of resources; here is another, on
<a href="https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64/">Eli Bendersky's site</a>.

<p>
</p><ul>
<li> In the general case, calling arbitrary other code,
ALL registers that hold live values across a call will have to be saved,
and restored after the call.  This sounds incredibly expensive, and is
only getting more expensive as CPUs add more and more registers. In
x86_64, the registers are partitioned into those the caller is
responsible for protecting, and those the callee is responsible for.
</li><li> Good compilers, then, are all about taking shortcuts and doing
the minimum needed for each specific case. A compiler can save costs
on the caller side and on the callee side.
</li><li> Stack registers.  As a reminder, there is an rsp
that is the true top of the stack, and a rbp that is the base pointer
register for the current function call.  The stack grows down.
</li></ul>

<p>


</p></dd><dt>When and what do we have to push and pop from the stack
when we call a function?
</dt><dd>
We (that mens you) should probably look at a bunch of examples, probably by
reverse engineering them with gcc -S, to get a feel for this.  A summary on
which we can expand/correct is:

<ul>
<li> caller pushes parameters.   By default the
first six parameters go into designated registers instead of main memory.
BTW, if you had anything in those registers, you have to save those values
(i.e. push them) before sticking parameters in registers for a new call.
</li><li> caller saves r10/r11 if it us using them.
</li><li> caller executes CALL instruction.
</li><li> CALL instruction pushes return address (IPC) and does a GOTO.
</li><li> Callee pushes (saves) rbp
</li><li> Callee sets rbp to the top of the stack
</li><li> Callee saves other "callee-save" registers if it uses them (rbx,r12-r15)
</li><li> Callee pushes/creates local region, by subtracting N bytes from rsp.
</li><li> Callee by default copies parameters from registers into local space.
</li><li> Callee executes function body.
</li><li> Callee stores return value in rax, if there is one
</li><li> Callee frees local region by adding N bytes to rsp
</li><li> Callee restores rbx, r12-r15 if it uses them
</li><li> Callee restores rsp and rbp for caller via LEAVE, or its equivalent.
</li><li> Callee executes RET, which pops saved IPC and does a GOTO to it.
</li></ul>

</dd><dt>Can we use the stack exclusively for all of our parameters and local
variables?

</dt><dd>
Your compiler can ignore register parameters entirely when you generate code
that calls to and returns from your own functions.  IFF your code needs to call
C library code (such as printf, reads, etc.) you would have to use the
standard calling conventions (including registers) to call those functions
successfully.


</dd></dl>



<h3> Storage for Temporaries </h3>

<ul>
<li> size of activation records grows with the number of temporaries, so
compiler should try to allocate temporaries carefully
</li><li> in general, two temporaries can use the same memory location if they
are not live simultaneously
</li><li> allocate temporaries by examining each in turn and assigning it the
first location in the field for temporaries that does not contain a live
temporary. If a temporary cannot be assigned to a previously created
location, use a new location.
</li></ul>


<h3> Storage for Temporaries Example </h3>

Consider the following (a dot-product code) example. This is a single basic
block, subdivided using the liveness of some non-overlapping temporary
variables.  <p>

<table border="">
<tbody><tr><td>
t1 live</td><td>
<pre>	prod := 0
	i := 1
L3:	t1 := 4 * i
	t2 := a[t1]
</pre>
</td></tr><tr><td>t3 live</td><td>
<pre>	t3 := 4 * i
	t4 := b[t3]
</pre>
</td></tr><tr><td>t5 live</td><td>
<pre>	t5 := t2 + t4
	t6 := prod + t5
</pre>
</td></tr><tr><td>t7 live</td><td>
<pre>	prod := t6
	t7 := i + 1
	i := t7
</pre>
</td></tr><tr><td></td><td>
<pre>	if i &lt;= 20 goto L3
</pre>
</td></tr></tbody></table>

</p><p>
t1, t3, t5, t7 can share the same location.
What about t2, t4, and t6?
</p><p>

Notes:
</p><ul>
<li> the "reusing temporary variables" problem is pretty much the
     same as the register allocation problem
</li><li> optimal allocation is NP-complete in general
</li></ul>





<!--
<h3> Peek at <a href="libctab.h">libctab.h</A> and <A href="libctab.c">libctab.c</A></h3>

<ul>
<li> Did you know that when you invoke the C compiler, you get a
library (-lc) linked in by default even when you did not ask for it?
<li> Similarly, ct can invoke the linker including libctab.o automatically
<li> By the way, in real life a libtab would need to have weirder variable
     names, such as all beginning with __ct__
<li> Using C++ for libctab would make certain aspects better
     (package to protect namespace, destructors to free local tables...)
     but beyond the scope of this class.
</ul>
-->



<h3> <a name="dag">DAG</a> representation of basic blocks </h3>

This concept is useful in code optimization.  Although we are not doing a
homework on optimization, you should understand it to be essential in real
life and have heard and seen a bit of the terminology.


<ul>
<li> Each <em>node</em> of a flow graph (i.e. basic block)
can be represented by a directed acyclic graph (DAG).
</li><li> Why do it?  May enable optimizations...
</li></ul>
<p>

A DAG for a basic block is one with the following labels on nodes:

</p><ol>
<li> leaves are labelled by unique identifiers, either variable names or
constants.
</li><li> interior nodes are labelled by operator symbols
</li><li> nodes are optionally given a sequence of identifiers as labels
(these identifiers are deemed to have the value computed at that node).
</li></ol>

<p>

</p><h4>Example</h4>

For the three-address code

<pre>L:	t1 := 4 * i
	t2 := a[t1]
	t3 := 4 * i
	t4 := b[t3]
	t5 := t2 * t4
	t6 := prod + t5
	t7 := i + 1
	i := t7
	if i &lt;= 20 goto L
</pre>

What should the corresponding DAG look like?

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


<ul>
<li> Chapter 6 of the text presents DAGs constructed from syntax
     trees immediately before, rather than after, three address code.
</li><li> We presented it later than that, because it enables common optimizations.
</li></ul>

<h3> Constructing a DAG </h3>

<u>Input</u>: A basic block.
<p>

<u>Output</u>: A DAG for the block, containing:
</p><ul>
<li> a label for each node, and
</li><li> for each node, a (possibly empty) list of attached identifiers
</li></ul>
<p>

<u>Method</u>: Consider an instruction x := y op z.
</p><ol>
<li> If node(y), the node in the DAG that represents the value of y at that
point, is undefined, then create a leaf labelled y. Let node(y) be this node.
Similar for z.

</li><li> determine if there is a node labelled <u>op</u> with left child node(y)
and right child node(z).  if not, create such a node. let this node be <u>n</u>

</li><li> <ul>
     <li> a) delete x from the list of attached identifiers for node(x) [if defined]
     </li><li> b) append x to the list of attached identifiers for node n (from 2).
     </li><li> c) set node(x) to n
     </li></ul>
</li></ol>

<h3> Applications of DAGs </h3>

<ol>
<li> automatically detects common subexpressions
</li><li> can determine which identifiers have their value used in the block --
these are identifiers for which a leaf is created in step (1) at some  point.
</li><li> Can determine which statements compute values that could be used outside
the block -- these are statements s whose node n constructed in step (2)
still has node(x)=n at the end of the DAG construction, where x is the
identifier defined by S.
</li><li> Can reconstruct a simplified list of 3-addr instructions, taking advantage
of common subexpressions, and not performing copyin assignments of the form
x := y unless really necessary.
</li></ol>

<h3> Evaluating the nodes of a DAG </h3>

<ul>
<li> The evaluation order of the interior nodes of a DAG must be consistent
with a topological sort of the DAG, so that operands are evaluated before an
operator is applied.
</li><li> In the presence of pointer or array assignments, or procedure calls, not
every topological sort may be permissible.
 Example: given a basic block
<pre>x := a[i]
a[j] := y
z := a[i]
</pre>
</li></ul>

The "optimized" basic block after DAG construction and common subexpression
elimination equates x and z, but this behaves incorrectly when i = j.


<p>
<font size="1"> <a name="40">lecture #40</a> began here</font>
</p>

<h3> Grade Extension? </h3>

If you don't have to walk and receive your degree in May,
and have some reportable extenuating circumstance, feel free to request
a grade extension.

<h3> What if my HW#6 submission is a little bit late? </h3>

<ul>
<li> HW#6 due date is based on keeping your finals week open, and
     giving me time to grade projects before Monday night.
<li> I have reserved (sort of) the rest of this week for grading HW#6.
<li> I will not notice/penalize if your HW#6 is a few hours late, since
     it turns out I have an NMT function from 5-7pm.
</ul>

<h3> Code Optimization </h3>

There are major classes of optimization that can significantly speedup
a compiler's generated code.  Usually you speed up code by doing the
work with fewer instructions and by avoiding unnecessary memory reads
and writes. You can also speed up code by rewriting it with fewer gotos.


<h4> Constant Folding </h4>

Constant folding is performing arithmetic at compile-time when the values
are known.  This includes simple expressions such as 2+3, but with more
analysis
some variables' values may be known constants for some of their uses.
<pre>     x = 7;
     ...
     y = x+5;
</pre>

<h4> Common Subexpression Elimination </h4>

Code that redundantly computes the same value occurs fairly frequently,
both explicitly because programmers wrote the code that way, and implicitly
in the implementation of certain language features.
<p>

Explicit:
</p><pre>    (a+b)*i + (a+b)/j;
</pre>

The (a+b) is a common subexpression that you should not have to compute twice.
<p>

Implicit:
</p><pre>    x = a[i]; a[i] = a[j]; a[j] = x;
</pre>

Every array subscript requires an addition operation to compute the memory
address; but do we have to compute the location for a[i] and a[j] twice in
this code?


<h4> Loop Unrolling </h4>

Gotos are expensive (do you know why?).  If you know a loop will
     execute at least (or exactly) 3 times, it may be faster to copy the
     loop body those three times than to do a goto.  Removing gotos
     simplifies code, allowing other optimizations.

<p>

<table border="">
<tbody><tr><th>original</th><th>unrolled</th><th>after subsequent constant folding
</th></tr><tr>
<td>
<pre>for(i=0; i&lt;3; i++) {
   x += i * i;
   y += x * x;
   }
</pre>
</td><td>
<pre>   x += 0 * 0;
   y += x * x;
   x += 1 * 1;
   y += x * x;
   x += 2 * 2;
   y += x * x;
</pre>
</td><td>
<pre>   y += x * x;
   x += 1;
   y += x * x;
   x += 4;
   y += x * x;
</pre>
</td></tr></tbody></table>


</p><h3> Optimization Techniques, cont'd</h3>

<h4> Algebraic Properties </h4>

Implicit in the previous example of loop unrolling was the notion that
certain computations can be simplified by basic math properties.

<p>

<table border="">
<tbody><tr>
<th> name
</th><th> sample
</th><th> optimized as
</th></tr><tr>
<td> identities
</td><td>
<pre>x = x * 1;
x = x + 0;
</pre>
</td><td>
</td></tr><tr>
<td> simplification
</td><td>
<pre>y = (5 * x) + (7 * x);
</pre>
</td><td>
<pre>y = 12 * x;
</pre>
</td></tr><tr>
<td> commutativity
</td><td>
<pre>y = (5 * x) + (x * 7);
</pre>
</td><td>
<pre>y = (5 * x) + (7 * x);
</pre>
</td></tr><tr>
<td> strength reduction
</td><td>
<pre>x = y * 16;
</pre>
</td><td>
<pre>x = y &lt;&lt; 4;
</pre>
</td></tr></tbody></table>

This open-ended category might also include exploits of associativity,
distributive properties, etc.

</p><h4> Hoisting Loop Invariants </h4>

This one requires knowledge, perhaps too much knowledge. I know the following
optimization is safe, but does the compiler know? What would you have
to know/prove in order for this example to be "safe" for a compiler to do?
<p>

<table border="">
<tbody><tr><td>
<pre>for (i=0; i&lt;strlen(s); i++)
   s[i] = tolower(s[i]);
</pre>
</td><td>
<pre>t_0 = strlen(s);
for (i=0; i&lt;t_0; i++)
   s[i] = tolower(s[i]);
</pre>
</td></tr></tbody></table>


</p><h4> Peephole Optimization </h4>

Peephole optimizations look at the native code through a small, moving
window for specific patterns that can be simplified.  These are some of the
easiest optimizations because they potentially don't require any analysis
of other parts of the program in order to tell when they may be applied.
Although some of these are stupid and you wouldn't think they'd come up,
the simple code generation algorithm we presented earlier is quite stupid
and does all sorts of obvious bad things that we can avoid.
<p>

<table border="">
<tbody><tr>
<th> name
</th><th> sample
</th><th> optimized as
</th></tr><tr>
<td> redundant load or store
</td><td>
<pre>MOVE R0,a
MOVE a,R0
</pre>
</td><td>
<pre>MOVE R0,a
</pre>
</td></tr><tr>
<td> dead code
</td><td>
<pre>#define debug 0
...
if (debug) printf("ugh");
</pre>
</td></tr><tr>
<td> control flow simplification
</td><td>
<pre>if a &lt; b goto L1
...
L1: goto L2
</pre>
</td><td>
<pre>if a &lt; b goto L2
...
L1: goto L2
</pre>
</td></tr></tbody></table>



</p><h3> Peephole Optimization Examples </h3>

It would be nice if we had time to develop a working demo program for
peephole optimization, but let's start with the obvious.

<p>

<table border="">
<tbody><tr><th>as generated</th><th>replace with</th><th>comment
</th></tr><tr>
<td>
<pre>	movq	%rdi, -56(%rbp)
	cmpq	$1, -56(%rbp)
</pre>
</td><td>
<pre>	movq	%rdi, -56(%rbp)
	cmpq	$1, %rdi
</pre>
</td><td> reuse n that's already in a register
</td></tr><tr>
<td>
<pre>	cmpq	$1, %rdi
	setle	%al
	movzbl	%al,%eax
	movq	%rax, -8(%rbp)
	cmpq	$0, -8(%rbp)
	jne	.L0
</pre>
</td><td>
<pre>	cmpq	$1, %rdi
	jle	.L0
</pre>
</td><td> 
boolean variables are for wimps.<br>
setle sets a byte register (%al) to contain a boolean <br>
movzbl zero-extends a byte to a long (movsbl sign-extends)
</td></tr><tr>
<td>
<pre>	cmpq	$1, %rdi
	jle	.L0
	jmp	.L1
.L0:
</pre>
</td><td>
<pre>	cmpq	$1, %rdi
	jg	.L1
.L0:
</pre>
</td><td> 
Use fall throughs when possible; avoid jumps.

</td></tr><tr>
<td>
<pre>	movq	%rax, -16(%rbp)
	movq	-16(%rbp), %rdi
</pre>
</td><td>
<pre>	movq	%rax, %rdi
</pre>
</td><td> 
TAC code optimization might catch this sooner
</td></tr><tr>
<td>
<pre>	movq	-56(%rbp), %rax
	subq	$1, %rax
	movq	%rax, %rdi
</pre>
</td><td>
<pre>	movq	-56(%rbp), %rdi
	subq	$1, %rdi
</pre>
</td><td> 
What was so special about %rax again?
</td></tr><tr>
<td>
<pre>	movq	%rax, -40(%rbp)
	movq	-24(%rbp), %rax
	addq	-40(%rbp), %rax
</pre>
</td><td>
<pre>	addq	-24(%rbp), %rax
</pre>
</td><td> 
Addition is commutative.
</td></tr></tbody></table>




</p><h4> Interprocedural Optimization </h4>

Considering memory references across procedure call boundaries;
     for example, one might pass a parameter in a register if both
     the caller and callee generated code knows about it.
<h4> argument culling </h4>
 when the value of a specific parameter is a constant, a custom version
     of a called procedure can be generated, in which the parameter is
     eliminated, and the constant is used directly (may allow additional
     constant folding).

<table border="">
<tbody><tr><td>
<pre>f(x,r,s,1);

int f(int x, float y, char *z, int n)
{
  switch (n) {
  case 1:
     do_A; break;
  case 2:
     do_B; break;
     ...
     }
}
</pre>
</td><td>
<pre>f_1(x,r,s);

int f_1(int x, float y, char *z)
{
   do_A;
}
int f_2(int x, float y, char *z)
{
   do_B;
}
...
</pre>

</td></tr></tbody></table>

<A href="#finalreview">Warp to Final Exam Review</A>


<h3> Code Generation for Input/Output </h3>

This section is on how to generate code for basic
C input/output constructs.

<dl>
<dt> getchar()
</dt><dd> Basic appearance of a call to getchar() in final code:
<pre>	call	getchar
	movl	%eax, <em>destination</em>
</pre>
     Of course, VGo does not have a getchar() function, it reads a line at
     a time.
     A built-in function for reading a line at a time might be built on
     top of this in vgo or in C, but it might be better to call a different
     input function.
</dd><dt> <code>gets()</code> is part of the C standard that permanently encodes
a buffer overrun attack in the language for all time.  However, we could use
<code>fgets(char*,int,FILE*)</code> to implement VGo's input function.
<pre>char *vgoread()
{
   int i;
   char *buf = malloc(4096);
   if (buf == NULL) return NULL; // should do more
   i = fgets(buf, 4095, stdin);
   // should do more
   return buf;
}
</pre>
What-all is wrong with this picture?
</dt><dd>
</dd><dt> printf(s...)
</dt><dd> First parameter is passed in %rdi. An "interesting"
section in the AMD64 reference manuals explains that 32-bit operands are
automatically sign-extended in 64-bit registers, but 8- and 16-bit operands
are <em>not</em> automatically signed extended in 32-bit registers.
If string s has label .LC0
<pre>	movl	$.LC0, %eax	; load 32-bit addr
				; magically sign-extended to 64-bits
	movq	%rax, %rdi	; place 64-bit edition in param #1 reg.
	call	printf		; call printf
</pre>

</dd><dt> printf(s, i)
</dt><dd> Printf'ing an int ought to be the simplest printf.
The second parameter is passed in %rsi.  If you placed a 32-bit
int in %esi you would still be OK.
<pre>	movq	<em>source</em>, %rsi	; what we would do
	movl	<em>source</em>, %esi	; "real" C int: 32, 64, same diff
</pre>

</dd><dt> printf(s, c)
</dt><dd> Printf'ing a character involves passing that char as a parameter.
Generally when passing
a "char" parameter one would pass it in a (long word, aligned) slot, and
it is prudent to (basically) promote it to "int" in this slot.
<pre>	movsbl	<em>source</em>, %esi
</pre>

</dd><dt> printf(s, s)
</dt><dd> Printf'ing a string involves passing that string as a parameter.
For <a href="https://www.cs.nmt.edu/~jeffery/courses/423/x64/printf-s.c">local variable string constant data</a>,
gcc does
some <a href="https://www.cs.nmt.edu/~jeffery/courses/423/x64/printf-s.s">pretty weird stuff</a>.
I'd kind of rather allocate the string constant out of the string
constant region and then copy it into the local region, but perhaps
calculating the contents of a string constant as a sequence of
32-bit long immediate values is an interesting exercise.

</dd></dl>

<!--
<h3> C++ Output </h3>

Now, how about C++?  After some thought, we concluded that each output
(send) operator could be implemented by generating code for one call to
printf, with an appropriate format string for the type of the right operand.
This output is a side effect.
The expression result of the output operator is its left operand.


Potential optimizations of the preceding method for C++ output operations
include:
<ul>
<li> bundling a string of output operators into a single call to printf, or
     almost the opposite,
<li> using more direct output functions than printf, which is not famous for
     speed.  C++ may have dumped C stdio specifically because they believed
     printf's "mini-intepreter" of format strings was suboptimal.
     For example, fputc(c,stdout) is faster than printf("%c",c).
     Q: what is the fastest way to write out an integer?  What about a double?
</ul>

<h3> C++ Input Operator </h3>

Consider for a moment how to input an integer.  This is pretty fundamental;
even toy programs usually let a user enter a number.  The C program for it
might use scanf("%d", &amp;i), but in C++ one says cin &gt;&gt; i.

<table border>
<tr>
<th> "Real" <th> C-like, for 120++
<tr>
<td>
<pre>
	leaq	-8(%rbp), %rax
	movq	%rax, %rsi
	movl	$_ZSt3cin, %edi
	call	_ZNSirsERi
</pre>
<td>
<pre>
	leaq	-8(%rbp), %rax
	movq	%rax, %rsi
	movl	$.LC0, %edi
	movl	$0, %eax
	call	scanf
</pre>
</table>
-->

<!--
<h3> Implementing 120++ subset cin, cout, &lt;&lt; and &gt;&gt; </h3>

This topic is by student request. Our starting point is the goal of
providing minimal functionality necessary to produce output, so you
can tell whether generated code did anything.  In fact, let's start
with "hello world".  Consider the following sample hello.cpp program:

<pre>
#include &lt;iostream&gt;
using namespace std;

int main()
{
cout << "Hello, world\n";
}
</pre>

One of your basic design decisions is whether to use the real cin/cout,
or to write your own (toy subset) versions.

<h4> libstdc++ </h4>

If you follow g++ calling
conventions you can potentially link to and use their library, which
might save you some work.  But, g++ calling conventions are no picnic.
For the preceding "hello, world" program, the most juicy bits of the
generated assembler are:

<pre>
	.section	.rodata
.LC0:
	.string	"Hello, world\n"
	.text
.globl main
	.type	main, @function
main:
	...
	movl	$.LC0, %esi
	movl	$_ZSt4cout, %edi
	call	_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc
</pre>

Personally, I can stomach the reference to <code>$_ZSt4cout</code>
but I am not superkeen about generating calls to functions with names
like the one in the <code>call</code> instruction here.

<h4> Homemade 120++ cout emulation </h4>

How about writing your own <code>lib120++.so</code>
and linking it in when you generate code?  Suppose that

<pre>cout &lt;&lt; s;</pre> resulted in the generated code equivalent to:

<pre>cout.out_str(s);</pre>

where <code>cout</code> in 120++ is an instance of a toy
<code>ofstream</code> class that looks like (_120ofstream.h):

<pre>
#include &lt;stdio.h&gt;
class _120_ofstream {
private:
   FILE *f;
public:
   _120_ofstream(int i);
   void out_str(char *s);
   void out_long(long l);
   void out_double(double d);
};
</pre>

The constructor parameter specifies cout (1) or cerr(2).
You would write your own implementation of this "library class",
compile with g++ and link it in and call it from your generated code.

<p>

If your compiler doesn't implement classes at all,
you might instead translate

<pre>cout &lt;&lt; s;</pre> to

<pre>_120out_str(cout, s);</pre>

where <code>cout</code> is a global variable (int, value == 1)
and the function is

<pre>
void _120out_str(int f, char *s)
{
   FILE *fp;
   if (f == 1) fp = stdout;
   else if (f == 2) fp = stderr;
   else { fprintf(stderr, "unknown output stream %d\n", f); exit(1); }
   fprintf(fp, "%s", s);
}
</pre>

You might need more output functions for other types.
g0 considers short and int to be the same as long, and float
to be the same as double.  Does it ever output char?
-->

<h3> Another Word on Interprocedural Optimization </h3>

The optimization unit of this course mentions only the
biggest categories of compiler optimization and gives very brief
examples.  That "argument culling" example of interprocedural
optimization deserves at least a little more context:

<ul>
<li> Interprocedural optimization (IPO) includes any optimizations that
     apply across function call boundaries, not just culling
</li><li> Because function call boundaries are what is being optimized, this
     will often focus on analysis of information known about parameters
     and return type
</li><li> Includes function inlining, if the compiler decides when to do that,
     rather than leave the decision up to the programmer.
</li><li> Can only do interprocedural optimization on procedures the compiler
     knows about; limited value unless compiling whole program together,
     or embedding in linker
</li><li> Modern production compilers have extra command-line options for IPO
</li></ul>


<h3> Comments on Debugging Assembler </h3>

The compiler writer that generates bad assembler code may need to debug
the assembler code in order to understand why it is wrong.
<ul>
<li> See <a href="http://dbp-consulting.com/tutorials/debugging/basicAsmDebuggingGDB.html">this tutorial from DBP Consulting</a> for some good ideas
</li><li> You almost only need to learn gdb's si and ni commands.
</li><li> You also need to know "as --gstabs+"
</li><li> You also need to know "info registers", or "i r" (e.g. "i r eax")
</li><li> In plain assembler debugging s and n work in lieu of si and ni
</li></ul>

<h3> Dominators and Loops </h3>

Raison d'etre: many/various Loop Optimizations require that loops be
specially identified within a general flow graph context.  If code is
properly structured (e.g. no "goto" statements) these loop optimizations are
safe to do, but in the general case for C you would have to check...

<dl>
<dt> dominator
</dt><dd> node d in a flow graph <em>dominates</em> node n (written as "d dom n")
if every path from the initial node of the flow graph to n goes through d
</dd><dt> dominator tree
</dt><dd> tree formed from nodes in the flow graph whose root is the initial node,
and node n is an ancestor of node m only if n dominates m. Each node in a
flow graph has a unique "immediate dominator" (nearest dominator), hence a
dominator tree can be formed.
</dd></dl>

<img src="domtree.png" width="500">

<h3> Loops in Flow Graphs </h3>

<ul>
<li> Must have a single entry point (the header) that dominates all nodes
</li><li> Must be a way to iterate; at least one path back to the header
</li><li> To find loops: look for edges a-&gt;b where b dominates a (back edges)
</li><li> Given a back edge n-&gt;d, the <em>natural loop</em> of this edge is
d plus the set of nodes that can reach n without going through d.
</li><li> every back edge has a natural loop...
</li></ul>



<h3> Algorithm to construct the natural loop of a back edge </h3>

Input: a flow graph <code>G</code> and a back edge <code>n -&gt; d</code> <br>
Output: the set (named <em>loop</em>) consisting of all nodes in the
natural loop of <code>n -&gt; d</code>.
<p>
Method: depth-first search on the reverse flow graph <code>G'</code>.
Start with loop containing only node <code>n</code> and <code>d</code>.
Consider each node <code>m | m != d</code> that is in
<em>loop</em>, and insert <code>m</code>'s predecessors in
<code>G</code> into <em>loop</em>. Each
node is placed once on a stack, so its predecessors will be examined.
Since <code>d</code> is put in <em>loop</em> initially, its predecessors
are not examined.

</p><pre>procedure insert(m)
   if not member(loop, m) then {
      loop := loop ++ { m }
      push m onto stack
   }
end

main:
   stack := []
   loop := { d }
   insert(n)
   while stack not empty do {
      pop m off stack
      for each predecessor p of m do insert(p)
      }
</pre>

<h3> Inner Loops </h3>

<ul>
<li> If only natural loops are considered then unless two loops have the same
header, they are either disjoint or one is nested within the other.  The ones
that are nested inside other loops may be of more interest e.g. for
optimization.
<br>
<img src="innerloops0001.png" width="400">

</li><li> If two loops share the same header, neither is inner to the other,
instead they are treated as one loop.
<br>
<img src="innerloops0002.png" width="200">
</li></ul>









<h3> Code Generation for Virtual Machines </h3>

A virtual machine architecture such as the JVM changes the "final" code
generation somewhat.  We have seen several changes, some of which
simplify final code generation and some of which complicate things.

<dl>
<dt> no registers, simplified addressing
</dt><dd> a virtual machine may omit a register model and avoid complex
     addressing modes for different types of variables
</dd><dt> uni-size or descriptor-based values
</dt><dd> if all variables are "the same size", some of the details of
     memory management are simplified.  In Java most values occupy
     a standard "slot" size, although some values occupy two slots.
     In Icon and Unicon, all values are stored using a same-size descriptor.
</dd><dt> runtime type system
</dt><dd> requiring type information at runtime may complicate the
     code generation task since type information must be present
     in generated code.  For example in Java method invocation and
     field access instructions must encode class information.
</dd></dl>

Just for fun, let's compare the generated code for java with that X86
native code we looked at earlier when we were talking about how to make
variables spill out of registers:
<pre>	iload_1
	iload_2
	iadd
	iload_3
	iload 4
	iadd
	imul
	iload 5
	iload 6
	iadd
	iload 7
	iload_1
	iadd
	imul
	iload_3
	iload 5
	imul
	idiv
	iadd
	istore_1
</pre>

What do you see?
<br><br><br><br><br><br>
<ul>
<li> Stack-machine model. Most instructions implicitly use the stack.
</li><li> Difference between "iload_3" and "iload 4": Java VM has special
     opcodes that run faster for first 3 locals/temporaries.
</li></ul>

thanks here to T. Mowry.

<h3> Preheaders </h3>

Loop optimizations often require code to be executed once before the loop.
Example: loop hoisting.

Solution: introduce a new (possibly empty) basic block for every loop.
It had to have a header anyhow; give it a preheader.

<h3> What was all that Loops/Dominators Stuff For?</h3>

<ul>
<li>You can't do the loop optimizations on malformed loops!
</li><li> To be safe, one must identify proper optimization-eligible "loops"
from their shape in the flow graph, not
from syntax keywords like "while" or "for".
</li><li> The whole flow graph for a function, then, will contain zero or more
    (usually one or more) inner, natural loops that can be worked on by
    storing in an auxiliary data structure the set of nodes (from the flow
    graph) that belong under a given header.
</li></ul>
<p>

Given that you find such a natural loop, you can do:

</p><h4> Loop Hoisting </h4>

<ul>
<li> identify loop invariant. Invariant wrt loop iff operands are defined
     outside loop or constant OR definition inside loop was itself invariant.
</li><li> move invariant to preheader
</li></ul>

Hoisting Conditions
thank you to Peter Lee

Hoisting conditions
For a loop-invariant definition
d: t = x op y
we can hoist instruction d into the loops pre-header if:
1. ds block dominates all loop exits at which t is
live-out, and
2. there is only one definition of t in the loop, and
3. t is not live-out of the pre-header

<h4> Finding Loop Invariants </h4>

OK, what can you do with this:
<p>
<img src="hoisting.png">
</p><p>
Did you get:
</p><p>
<img src="hoisted.png">
</p><p>

Exercise: run it a few billion times; see whether hoisting a couple
operations out of the loop makes a measurable difference.  It might
not, after all... gotos are expensive.

Exercise: what is wrong with this example?

Another example (from Wikipedia loop-invariant code motion):

</p><pre>for (int i = 0; i &lt; n; i++) {
    x = y + z;
    a[i] = 6 * i + x * x;
}
</pre>

One can hoise not just x = y + z; because it establishes x as invariant,
subexpression x*x (into a temp variable) can also be hoisted.


<h3> More on Runtime Systems </h3>

Every compiler (including yours) needs a runtime system.  A runtime system
is the set of library functions and possibly global variables maintained by
the language on behalf of a running program.  You use one all the time; in C
it functions like printf(), plus perhaps internal compiler-generated calls
to do things the processor doesn't do in hardware.<p>

So you need a runtime system; potentially, this might be as big or bigger a
job than writing the compiler.  Languages vary from assembler (no runtime
system) and C (small runtime system, mostly C with some assembler) on up to
Java (large runtime system, mostly Java with some C) and in even higher level
languages the compiler may evaporate and the runtime system become gigantic.
The Unicon language has a relatively trivial compiler and gigantic virtual
machine and runtime system.  Other scripting languages might have no compiler
at all, doing everything (even lexing and parsing) in the runtime system.
</p><p>

<!--
For your project: whatever type of output code you generate, you need a plan
for what to do about a runtime system.  And, in principle, I am not opposed
to helping with this part.  But the compiler and runtime system have to fit
together; if I write part of the BASIC runtime system for you, or we write
it together, we have to agree on things such as: what the types of
parameters and return values must look like.<p>

So, what belongs in a Color BASIC runtime system?  Anything not covered
by a three address instruction.  Looking at cocogram.y:
<ul>
<li> INPUT/PRINT
<li> READ/DATA
<li> CLEAR
<li> CLOAD/CSAVE/SKIPF
<li> CLS
<li> SET/RESET
<li> SOUND
<li> CHR$, LEFT$, MID$, RIGHT$, INKEY$
<li> ASC, INT, JOYSTK, LEN, PEEK, RND, VAL
<li> DIM
<li> string +, string compares
</ul>
<p>

What would a runtime system function look like?  It would take in and
pass out BASIC values, represented as C structs.  You would then link
this code in to your generated C or assembler code (if you generated
Java code, you would have to deal with the Java Native Interface or
else write these functions in Java).
<pre>
void PRINT(struct descrip *d)
{
   switch (d->type) {
   case INTEGER: printf("%d",d->value.ival); break;
   case REAL: printf("%f",d->value.rval); break;
   case STRING: printf("%*s",d->size,d->value.string); break;
   case ARRAY: printf("cannot print arrays"); break; /* can't get here */
   default: printf("PRINT: internal error, type %d\n", d->type);
   }
}
</pre>

Now, let's look at the "whole" runtime system:

<ul>
<li> <A href="libb.c">libb.c</A>
</ul>

<h3> More on Memory Management in the BASIC Runtime System </h3>

Arrays are interesting.  They can be used without being declared or DIM'ed.
They can only be DIM'ed once.  If you use them before they are DIM'ed, they
are implicitly DIM'ed to size 11 and can't be re-DIM'ed.
<p>
What do variables A, A(), A$, and A$() look like in memory?  How does our
runtime system make it so?
<p>
Let's take a look at DIM, in libc.c.  This DIM is for arrays of numbers.
How would you handle arrays of strings?
<p>
Can you implement STRCAT for your BASIC runtime system?
<p>
What other BASIC statements, operators, or functions allocate memory?
<p>
How would we avoid memory "leaks"?

<h3> STRCAT </h3>

So, what does your STRCAT look like?  <A href="libb.c#strcat">Here's one.</A>

<h3> GOSUBs </h3>

Our 3-address instruction set has call and return instructions, but basic
is less structured than regular procedural languages; you can GOSUB to any
line number you want.  You can't use a variable to GOSUB to line number X,
but in principle every line number could be the target of a procedure call.
<p>
If you use the "call" (3-address) instruction to do GOSUB, your native code
will have to make a clear distinction between BASIC call's and calls to
runtime system (built-in) functions.  Perhaps it is best to implement BASIC
GOSUB by pushing a "param" (the next instruction following the GOSUB) and
a "goto".  The BASIC RETURN is then a "pop" followed by a "goto".  What,
we don't have a "pop" 3-address instruction?  We do now...  the name of
"param" should probably be "push" anyhow.
<p>

Come to think of it, we've been talking about doing a call to a built-in
function such as PRINT, but that PRINT function we wrote is C code; it
doesn't do a 3-address "ret" instruction, hmmm.  How are we going to
generate the native code for the 3-address "call" instruction?
It may include an assembler call instruction, but it may also involve
instructions to handle the interface between BASIC and C.
-->
<!--
<h3> Flex SDK Comments </h3>

Adobe's Flex SDK web pages point you only at Windows binary downloads,
but if you dig further, it appears to be some big Java open source project.
<ul>
<li><A href="http://opensource.adobe.com/wiki/display/flexsdk/Setup+on+Linux">build instructions</A>
<li> You have to have a good Java and Ant (wormulon didn't, Larry seems
     to have put it on for me
<li> Warning: the SVN checkout can take HOURS on a cable modem.  Literally
     filled my laptop hard drive over several hours without completing.
     It occurs to me this might be their way of making their "open source"
     project as not-open as possible.
     Suggest you append "/trunk" to the name they say to checkout.
     Long checkout seems to be worsened by an idiotic policy of putting open
     sandbox end-user junk in the SVN repository! But also, it is big.
<li> Tried with /trunk on eternium, ran 46 minutes and then died with an
     error prior to completion
<li> Instructions say to "source setup.sh", but this did not go so well for
     me on wormulon (must be running bash, not csh). When I switched over to
     bash, complained about many missing or renamed files and died.
<li>Conclusions:
    (a) easier to just get this on a Windows machine if you have one.
    (b) example of an "open source" project that isn't really open.
</ul>
-->

</p><h3> Quick Look at the Implementation of Unicon </h3>

<ul>
<li> Language much higher level than C, C++, or Java, closer to Python
</li><li> Descended from Icon, whose Big Research Contribution was:
     integrating goal-directed evaluation into imperative programming
</li><li> Unicon came into existence because a tiny office in The Government
     wanted to use Icon, but needed it to be relevent to their real world
     problems: big data, analysis of large unstructured text stored in
     SQL databases.
</li><li> Unicon's Little Research Contributions are:
<ul>
<li> scaling Icon to large real-world problems
</li><li> adding OOP, concurrency, pattern type, rich high-level I/O subsystems
</li><li> native execution monitoring
</li></ul>
</li><li> At least Three implementations:
<ul>
<li> Virtual machine, no registers, yes built-in backtracking
</li><li> Optimizing compiler, generates C, backtracking turns into continuation passing
</li><li> Transformer, generates Java, backtracking turns into iterators
</li></ul>
</li><li> In all cases, the runtime system is far larger than the compiler!
</li><li> Compared with a traditional language:
<ul>
<li> no type checking in the compiler!
</li><li> runtime type checks (opt. compiler: type inferencing)
</li></ul>
</li></ul>

The remainder of this quick look will focus on OO features, as implementing
object-oriented language features is of broad interest.


<h3> On Double Constants in Assembler </h3>

For what its worth, I was Wrong. I claimed to one or more of you that
immediate mode instructions didn't include full 64-bit immediate constants,
but see the end of lecture #48! Earlier this semester we already noted
that x86_64 does in fact have immediate mode for 64-bits...for at least
one instruction/opcode (movabsq).  Proof by contradiction.  I note that the
double 3.1415 was represented in <a href="https://www.cs.nmt.edu/~jeffery/courses/423/x64/dbl.s">output assembler</a>
by $4614256447914709615.
Just for fun, I checked my earlier cast-to-long strategy:
<pre>#include <iostream>
using namespace std;
int main()
{
   double d;
   d = 3.1415;
   long l = *(long *)(&amp;d);
   cout &lt;&lt; "$" &lt;&lt; l &lt;&lt; endl;
}
</iostream></pre>
outputs:
<pre>$4614256447914709615
</pre>
We win.


<h3> Tips on Invoking the Assembler and Linker from your Compiler </h3>

HW#6 calls for your compiler to produce an executable
that I can run.  But we have mainly discussed a compiler that writes out code
suitable for input to an assembler. A student requested that I give you some
tips on getting the rest of the way.

<ul>
<li> You could write a puny shell script that ran your compiler (named
     something else) and them ran the assembler and linker.
</li><li> Probably better to call assembler and linker from within your main().
</li><li> Probably this means invoking an external program/process from your
     program.
</li><li> Most standard way to do this is via system(s).  Could use popen() or
     fork()/exec()/wait() but system() is probably best.
</li><li> Return integer is a "status" consisting of an exit code PLUS STUFF.
     You have to use WEXITSTATUS(i) to get the process return code of 
     command s.
</li><li> The assembler is named as, and as mentioned you may want to use
as --gstabs+, as in
<pre>as --gstabs+ -o foo.o foo.s
</pre>
</li><li> The linker is named ld, and you typically would invoke it with not
     just your own code, but also startup code to call your main(), and
     a runtime library. If your library were named libpuny.a that might
     look like:
<pre>ld -o foo /usr/lib64/crt1.o foo.o -lpuny
</pre>
</li><li> If you were invoking the linker ld on a "real" g++ standard library the
ld command invocation is more complex. For example in April 2021 on
lovecraft.cs.nmt.edu it looked like:

<pre>ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 /usr/lib/x86_64-linux-gnu/crt1.o /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbegin.o hello.o -lc /usr/lib/gcc/x86_64-linux-gnu/7/crtend.o /usr/lib/x86_64-linux-gnu/crtn.o</pre>

In April 2023 these versions appear the same or very close on login.cs.nmt.edu
but might vary on your machine.

<!--
 For example in December 2017 on
wormulon (Centos) it looked like:
<pre>ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 /usr/lib64/crt1.o /usr/lib64/crti.o /usr/lib/gcc/x86_64-redhat-linux/4.4.7/crtbegin.o dbl.o /usr/lib64/libstdc++.so.6 -lc /usr/lib/gcc/x86_64-redhat-linux/4.4.7/crtend.o /usr/lib64/crtn.o
</pre>-->
Since this is version-specific, a more "portable" way is to use
gcc or g++ as
your linker, if you are going to link in its standard C (or C++) libraries:
<pre>gcc hello.o
</pre>

</li><li> Runtime libraries like libpuny.a are built from .o files by running
the archiver program ar, as in
<pre>ar cr libpuny.a mylib1.o mylib2.o ...
</pre>
</li><li> You can expect to have to read the man pages for as, ld, ar, and system
in order to figure out options.
</li><li> There is a potential problem with where your
compiler should find libpuny.a, how shall we solve that?
</li></ul>


<h3> Imports and Inheritance in Unicon </h3>

Unicon is different from mainstream languages, and this section is not intended
to tell you what you are supposed to do, it is intended to provide a basis for
comparison.

<h4> Syntax Tree Overview </h4>

Unicon uses "iyacc", a variant of Berkeley yacc, which is a cousin of Bison.
The <a href="https://www.cs.nmt.edu/~jeffery/courses/423/unigram.y">unigram.y</a> grammar has around 234 shift reduce
conflicts.  The semantic action at the import statement is illustrative of
tree construction as well as what little semantic analysis Unicon does.

<pre>import: IMPORT implist {
   $$ := node("import", $1,$2," ")
   import_class($2)
   } ;
</pre>

For what its worth, the tree type in Unicon is very challenging and
sophisticated:
<pre>record treenode(label, children)
procedure node(label, kids[])
   return treenode(label, kids)
end
</pre>

Actually, Unicon syntax trees are incredibly simple, except that
they are actually heterogeneous trees with a mixture
of treenode, string, token, and various class objects.

<h4> Idol.icn </h4>

Despite the generic tree, various class objects
from <a href="https://www.cs.nmt.edu/~jeffery/courses/423/idol.icn">idol.icn</a> store all the
interesting stuff in the syntax tree.  It is almost
really one class per non-terminal type, and those
non-terminals that have symbol tables have a field
in the class that contains the symbol (hash) table object.
<p>

class Package (one of the only parts of idol.icn I didn't write)
tells a real interesting story.  There is both an in-memory
representation of what we know about the world, and a persistent
on-disk representation (in order to support separate compilation).

</p><pre>#
# a package is a virtual syntax construct; it does not appear in source
# code, but is stored in the database.  The "fields" in a package are
# the list of global symbols defined within that package.  The filelist
# is the list of source files that are linked in when that package is
# imported.
#
class Package : declaration(files, dir, classes)
   #
   # Add to the two global tables of imported symbols from this package's
   # set of symbols.  If sym is non-null, we are importing an individual
   # symbol (import "pack.symbol").
   #
   method add_imported(sym)
      local s, f

      if /dir then return
      
      f := open(dir || "/uniclass", "dr") |
	 stop("Couldn't re-open uniclass db in " || dir)
      every s := (if \sym then sym else fields.foreach()) do {
         if member(imported, s) then
             put(imported[s], self.name)
          else {
             imported[s] := [self.name]
          }

         if fetch(f, self.name || "__" || s) then {
            if member(imported_classes, s) then
               put(imported_classes[s], self.name)
            else {
               imported_classes[s] := [self.name]
            }
         }
      }
      close(f)
   end
   method Read(line)
      self$declaration.Read(line)
      self.files := idTaque(":")
      self.files$parse(line[find(":",line)+1:find("(",line)] | "")
   end
   method size()
      return fields$size()
   end
   method insertfname(filename)
      /files := idTaque(":")
      if files.insert(filename) then {
         write(filename, " is added to package ", name)
         writespec()
         }
      else write(filename, " is already in Package ", name)
   end
   method insertsym(sym, filename)
      if fields.insert(sym) then {
         write(sym, " added to package ", name)
         writespec()
         }
      else write(sym, " is already in Package ", name)
   end
   method containssym(sym)
       return \fields.lookup(sym)
   end
   method String()
      s := self$declaration.String()
      fs := files.String()
      if *fs &gt; 0 then fs := " : " || fs
      s := s[1: (*tag + *name + 2)] || fs || s[*tag+*name+2:0]
      return s
   end
   method writespec()
   if \name &amp; (f := open(env,"d")) then {
      insert(f, name, String())
      close(f)
      return
      }
   stop("can't write package spec for ", image(name))
   end
initially(name)
   if name[1] == name[-1] == "\"" then {
      name := name[2:-1]
      self.name := ""
      name ? {
	 if upto('/\\') then {
	    while self.name ||:= tab(upto('/\\')) do self.name ||:= move(1)
	    }
	 self.name ||:= tab(find(".")|0)
	 }
      }
   else {
      self.name := name
      }
   if dbe := fetchspec(self.name) then {
      Read(dbe.entry)
      self.dir := dbe.dir
      }
   /tag := "package"
   /fields := classFields()
end
</pre>

<h4> fetching a specification </h4>

Given a class name, how do we find it?  It must live in a GDBM database
(uniclass) somewhere along the IPATH. A bunch of tedious string parsing
concluding with a GDBM fetch.

<pre>#
# find a class specification, along the IPATH if necessary
#
procedure fetchspec(name)
   static white, nonwhite
   local basedir := "."
$ifdef _MS_WINDOWS_NT
   white := ' \t;'
   nonwhite := &amp;cset -- ' \t;'
$else
   white := ' \t'
   nonwhite := &amp;cset -- ' \t'
$endif
   name ? {
      while basedir ||:= tab(upto('\\/')) do {
	 basedir ||:= move(1)
	 }
      name := tab(0)
      # throw away initial "." and trailing "/"
      if basedir[-1] == ("\\"|"/") then basedir := basedir[2:-1]
      }
   if f := open(basedir || "/" || env,"dr") then {
      if s := fetch(f, name) then {
	 close(f)
	 return db_entry(basedir, s)
	 }
      close(f)
      }

   if basedir ~== "." then fail # if it gave a path, don't search IPATH

   ipath := ipaths()

   if \ipath then {
      ipath ? {
         dir := ""
	 tab(many(white))
	 while dir ||:= tab(many(nonwhite)) do {
	    if *dir&gt;0 &amp; dir[1]=="\"" &amp; dir[-1] ~== "\"" then {
		dir ||:= tab(many(white)) | { fail }
	       }
	    else {
		if dir[1]==dir[-1]=="\"" then dir := dir[2:-1]
		if f := open(dir || "/" || env, "dr") then {
		    if s := fetch(f, name) then {
			close(f); return db_entry(dir, s) }
		    close(f)
		}
		tab(many(white))
		dir := ""
	    }
	}
     }
  }
end
</pre>

<h3> Closure-Based Inheritance </h3>

Unicon not only allows multiple inheritance, it is the only language that I
know of that can handle cycles in the inheritance graph.  It does this by
having each child be completely self-centered. When they inherit, they rifle
through their parents looking for spare change. This is a depth-first method
that completely/perfectly inherits from the first superclass (including all
its parents) and only then considers later step-parents.
<p>

Inside class Class, supers is an object that maintains an ordered list of a
class' superclasses (i.e. parents).  Variable classes is effectively a
global object that knows all the classes in the current package and let's
you look them up by name.  Variable added tracks classes already visited,
and prevents repeating any classes already on the list.

</p><pre>  method transitive_closure()
    count := supers.size()
    while count &gt; 0 do {
	added := taque()
	every sc := supers.foreach() do {
	  if /(super := classes.lookup(sc)) then
	    halt("class/transitive_closure: couldn't find superclass ",sc)
	  every supersuper := super.foreachsuper() do {
	    if / self.supers.lookup(supersuper) &amp;
		 /added.lookup(supersuper) then {
	      added.insert(supersuper)
	    }
	  }
	}
	count := added.size()
	every self.supers.insert(added$foreach())
    }
  end
</pre>

Given that all the superclasses have been ordered, the actual inheritance
in class Class is done by a method resolve():

<pre>  method resolve()
    #
    # these are lists of [class , ident] records
    #
    self.imethods := []
    self.ifields := []
    ipublics := []
    addedfields := table()
    addedmethods := table()
    every sc := supers.foreach() do {
	if /(superclass := classes.lookup(sc)) then
	    halt("class/resolve: couldn't find superclass ",sc)
	every superclassfield := superclass.foreachfield() do {
	    if /self.fields.lookup(superclassfield) &amp;
	       /addedfields[superclassfield] then {
		addedfields[superclassfield] := superclassfield
		put ( self.ifields , classident(sc,superclassfield) )
		if superclass.ispublic(superclassfield) then
		    put( ipublics, classident(sc,superclassfield) )
	    } else if \strict then {
		warn("class/resolve: '",sc,"' field '",superclassfield,
		     "' is redeclared in subclass ",self.name)
	    }
	}
	every superclassmethod := (superclass.foreachmethod()).name() do {
	    if /self.methods.lookup(superclassmethod) &amp;
	       /addedmethods[superclassmethod] then {
		addedmethods[superclassmethod] := superclassmethod
		put ( self.imethods, classident(sc,superclassmethod) )
	    }
	}
	every public := (!ipublics) do {
	    if public.Class == sc then
		put (self.imethods, classident(sc,public.ident))
	}
    }
  end
</pre>


<h3> Unicon Methods Vectors </h3>

Unicon resolves each class' inheritance information at compile time, and
generates a <em>field table</em> for runtime calculations that map field
names to slot#/offsets.  Methods vectors are just structs,
shared by objects by means of a pointer (__m) added to class instances.



<p>
<font size="1"> <a name="finalreview">final review</a> began here</font>
</p><p>



</p><h3> Final Exam Review </h3>

The final exam is comprehensive, but with a strong emphasis on middle and
"back end"
compiler issues: symbol tables, semantic analysis, and code generation.
The exam is (up to) 3 hours, closed book exam. You may bring up to 30 sheets
of notes written on paper size 8.5x11" or smaller.
In Spring 2023 we wrote a compiler for a more dynamically-typed language,
so you can expect some questions about that.

<ul>
<li>  Review your lexical analysis, regular expressions, and finite automata.
</li><li>  Review your syntax analysis, CFG's, and parsing.
</li><li>  If a parser discovers a syntax error, how can it report what line
      number that error occurs on?  If semantic analysis discovers a
      semantic error (or probable semantic error), how can it report what
      line number that error occurs on?
</li><li>  What are symbol tables?  How are they used?
      What information is stored there?
<li>  How does information get into a symbol table?
<li>  How many symbol tables does a compiler need?
<li>  What is "semantic analysis"?
<li>  What does "semantic analysis" accomplish? What are its side effects?
<li>  What are the primary activities of a compiler's semantic analyzer?
<li> How is type checking different for a language like PunY than for a
      language such as C?
<li>  What are memory regions, and why does a compiler care?
<li>  What memory regions are there, and how do they affect code generation?
<li>  What does code generation do, anyhow?
<li>  What kinds of code generation are there?
<li>  Why do (almost all) compilers use an "intermediate code"?  What does
      intermediate code look like?  How is it different from final code?
<li> What are the main tasks in final code generation?
<li> How is final code generation for a bytecode virtual machine different
     than final native code for a mainstream CPU?
</ul>

<h4><a href="https://www.cs.nmt.edu/~jeffery/courses/423/sample-final.pdf">Sample Final Exam</a></h4>

This final is from a previous year and has questions specific to that
year's project.  But it gives you an idea of the kinds of questions
that appear on the final.  In Spring 2023, some of the questions may
be in a different format (short answer, multiple choice, true or false).
</body></html>
